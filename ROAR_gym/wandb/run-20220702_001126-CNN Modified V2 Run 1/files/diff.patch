diff --git a/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py b/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py
index 1fcefba..ff5a1cc 100644
--- a/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py
+++ b/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py
@@ -106,7 +106,7 @@ class ROARppoEnvE2E(ROAREnv):
         self.previous_control = None
 
     def step(self, action: Any) -> Tuple[Any, float, bool, dict]:
-        obs = []
+        obs = None #[]
         rewards = []
         self.steps+=1
         for i in range(1):
@@ -131,8 +131,8 @@ class ROARppoEnvE2E(ROAREnv):
             self.agent.kwargs["control"] = control
             self.previous_control = control
             
-            ob, reward, is_done, info = super(ROARppoEnvE2E, self).step(action)
-            obs.append(ob)
+            obs, reward, is_done, info = super(ROARppoEnvE2E, self).step(action) #was ob, reward, is_done, ...
+            #obs.append(ob)
             rewards.append(reward)
             if is_done:
                 break
@@ -148,7 +148,7 @@ class ROARppoEnvE2E(ROAREnv):
             self.wandb_logger()
             self.crash_check = False
             self.update_highscore()
-        return np.array(obs), self.frame_reward, self._terminal(), self._get_info()
+        return obs, self.frame_reward, self._terminal(), self._get_info() #np.array(obs), self.frame_reward, self._terminal(), self._get_info()
 
     def _get_info(self) -> dict:
         info_dict = OrderedDict()
@@ -274,10 +274,11 @@ class ROARppoEnvE2E(ROAREnv):
             ])
 
 
-            return {
+            retVal = {
                 "occupancy_map": cnnObs,
                 "previous_control": last_control_array
             }
+            return retVal
 
         else:
             data = self.agent.occupancy_map.get_map(transform=self.agent.vehicle.transform,
diff --git a/ROAR_gym/configurations/ppo_configuration.py b/ROAR_gym/configurations/ppo_configuration.py
index 7e6c1d3..4e074f1 100644
--- a/ROAR_gym/configurations/ppo_configuration.py
+++ b/ROAR_gym/configurations/ppo_configuration.py
@@ -10,8 +10,8 @@ sys.path.append(Path(os.getcwd()).parent.as_posix())
 misc_params = {
   "env_name": 'roar-e2e-ppo-v0',
   "run_fps": 8,  # TODO Link to the environment RUN_FPS
-  "model_directory": Path("./output/Yunhao_PPOe2e_CNN_Modified_Change_V2"),
-  "run_name": "CNN V2 Modified Run 1",
+  "model_directory": Path("./output/Yunhao_PPOe2e_CNN_Modified_V2_Change"),
+  "run_name": "CNN Modified V2 Run 1",
   "total_timesteps": int(1e6),
 }
 
diff --git a/ROAR_gym/configurations/wandb_configuration.json b/ROAR_gym/configurations/wandb_configuration.json
index 2476cda..fc69aae 100644
--- a/ROAR_gym/configurations/wandb_configuration.json
+++ b/ROAR_gym/configurations/wandb_configuration.json
@@ -1 +1 @@
-{"run_id": "CNN V2 Modified Run 1", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
\ No newline at end of file
+{"run_id": "CNN Modified V2 Run 1", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
\ No newline at end of file
diff --git a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468564.Windys-Desktop.19712.0 b/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468564.Windys-Desktop.19712.0
deleted file mode 100644
index a6bbbb9..0000000
Binary files a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468564.Windys-Desktop.19712.0 and /dev/null differ
diff --git a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468585.Windys-Desktop.20204.0 b/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468585.Windys-Desktop.20204.0
deleted file mode 100644
index 97bdd74..0000000
Binary files a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468585.Windys-Desktop.20204.0 and /dev/null differ
diff --git a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468665.Windys-Desktop.20072.0 b/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468665.Windys-Desktop.20072.0
deleted file mode 100644
index 2c2b95d..0000000
Binary files a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468665.Windys-Desktop.20072.0 and /dev/null differ
diff --git a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468752.Windys-Desktop.5676.0 b/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468752.Windys-Desktop.5676.0
deleted file mode 100644
index db95b14..0000000
Binary files a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468752.Windys-Desktop.5676.0 and /dev/null differ
diff --git a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468960.Windys-Desktop.10996.0 b/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468960.Windys-Desktop.10996.0
deleted file mode 100644
index e13ecd2..0000000
Binary files a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656468960.Windys-Desktop.10996.0 and /dev/null differ
diff --git a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656469475.Windys-Desktop.8628.0 b/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656469475.Windys-Desktop.8628.0
deleted file mode 100644
index ddbae88..0000000
Binary files a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656469475.Windys-Desktop.8628.0 and /dev/null differ
diff --git a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656471346.Windys-Desktop.18756.0 b/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656471346.Windys-Desktop.18756.0
deleted file mode 100644
index 2389b3e..0000000
Binary files a/ROAR_gym/runs/CNN V2 Modified Run 1/PPO_0/events.out.tfevents.1656471346.Windys-Desktop.18756.0 and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/code/ROAR_Gym/e2eModel.py b/ROAR_gym/wandb/run-20220621_224502-Run 5/files/code/ROAR_Gym/e2eModel.py
deleted file mode 100644
index 0016e12..0000000
--- a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/code/ROAR_Gym/e2eModel.py	
+++ /dev/null
@@ -1,352 +0,0 @@
-"""
-IMPORTANT
-IF YOU HAVE NOT RUN THIS FILE AS 'ADMIN' (OR OPENED PYCHARM AS 'ADMIN')
-STOP AND RESTART WITH ADMIN PRIVILEGES
-
-TODO: Before Running this file make the following changes:
-1. Add the following line:
-    self._last_obs = np.nan_to_num(self._last_obs)
-
-to the following file:
-    ROAR\venv\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py
-
-2. Add this line after line 167 such that:
-with th.no_grad():
-    # Convert to pytorch tensor or to TensorDict
-    self._last_obs = np.nan_to_num(self._last_obs)
-    obs_tensor = obs_as_tensor(self._last_obs, self.device)
-    actions, values, log_probs = self.policy.forward(obs_tensor)
-
-3. Add: #############################################################################still needed?###########
-
-        data.pop('_last_obs')
-
-    in  line 652 of base_class.py for sb3
-    possible location of file: \envs\ROAR\Lib\site-packages\stable_baselines3\common\base_class.py
-
-4. Change for on_policy_algorithm.py, in function collect_rollouts add:
-
-        self.env.reset()
-
-    before the following while loop:
-
-        while n_steps < n_rollout_steps:
-"""
-
-# IMPORTS
-# imports for logs and warnings
-import warnings
-import logging
-
-from typing import Optional, Dict
-
-# imports for weights and biases integration
-import wandb
-from wandb.integration.sb3 import WandbCallback
-
-# imports for file path handling
-import os
-import sys
-from pathlib import Path
-sys.path.append(Path(os.getcwd()).parent.as_posix())
-
-# imports for reading and writing json config files
-import json
-
-# imports from the ROAR module
-from ROAR_Sim.configurations.configuration import Configuration as CarlaConfig
-from ROAR.configurations.configuration import Configuration as AgentConfig
-from ROAR.agent_module.agent import Agent
-from ROAR.agent_module.rl_e2e_ppo_agent import RLe2ePPOAgent
-from ROAR.agent_module.forward_only_agent import ForwardOnlyAgent   # testing stuff
-
-# imports for reinforcement learning
-import gym
-import torch as th
-from stable_baselines3.ppo.ppo import PPO
-from stable_baselines3.ppo.policies import CnnPolicy
-from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps, CallbackList, BaseCallback
-from stable_baselines3.common.monitor import Monitor
-from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder
-
-
-# imports for helper functions and torch cnn models
-from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN
-
-
-
-# imports from config files
-from configurations.ppo_configuration import PPO_params, misc_params, wandb_saves
-agent_config = AgentConfig.parse_file(Path("configurations/agent_configuration.json"))
-carla_config = CarlaConfig.parse_file(Path("configurations/carla_configuration.json"))
-
-# Setup for the loggers
-logging.getLogger("tensorflow").setLevel(logging.ERROR)
-logging.getLogger("numpy").setLevel(logging.ERROR)
-warnings.filterwarnings('ignore')
-try:
-    from ROAR_Gym.envs.roar_env import LoggingCallback
-except:
-    from ROAR_Gym.ROAR_Gym.envs.roar_env import LoggingCallback
-
-# os.environ["CUDA_VISIBLE_DEVICES"]="0,1"
-#  Parameters & Constants
-CUDA_VISIBLE_DEVICES = 1
-RUN_FPS = misc_params["run_fps"]
-MODEL_DIR = misc_params["model_directory"]
-WANDB_CONFIG_DIR = "configurations/wandb_configuration.json"
-
-
-def json_read_write(file, load_var=None, mode='r'):
-    """
-
-    Args:
-        file: address of json file to be loaded
-        load_var: variable to be written to, or read from
-        mode: 'r' to read from json, 'w' to write to json
-
-    Returns:
-        load_var: variable with data that has been read in mode 'r'
-                  original variable in case of 'w'
-
-    """
-    if mode == 'r':
-        with open(file, mode) as json_file:
-            load_var = json.load(json_file)  # Reading the file
-            print(f"{file} json config read successful")
-            json_file.close()
-            return load_var
-    elif mode == 'w':
-        assert load_var is not None, "load_var was None"
-        with open(file, mode) as json_file:
-            json.dump(load_var, json_file)  # Writing to the file
-            print(f"{file} json config write successful")
-            json_file.close()
-            return load_var
-    else:
-        assert mode == 'w' or 'r', f"unsupported mode type: {mode}"
-        return None
-
-# TODO track previously used run IDs
-def wandb_run_init(wandb_hp_config, load=False, requested_run_id=None, use_random_id=False):
-
-    wandb_config = json_read_write(
-        file=WANDB_CONFIG_DIR,
-        mode='r',
-    )
-
-    if load is True:
-        # Load run_id from the config file
-        run_id = wandb_config["run_id"]
-        assert run_id != "", "Run ID not set even though previous run exists"
-    else:
-        # Create wandb run id
-        if requested_run_id is not None:
-            run_id = requested_run_id
-        else:
-            assert use_random_id is True, "RUN ID NOT SET FOR NEW RUN"
-            run_id = wandb.util.generate_id()
-
-        # Store run_id to wandb_configuration file
-        wandb_config["run_id"] = run_id
-        wandb_config = json_read_write(
-            file=WANDB_CONFIG_DIR,
-            load_var=wandb_config,
-            mode='w',
-        )
-
-    # Create a wandb run variable
-    wandb.tensorboard.patch(
-        tensorboard_x=False,
-        pytorch=True,
-    )
-    run = wandb.init(
-        project=wandb_config["project_name"],
-        entity=wandb_config["entity"],  # Change to whoever wants to log the data
-        config=wandb_hp_config,
-        # sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics
-        save_code=True,  # Allows us to check diff of code between runs
-        resume="allow",
-        # magic=True,
-        id=run_id,
-        name=run_id,
-        #monitor_gym=True,  # auto-upload the videos of agents playing the game,
-    )
-
-    return run
-
-
-class Tensorboard_Faster_Logger(BaseCallback):
-    """
-    Callback for saving a model (the check is done every ``check_freq`` steps)
-    based on the training reward (in practice, we recommend using ``EvalCallback``).
-
-    :param check_freq:
-    :param log_dir: Path to the folder where the model will be saved.
-      It must contains the file created by the ``Monitor`` wrapper.
-    :param verbose: Verbosity level.
-    """
-    def __init__(self, check_freq: int, verbose: int = 1):
-        super(Tensorboard_Faster_Logger, self).__init__(verbose)
-        self.check_freq = check_freq
-
-    # def _init_callback(self) -> None:
-
-    def _on_step(self) -> bool:
-        if self.n_calls % self.check_freq == 0:
-            self.logger.dump(self.num_timesteps)
-        return True
-
-
-def main(pass_num):
-    # Create the gym environment using the configs
-    env = gym.make(
-        id=misc_params["env_name"],
-        params={
-            "agent_config": agent_config,
-            "carla_config": carla_config,
-            "ego_agent_class": RLe2ePPOAgent,
-        }
-    )
-    #print(th.cuda.is_available())
-
-    # Setting the feature extract or based on the environment mode
-    if env.mode == 'baseline':
-        policy_kwargs = dict(
-            features_extractor_class=Atari_PPO_Adapted_CNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-    else:
-        policy_kwargs = dict(
-            features_extractor_class=CustomMaxPoolCNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-
-    # training kwargs for PPO init
-    training_kwargs = PPO_params
-
-    # wandb config for current run hyper-parameters
-    wandb_hp_config = {
-        "policy_type": "CnnPolicy",
-        "env_name": misc_params["env_name"],
-        "training_kwargs": training_kwargs,
-    }
-
-    # Try to find latest model path if we have trained previously
-    latest_model_path = find_latest_model(MODEL_DIR)
-    print(latest_model_path)
-    # FIXME wandb may continue old run if the run crashes before it is logged
-    if latest_model_path is None:
-        # Create new wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=False,
-            requested_run_id=misc_params["run_name"],
-        )
-
-        # Create model with tensorboard log
-        model = PPO(
-            CnnPolicy,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs
-        )
-
-        print(f"Starting new run {run.id}")
-    else:
-        # Load wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=True,
-        )
-
-        # Load the model
-        model = PPO.load(
-            latest_model_path,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs,
-        )
-
-        print(f"Loading old run {run.id}")
-
-    print("Model Loaded Successfully")
-
-    # Defining Callback Functions
-
-    logging_callback = LoggingCallback(model=model)
-
-    faster_Logging_Callback = Tensorboard_Faster_Logger(check_freq=wandb_saves["model_save_freq"])
-
-    checkpoint_callback = CheckpointCallback(
-        save_freq=wandb_saves["model_save_freq"],
-        verbose=2,
-        save_path=(MODEL_DIR / "logs").as_posix()
-    )
-
-    event_callback = EveryNTimesteps(
-        n_steps=wandb_saves["model_save_freq"],
-        callback=checkpoint_callback
-    )
-
-    wandb_callback = WandbCallback(
-        verbose=2,
-        model_save_path=f"models/{run.id}",
-        gradient_save_freq=PPO_params["n_steps"],
-        model_save_freq=wandb_saves["model_save_freq"],
-    )
-
-    callbacks = CallbackList([
-        wandb_callback,
-        checkpoint_callback,
-        event_callback,
-        logging_callback
-        # faster_Logging_Callback
-    ])
-
-    # Begin learning
-    model = model.learn(
-        total_timesteps=misc_params["total_timesteps"],
-        callback=callbacks,
-        reset_num_timesteps=False,
-        # tb_log_name=wandb_config["run_id"],
-    )
-
-    # Save Model
-    model.save(MODEL_DIR / f"roar_e2e_model_{pass_num}")  # TODO fix naming convention
-    print("Successful Save!")
-    # # Finish wandb run
-    # run.finish()
-
-if __name__ == '__main__':
-    logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
-                        datefmt="%H:%M:%S", level=logging.INFO)
-    logging.getLogger("Controller").setLevel(logging.ERROR)
-    logging.getLogger("SimplePathFollowingLocalPlanner").setLevel(logging.ERROR)
-    i=0
-    while True:
-        main(i)
-        i += 1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
diff --git a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/config.yaml b/ROAR_gym/wandb/run-20220621_224502-Run 5/files/config.yaml
deleted file mode 100644
index 29b88a8..0000000
--- a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/config.yaml	
+++ /dev/null
@@ -1,297 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F139963788>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.18
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655822702
-    t:
-      1:
-      - 1
-      - 41
-      - 55
-      2:
-      - 1
-      - 41
-      - 55
-      3:
-      - 1
-      - 3
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.18
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DF5CB88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0.0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F07DD13A88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DD87288>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x000001F07DF32888>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655822704.350984
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Run 5
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/diff.patch b/ROAR_gym/wandb/run-20220621_224502-Run 5/files/diff.patch
deleted file mode 100644
index 7d1444a..0000000
--- a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/diff.patch	
+++ /dev/null
@@ -1,154 +0,0 @@
-diff --git a/Bridges/__pycache__/__init__.cpython-37.pyc b/Bridges/__pycache__/__init__.cpython-37.pyc
-index 748c80a..6945bfa 100644
-Binary files a/Bridges/__pycache__/__init__.cpython-37.pyc and b/Bridges/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/Bridges/__pycache__/bridge.cpython-37.pyc b/Bridges/__pycache__/bridge.cpython-37.pyc
-index d31942c..163ceb3 100644
-Binary files a/Bridges/__pycache__/bridge.cpython-37.pyc and b/Bridges/__pycache__/bridge.cpython-37.pyc differ
-diff --git a/Bridges/__pycache__/carla_bridge.cpython-37.pyc b/Bridges/__pycache__/carla_bridge.cpython-37.pyc
-index 2f8c9c7..c27b47d 100644
-Binary files a/Bridges/__pycache__/carla_bridge.cpython-37.pyc and b/Bridges/__pycache__/carla_bridge.cpython-37.pyc differ
-diff --git a/ROAR/__pycache__/__init__.cpython-37.pyc b/ROAR/__pycache__/__init__.cpython-37.pyc
-index 455e188..89d68d0 100644
-Binary files a/ROAR/__pycache__/__init__.cpython-37.pyc and b/ROAR/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc b/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc
-index 84e3be8..8a87e2e 100644
-Binary files a/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/agent_module/__pycache__/agent.cpython-37.pyc b/ROAR/agent_module/__pycache__/agent.cpython-37.pyc
-index 0b1ba9f..49b6a35 100644
-Binary files a/ROAR/agent_module/__pycache__/agent.cpython-37.pyc and b/ROAR/agent_module/__pycache__/agent.cpython-37.pyc differ
-diff --git a/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc b/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc
-index c0ee652..b15ce97 100644
-Binary files a/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc and b/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc differ
-diff --git a/ROAR/configurations/__pycache__/configuration.cpython-37.pyc b/ROAR/configurations/__pycache__/configuration.cpython-37.pyc
-index 9449546..0be15b5 100644
-Binary files a/ROAR/configurations/__pycache__/configuration.cpython-37.pyc and b/ROAR/configurations/__pycache__/configuration.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/__init__.cpython-37.pyc b/ROAR/control_module/__pycache__/__init__.cpython-37.pyc
-index 82c261f..430719b 100644
-Binary files a/ROAR/control_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/control_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/controller.cpython-37.pyc b/ROAR/control_module/__pycache__/controller.cpython-37.pyc
-index 6443e8f..4c185d0 100644
-Binary files a/ROAR/control_module/__pycache__/controller.cpython-37.pyc and b/ROAR/control_module/__pycache__/controller.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc b/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc
-index 391e7bc..d33e01a 100644
-Binary files a/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc and b/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc b/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc
-index 0e2ca63..741d469 100644
-Binary files a/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc and b/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc differ
-diff --git a/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc b/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc
-index c12f588..4b95d18 100644
-Binary files a/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/perception_module/__pycache__/detector.cpython-37.pyc b/ROAR/perception_module/__pycache__/detector.cpython-37.pyc
-index f6e7a5f..9b981ac 100644
-Binary files a/ROAR/perception_module/__pycache__/detector.cpython-37.pyc and b/ROAR/perception_module/__pycache__/detector.cpython-37.pyc differ
-diff --git a/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc b/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc
-index d9da805..59ca4f5 100644
-Binary files a/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc and b/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc
-index 62e6f0c..d12d9b1 100644
-Binary files a/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc b/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc
-index dad5d0d..4359878 100644
-Binary files a/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc and b/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc
-index 7bc0045..97e7e25 100644
-Binary files a/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc b/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc
-index 174b209..e379bfb 100644
-Binary files a/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc and b/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc
-index 19daef3..cc05083 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc
-index 54bd8f0..28bf7ed 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc
-index 9b54d47..cc6755f 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc
-index f666feb..cb597cd 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc
-index e339030..101f2a2 100644
-Binary files a/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc b/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc
-index 3cf685f..d33614d 100644
-Binary files a/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc and b/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc b/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc
-index 0250514..54573e9 100644
-Binary files a/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc and b/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc b/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc
-index 00ab4de..e82ade8 100644
-Binary files a/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc b/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc
-index 86f93dc..221b205 100644
-Binary files a/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc b/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc
-index d636bc0..58a5a70 100644
-Binary files a/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc b/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc
-index d7e8cad..0c8dd30 100644
-Binary files a/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/module.cpython-37.pyc b/ROAR/utilities_module/__pycache__/module.cpython-37.pyc
-index 1c8adb5..c6fc09d 100644
-Binary files a/ROAR/utilities_module/__pycache__/module.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/module.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc b/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc
-index 6e2c1e3..5744478 100644
-Binary files a/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc b/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc
-index 7341979..dbdb981 100644
-Binary files a/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc b/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc
-index 1152170..612c420 100644
-Binary files a/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc differ
-diff --git a/ROAR_Sim/__pycache__/__init__.cpython-37.pyc b/ROAR_Sim/__pycache__/__init__.cpython-37.pyc
-index 717c785..56330d4 100644
-Binary files a/ROAR_Sim/__pycache__/__init__.cpython-37.pyc and b/ROAR_Sim/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc b/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc
-index ad18fd4..5d4255f 100644
-Binary files a/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc and b/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc b/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc
-index 34f7870..ec9ba16 100644
-Binary files a/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc and b/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc
-index cab1782..565b192 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc
-index e5483e6..a515167 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc
-index 67f0c8a..4bae8a1 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc
-index a98bf88..f4a3fa9 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc
-index 15303f6..16733de 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc
-index a3db8ca..6e26563 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc differ
-diff --git a/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc b/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc
-index 683efc4..4bf0e9c 100644
-Binary files a/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc and b/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc differ
-diff --git a/ROAR_gym/configurations/wandb_configuration.json b/ROAR_gym/configurations/wandb_configuration.json
-index 80dc65d..6083b9b 100644
---- a/ROAR_gym/configurations/wandb_configuration.json
-+++ b/ROAR_gym/configurations/wandb_configuration.json
-@@ -1 +1 @@
--{"run_id": "Run 5", "name": "", "project_name": "Full_Control", "entity": "roar"}
-\ No newline at end of file
-+{"run_id": "Run 5", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
-\ No newline at end of file
-diff --git a/ROAR_gym/e2eModel.py b/ROAR_gym/e2eModel.py
-index f0a3788..0016e12 100644
---- a/ROAR_gym/e2eModel.py
-+++ b/ROAR_gym/e2eModel.py
-@@ -157,7 +157,7 @@ def wandb_run_init(wandb_hp_config, load=False, requested_run_id=None, use_rando
- 
-     # Create a wandb run variable
-     wandb.tensorboard.patch(
--        tensorboardX=False,
-+        tensorboard_x=False,
-         pytorch=True,
-     )
-     run = wandb.init(
diff --git a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/requirements.txt b/ROAR_gym/wandb/run-20220621_224502-Run 5/files/requirements.txt
deleted file mode 100644
index 6be37cb..0000000
--- a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/requirements.txt	
+++ /dev/null
@@ -1,129 +0,0 @@
-absl-py==1.1.0
-anyio==3.6.1
-argon2-cffi-bindings==21.2.0
-argon2-cffi==21.3.0
-attrs==21.4.0
-babel==2.10.1
-backcall==0.2.0
-beautifulsoup4==4.11.1
-bleach==5.0.0
-cachetools==5.2.0
-carla==0.9.10
-certifi==2022.5.18.1
-cffi==1.15.0
-charset-normalizer==2.0.12
-click==8.1.3
-cloudpickle==2.1.0
-colorama==0.4.4
-cycler==0.11.0
-debugpy==1.6.0
-decorator==5.1.1
-defusedxml==0.7.1
-deprecation==2.1.0
-docker-pycreds==0.4.0
-entrypoints==0.4
-fastjsonschema==2.15.3
-fonttools==4.33.3
-gitdb==4.0.9
-gitpython==3.1.27
-google-auth-oauthlib==0.4.6
-google-auth==2.7.0
-grpcio==1.46.3
-gym-notices==0.0.7
-gym==0.21.0
-idna==3.3
-importlib-metadata==4.11.4
-importlib-resources==5.7.1
-ipykernel==6.13.1
-ipython-genutils==0.2.0
-ipython==7.34.0
-ipywidgets==7.7.0
-jedi==0.18.1
-jinja2==3.1.2
-json5==0.9.8
-jsonschema==4.6.0
-jupyter-client==7.3.4
-jupyter-core==4.10.0
-jupyter-packaging==0.12.1
-jupyter-server==1.17.1
-jupyterlab-pygments==0.2.2
-jupyterlab-server==2.14.0
-jupyterlab-widgets==1.1.0
-jupyterlab==3.4.3
-kiwisolver==1.4.2
-markdown==3.3.7
-markupsafe==2.1.1
-matplotlib-inline==0.1.3
-matplotlib==3.5.2
-mistune==0.8.4
-nbclassic==0.3.7
-nbclient==0.6.4
-nbconvert==6.5.0
-nbformat==5.4.0
-nest-asyncio==1.5.5
-notebook-shim==0.1.0
-notebook==6.4.12
-numpy==1.21.6
-oauthlib==3.2.0
-open3d==0.15.1
-packaging==21.3
-pandas==1.3.5
-pandocfilters==1.5.0
-parso==0.8.3
-pathtools==0.1.2
-pickleshare==0.7.5
-pillow==9.1.1
-pip==20.1.1
-prometheus-client==0.14.1
-promise==2.3
-prompt-toolkit==3.0.29
-protobuf==3.19.4
-psutil==5.9.1
-pyasn1-modules==0.2.8
-pyasn1==0.4.8
-pycparser==2.21
-pydantic==1.9.1
-pygame==2.1.2
-pygments==2.12.0
-pyparsing==3.0.9
-pyrsistent==0.18.1
-python-dateutil==2.8.2
-pytz==2022.1
-pywin32==304
-pywinpty==2.0.5
-pyyaml==6.0
-pyzmq==23.1.0
-requests-oauthlib==1.3.1
-requests==2.28.0
-rsa==4.8
-scipy==1.7.3
-send2trash==1.8.0
-sentry-sdk==1.5.12
-setproctitle==1.2.3
-setuptools==47.1.0
-shortuuid==1.0.9
-six==1.16.0
-smmap==5.0.0
-sniffio==1.2.0
-soupsieve==2.3.2.post1
-stable-baselines3==1.5.0
-tensorboard-data-server==0.6.1
-tensorboard-plugin-wit==1.8.1
-tensorboard==2.9.1
-terminado==0.15.0
-tinycss2==1.1.1
-tomlkit==0.11.0
-torch==1.11.0
-torchvision==0.12.0
-tornado==6.1
-traitlets==5.2.2.post1
-typing-extensions==4.2.0
-urllib3==1.26.9
-wandb==0.12.18
-wcwidth==0.2.5
-webencodings==0.5.1
-websocket-client==1.3.2
-werkzeug==2.1.2
-wheel==0.37.1
-widgetsnbextension==3.6.0
-zipp==3.8.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/wandb-metadata.json b/ROAR_gym/wandb/run-20220621_224502-Run 5/files/wandb-metadata.json
deleted file mode 100644
index 152ac63..0000000
--- a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/wandb-metadata.json	
+++ /dev/null
@@ -1,24 +0,0 @@
-{
-    "os": "Windows-10-10.0.22000-SP0",
-    "python": "3.7.9",
-    "heartbeatAt": "2022-06-21T14:45:03.603935",
-    "startedAt": "2022-06-21T14:45:02.258790",
-    "docker": null,
-    "gpu": "NVIDIA GeForce RTX 3080",
-    "gpu_count": 1,
-    "cpu_count": 20,
-    "cuda": null,
-    "args": [],
-    "state": "running",
-    "program": "e2eModel.py",
-    "codePath": "ROAR_Gym\\e2eModel.py",
-    "git": {
-        "remote": "https://github.com/FranardoHuang/ROAR",
-        "commit": "2e26a2b6e3f41d0ee21deb73c44a37983206fa5b"
-    },
-    "email": "1745500559@qq.com",
-    "root": "D:/Programming/Subjects/ROAR/ROAR_RL",
-    "host": "Windys-Desktop",
-    "username": "cxcyh",
-    "executable": "C:\\Program Files\\Python\\Python37\\python.exe"
-}
diff --git a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_224502-Run 5/files/wandb-summary.json
deleted file mode 100644
index c72388e..0000000
--- a/ROAR_gym/wandb/run-20220621_224502-Run 5/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"Episode reward": -283.2, "Checkpoint reached": 90, "largest_steps": 94, "highest_speed": 74.65673070726874, "Episode_Sim_Time": 400, "episode Highspeed": 55.530553036706245, "avg10_checkpoints": 65.0, "avg10_score": -265.9833333333333, "_timestamp": 1655822716, "_runtime": 14, "_step": 3, "_wandb": {"runtime": 14}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_224502-Run 5/run-Run 5.wandb b/ROAR_gym/wandb/run-20220621_224502-Run 5/run-Run 5.wandb
deleted file mode 100644
index d8b4f47..0000000
Binary files a/ROAR_gym/wandb/run-20220621_224502-Run 5/run-Run 5.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_225407-Run 5/files/config.yaml b/ROAR_gym/wandb/run-20220621_225407-Run 5/files/config.yaml
deleted file mode 100644
index 7a33560..0000000
--- a/ROAR_gym/wandb/run-20220621_225407-Run 5/files/config.yaml	
+++ /dev/null
@@ -1,298 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F139963788>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.12
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655823247
-    t:
-      1:
-      - 1
-      - 41
-      - 55
-      2:
-      - 1
-      - 41
-      - 55
-      3:
-      - 1
-      - 3
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.12
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DF5CB88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F07DD13A88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DD87288>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x000001F07DF32888>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655822704.350984
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Run 5
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_225407-Run 5/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_225407-Run 5/files/wandb-summary.json
deleted file mode 100644
index 79c7186..0000000
--- a/ROAR_gym/wandb/run-20220621_225407-Run 5/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_timestamp": 1655823260, "avg10_score": -271.6166666666666, "largest_steps": 125, "Episode reward": -269.55, "Episode_Sim_Time": 400, "Checkpoint reached": 45, "_runtime": 29, "avg10_checkpoints": 85.0, "episode Highspeed": 46.99053533229937, "_step": 7, "highest_speed": 86.3693476181035, "_wandb": {"runtime": 27}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_225407-Run 5/run-Run 5.wandb b/ROAR_gym/wandb/run-20220621_225407-Run 5/run-Run 5.wandb
deleted file mode 100644
index 19c8640..0000000
Binary files a/ROAR_gym/wandb/run-20220621_225407-Run 5/run-Run 5.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_230254-Run 5/files/config.yaml b/ROAR_gym/wandb/run-20220621_230254-Run 5/files/config.yaml
deleted file mode 100644
index a7825e8..0000000
--- a/ROAR_gym/wandb/run-20220621_230254-Run 5/files/config.yaml	
+++ /dev/null
@@ -1,298 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F139963788>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.12
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655823775
-    t:
-      1:
-      - 1
-      - 41
-      - 55
-      2:
-      - 1
-      - 41
-      - 55
-      3:
-      - 1
-      - 3
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.12
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DF5CB88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F07DD13A88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DD87288>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x000001F07DF32888>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655822704.350984
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Run 5
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_230254-Run 5/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_230254-Run 5/files/wandb-summary.json
deleted file mode 100644
index 594aa0a..0000000
--- a/ROAR_gym/wandb/run-20220621_230254-Run 5/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_runtime": 44, "highest_speed": 86.3693476181035, "Episode_Sim_Time": 400, "episode Highspeed": 46.99053533229937, "Checkpoint reached": 45, "_step": 11, "_timestamp": 1655823788, "avg10_score": -271.6166666666666, "largest_steps": 125, "Episode reward": -269.55, "avg10_checkpoints": 85.0, "_wandb": {"runtime": 40}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_230254-Run 5/run-Run 5.wandb b/ROAR_gym/wandb/run-20220621_230254-Run 5/run-Run 5.wandb
deleted file mode 100644
index d1526b9..0000000
Binary files a/ROAR_gym/wandb/run-20220621_230254-Run 5/run-Run 5.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_230738-Run 5/files/config.yaml b/ROAR_gym/wandb/run-20220621_230738-Run 5/files/config.yaml
deleted file mode 100644
index d7f0ee7..0000000
--- a/ROAR_gym/wandb/run-20220621_230738-Run 5/files/config.yaml	
+++ /dev/null
@@ -1,296 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F139963788>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.12
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655824058
-    t:
-      1:
-      - 1
-      - 41
-      - 55
-      2:
-      - 1
-      - 41
-      - 55
-      3:
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.12
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DF5CB88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F07DD13A88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DD87288>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x000001F07DF32888>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655822704.350984
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Run 5
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_230738-Run 5/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_230738-Run 5/files/wandb-summary.json
deleted file mode 100644
index 6cf7e07..0000000
--- a/ROAR_gym/wandb/run-20220621_230738-Run 5/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"Checkpoint reached": 45, "_step": 11, "Episode reward": -269.55, "highest_speed": 86.3693476181035, "largest_steps": 125, "Episode_Sim_Time": 400, "avg10_checkpoints": 85, "episode Highspeed": 46.99053533229937, "_runtime": 44, "_timestamp": 1655823788, "avg10_score": -271.6166666666666, "_wandb": {"runtime": 50}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_230738-Run 5/run-Run 5.wandb b/ROAR_gym/wandb/run-20220621_230738-Run 5/run-Run 5.wandb
deleted file mode 100644
index 4eca650..0000000
Binary files a/ROAR_gym/wandb/run-20220621_230738-Run 5/run-Run 5.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/config.yaml b/ROAR_gym/wandb/run-20220621_230802-Run 5/files/config.yaml
deleted file mode 100644
index 9d7c448..0000000
--- a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/config.yaml	
+++ /dev/null
@@ -1,298 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F139963788>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.12
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655824082
-    t:
-      1:
-      - 1
-      - 41
-      - 55
-      2:
-      - 1
-      - 41
-      - 55
-      3:
-      - 1
-      - 3
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.12
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DF5CB88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F07DD13A88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F07DD87288>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x000001F07DF32888>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655822704.350984
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Run 5
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/events.out.tfevents.1655824085.Windys-Desktop.14588.0 b/ROAR_gym/wandb/run-20220621_230802-Run 5/files/events.out.tfevents.1655824085.Windys-Desktop.14588.0
deleted file mode 120000
index dce75c8..0000000
--- a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/events.out.tfevents.1655824085.Windys-Desktop.14588.0	
+++ /dev/null
@@ -1 +0,0 @@
-D:/Programming/Subjects/ROAR/ROAR_RL/ROAR_Gym/runs/Run 5/PPO_0/events.out.tfevents.1655824085.Windys-Desktop.14588.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/model.zip b/ROAR_gym/wandb/run-20220621_230802-Run 5/files/model.zip
deleted file mode 120000
index cd5daaa..0000000
--- a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/model.zip	
+++ /dev/null
@@ -1 +0,0 @@
-D:/Programming/Subjects/ROAR/ROAR_RL/ROAR_Gym/models/Run 5/model.zip
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_230802-Run 5/files/wandb-summary.json
deleted file mode 100644
index 908c9a1..0000000
--- a/ROAR_gym/wandb/run-20220621_230802-Run 5/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"Checkpoint reached": 60, "_runtime": 256, "avg10_score": -266.3590909090909, "highest_speed": 92.07593623954308, "largest_steps": 146, "Episode reward": -264.8, "avg10_checkpoints": 66.81818181818181, "_step": 95, "_timestamp": 1655824280, "Episode_Sim_Time": 400, "episode Highspeed": 68.5799983870569, "_wandb": {"runtime": 249}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_230802-Run 5/run-Run 5.wandb b/ROAR_gym/wandb/run-20220621_230802-Run 5/run-Run 5.wandb
deleted file mode 100644
index fc37fba..0000000
Binary files a/ROAR_gym/wandb/run-20220621_230802-Run 5/run-Run 5.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/code/ROAR_Gym/e2eModel.py b/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/code/ROAR_Gym/e2eModel.py
deleted file mode 100644
index 0016e12..0000000
--- a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/code/ROAR_Gym/e2eModel.py	
+++ /dev/null
@@ -1,352 +0,0 @@
-"""
-IMPORTANT
-IF YOU HAVE NOT RUN THIS FILE AS 'ADMIN' (OR OPENED PYCHARM AS 'ADMIN')
-STOP AND RESTART WITH ADMIN PRIVILEGES
-
-TODO: Before Running this file make the following changes:
-1. Add the following line:
-    self._last_obs = np.nan_to_num(self._last_obs)
-
-to the following file:
-    ROAR\venv\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py
-
-2. Add this line after line 167 such that:
-with th.no_grad():
-    # Convert to pytorch tensor or to TensorDict
-    self._last_obs = np.nan_to_num(self._last_obs)
-    obs_tensor = obs_as_tensor(self._last_obs, self.device)
-    actions, values, log_probs = self.policy.forward(obs_tensor)
-
-3. Add: #############################################################################still needed?###########
-
-        data.pop('_last_obs')
-
-    in  line 652 of base_class.py for sb3
-    possible location of file: \envs\ROAR\Lib\site-packages\stable_baselines3\common\base_class.py
-
-4. Change for on_policy_algorithm.py, in function collect_rollouts add:
-
-        self.env.reset()
-
-    before the following while loop:
-
-        while n_steps < n_rollout_steps:
-"""
-
-# IMPORTS
-# imports for logs and warnings
-import warnings
-import logging
-
-from typing import Optional, Dict
-
-# imports for weights and biases integration
-import wandb
-from wandb.integration.sb3 import WandbCallback
-
-# imports for file path handling
-import os
-import sys
-from pathlib import Path
-sys.path.append(Path(os.getcwd()).parent.as_posix())
-
-# imports for reading and writing json config files
-import json
-
-# imports from the ROAR module
-from ROAR_Sim.configurations.configuration import Configuration as CarlaConfig
-from ROAR.configurations.configuration import Configuration as AgentConfig
-from ROAR.agent_module.agent import Agent
-from ROAR.agent_module.rl_e2e_ppo_agent import RLe2ePPOAgent
-from ROAR.agent_module.forward_only_agent import ForwardOnlyAgent   # testing stuff
-
-# imports for reinforcement learning
-import gym
-import torch as th
-from stable_baselines3.ppo.ppo import PPO
-from stable_baselines3.ppo.policies import CnnPolicy
-from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps, CallbackList, BaseCallback
-from stable_baselines3.common.monitor import Monitor
-from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder
-
-
-# imports for helper functions and torch cnn models
-from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN
-
-
-
-# imports from config files
-from configurations.ppo_configuration import PPO_params, misc_params, wandb_saves
-agent_config = AgentConfig.parse_file(Path("configurations/agent_configuration.json"))
-carla_config = CarlaConfig.parse_file(Path("configurations/carla_configuration.json"))
-
-# Setup for the loggers
-logging.getLogger("tensorflow").setLevel(logging.ERROR)
-logging.getLogger("numpy").setLevel(logging.ERROR)
-warnings.filterwarnings('ignore')
-try:
-    from ROAR_Gym.envs.roar_env import LoggingCallback
-except:
-    from ROAR_Gym.ROAR_Gym.envs.roar_env import LoggingCallback
-
-# os.environ["CUDA_VISIBLE_DEVICES"]="0,1"
-#  Parameters & Constants
-CUDA_VISIBLE_DEVICES = 1
-RUN_FPS = misc_params["run_fps"]
-MODEL_DIR = misc_params["model_directory"]
-WANDB_CONFIG_DIR = "configurations/wandb_configuration.json"
-
-
-def json_read_write(file, load_var=None, mode='r'):
-    """
-
-    Args:
-        file: address of json file to be loaded
-        load_var: variable to be written to, or read from
-        mode: 'r' to read from json, 'w' to write to json
-
-    Returns:
-        load_var: variable with data that has been read in mode 'r'
-                  original variable in case of 'w'
-
-    """
-    if mode == 'r':
-        with open(file, mode) as json_file:
-            load_var = json.load(json_file)  # Reading the file
-            print(f"{file} json config read successful")
-            json_file.close()
-            return load_var
-    elif mode == 'w':
-        assert load_var is not None, "load_var was None"
-        with open(file, mode) as json_file:
-            json.dump(load_var, json_file)  # Writing to the file
-            print(f"{file} json config write successful")
-            json_file.close()
-            return load_var
-    else:
-        assert mode == 'w' or 'r', f"unsupported mode type: {mode}"
-        return None
-
-# TODO track previously used run IDs
-def wandb_run_init(wandb_hp_config, load=False, requested_run_id=None, use_random_id=False):
-
-    wandb_config = json_read_write(
-        file=WANDB_CONFIG_DIR,
-        mode='r',
-    )
-
-    if load is True:
-        # Load run_id from the config file
-        run_id = wandb_config["run_id"]
-        assert run_id != "", "Run ID not set even though previous run exists"
-    else:
-        # Create wandb run id
-        if requested_run_id is not None:
-            run_id = requested_run_id
-        else:
-            assert use_random_id is True, "RUN ID NOT SET FOR NEW RUN"
-            run_id = wandb.util.generate_id()
-
-        # Store run_id to wandb_configuration file
-        wandb_config["run_id"] = run_id
-        wandb_config = json_read_write(
-            file=WANDB_CONFIG_DIR,
-            load_var=wandb_config,
-            mode='w',
-        )
-
-    # Create a wandb run variable
-    wandb.tensorboard.patch(
-        tensorboard_x=False,
-        pytorch=True,
-    )
-    run = wandb.init(
-        project=wandb_config["project_name"],
-        entity=wandb_config["entity"],  # Change to whoever wants to log the data
-        config=wandb_hp_config,
-        # sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics
-        save_code=True,  # Allows us to check diff of code between runs
-        resume="allow",
-        # magic=True,
-        id=run_id,
-        name=run_id,
-        #monitor_gym=True,  # auto-upload the videos of agents playing the game,
-    )
-
-    return run
-
-
-class Tensorboard_Faster_Logger(BaseCallback):
-    """
-    Callback for saving a model (the check is done every ``check_freq`` steps)
-    based on the training reward (in practice, we recommend using ``EvalCallback``).
-
-    :param check_freq:
-    :param log_dir: Path to the folder where the model will be saved.
-      It must contains the file created by the ``Monitor`` wrapper.
-    :param verbose: Verbosity level.
-    """
-    def __init__(self, check_freq: int, verbose: int = 1):
-        super(Tensorboard_Faster_Logger, self).__init__(verbose)
-        self.check_freq = check_freq
-
-    # def _init_callback(self) -> None:
-
-    def _on_step(self) -> bool:
-        if self.n_calls % self.check_freq == 0:
-            self.logger.dump(self.num_timesteps)
-        return True
-
-
-def main(pass_num):
-    # Create the gym environment using the configs
-    env = gym.make(
-        id=misc_params["env_name"],
-        params={
-            "agent_config": agent_config,
-            "carla_config": carla_config,
-            "ego_agent_class": RLe2ePPOAgent,
-        }
-    )
-    #print(th.cuda.is_available())
-
-    # Setting the feature extract or based on the environment mode
-    if env.mode == 'baseline':
-        policy_kwargs = dict(
-            features_extractor_class=Atari_PPO_Adapted_CNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-    else:
-        policy_kwargs = dict(
-            features_extractor_class=CustomMaxPoolCNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-
-    # training kwargs for PPO init
-    training_kwargs = PPO_params
-
-    # wandb config for current run hyper-parameters
-    wandb_hp_config = {
-        "policy_type": "CnnPolicy",
-        "env_name": misc_params["env_name"],
-        "training_kwargs": training_kwargs,
-    }
-
-    # Try to find latest model path if we have trained previously
-    latest_model_path = find_latest_model(MODEL_DIR)
-    print(latest_model_path)
-    # FIXME wandb may continue old run if the run crashes before it is logged
-    if latest_model_path is None:
-        # Create new wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=False,
-            requested_run_id=misc_params["run_name"],
-        )
-
-        # Create model with tensorboard log
-        model = PPO(
-            CnnPolicy,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs
-        )
-
-        print(f"Starting new run {run.id}")
-    else:
-        # Load wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=True,
-        )
-
-        # Load the model
-        model = PPO.load(
-            latest_model_path,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs,
-        )
-
-        print(f"Loading old run {run.id}")
-
-    print("Model Loaded Successfully")
-
-    # Defining Callback Functions
-
-    logging_callback = LoggingCallback(model=model)
-
-    faster_Logging_Callback = Tensorboard_Faster_Logger(check_freq=wandb_saves["model_save_freq"])
-
-    checkpoint_callback = CheckpointCallback(
-        save_freq=wandb_saves["model_save_freq"],
-        verbose=2,
-        save_path=(MODEL_DIR / "logs").as_posix()
-    )
-
-    event_callback = EveryNTimesteps(
-        n_steps=wandb_saves["model_save_freq"],
-        callback=checkpoint_callback
-    )
-
-    wandb_callback = WandbCallback(
-        verbose=2,
-        model_save_path=f"models/{run.id}",
-        gradient_save_freq=PPO_params["n_steps"],
-        model_save_freq=wandb_saves["model_save_freq"],
-    )
-
-    callbacks = CallbackList([
-        wandb_callback,
-        checkpoint_callback,
-        event_callback,
-        logging_callback
-        # faster_Logging_Callback
-    ])
-
-    # Begin learning
-    model = model.learn(
-        total_timesteps=misc_params["total_timesteps"],
-        callback=callbacks,
-        reset_num_timesteps=False,
-        # tb_log_name=wandb_config["run_id"],
-    )
-
-    # Save Model
-    model.save(MODEL_DIR / f"roar_e2e_model_{pass_num}")  # TODO fix naming convention
-    print("Successful Save!")
-    # # Finish wandb run
-    # run.finish()
-
-if __name__ == '__main__':
-    logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
-                        datefmt="%H:%M:%S", level=logging.INFO)
-    logging.getLogger("Controller").setLevel(logging.ERROR)
-    logging.getLogger("SimplePathFollowingLocalPlanner").setLevel(logging.ERROR)
-    i=0
-    while True:
-        main(i)
-        i += 1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
diff --git a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/config.yaml
deleted file mode 100644
index f734068..0000000
--- a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/config.yaml	
+++ /dev/null
@@ -1,49 +0,0 @@
-wandb_version: 1
-
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.12
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655824436
-    t:
-      1:
-      - 1
-      - 41
-      - 55
-      2:
-      - 1
-      - 41
-      - 55
-      3:
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.12
-      8:
-      - 3
-      - 5
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-policy_type:
-  desc: null
-  value: CnnPolicy
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
diff --git a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/diff.patch b/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/diff.patch
deleted file mode 100644
index e0e5a32..0000000
--- a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/diff.patch	
+++ /dev/null
@@ -1,169 +0,0 @@
-diff --git a/Bridges/__pycache__/__init__.cpython-37.pyc b/Bridges/__pycache__/__init__.cpython-37.pyc
-index 748c80a..6945bfa 100644
-Binary files a/Bridges/__pycache__/__init__.cpython-37.pyc and b/Bridges/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/Bridges/__pycache__/bridge.cpython-37.pyc b/Bridges/__pycache__/bridge.cpython-37.pyc
-index d31942c..163ceb3 100644
-Binary files a/Bridges/__pycache__/bridge.cpython-37.pyc and b/Bridges/__pycache__/bridge.cpython-37.pyc differ
-diff --git a/Bridges/__pycache__/carla_bridge.cpython-37.pyc b/Bridges/__pycache__/carla_bridge.cpython-37.pyc
-index 2f8c9c7..c27b47d 100644
-Binary files a/Bridges/__pycache__/carla_bridge.cpython-37.pyc and b/Bridges/__pycache__/carla_bridge.cpython-37.pyc differ
-diff --git a/ROAR/__pycache__/__init__.cpython-37.pyc b/ROAR/__pycache__/__init__.cpython-37.pyc
-index 455e188..89d68d0 100644
-Binary files a/ROAR/__pycache__/__init__.cpython-37.pyc and b/ROAR/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc b/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc
-index 84e3be8..8a87e2e 100644
-Binary files a/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/agent_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/agent_module/__pycache__/agent.cpython-37.pyc b/ROAR/agent_module/__pycache__/agent.cpython-37.pyc
-index 0b1ba9f..49b6a35 100644
-Binary files a/ROAR/agent_module/__pycache__/agent.cpython-37.pyc and b/ROAR/agent_module/__pycache__/agent.cpython-37.pyc differ
-diff --git a/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc b/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc
-index c0ee652..b15ce97 100644
-Binary files a/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc and b/ROAR/agent_module/__pycache__/pure_pursuit_agent.cpython-37.pyc differ
-diff --git a/ROAR/configurations/__pycache__/configuration.cpython-37.pyc b/ROAR/configurations/__pycache__/configuration.cpython-37.pyc
-index 9449546..0be15b5 100644
-Binary files a/ROAR/configurations/__pycache__/configuration.cpython-37.pyc and b/ROAR/configurations/__pycache__/configuration.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/__init__.cpython-37.pyc b/ROAR/control_module/__pycache__/__init__.cpython-37.pyc
-index 82c261f..430719b 100644
-Binary files a/ROAR/control_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/control_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/controller.cpython-37.pyc b/ROAR/control_module/__pycache__/controller.cpython-37.pyc
-index 6443e8f..4c185d0 100644
-Binary files a/ROAR/control_module/__pycache__/controller.cpython-37.pyc and b/ROAR/control_module/__pycache__/controller.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc b/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc
-index 391e7bc..d33e01a 100644
-Binary files a/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc and b/ROAR/control_module/__pycache__/pid_controller.cpython-37.pyc differ
-diff --git a/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc b/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc
-index 0e2ca63..741d469 100644
-Binary files a/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc and b/ROAR/control_module/__pycache__/pure_pursuit_control.cpython-37.pyc differ
-diff --git a/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc b/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc
-index c12f588..4b95d18 100644
-Binary files a/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/perception_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/perception_module/__pycache__/detector.cpython-37.pyc b/ROAR/perception_module/__pycache__/detector.cpython-37.pyc
-index f6e7a5f..9b981ac 100644
-Binary files a/ROAR/perception_module/__pycache__/detector.cpython-37.pyc and b/ROAR/perception_module/__pycache__/detector.cpython-37.pyc differ
-diff --git a/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc b/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc
-index d9da805..59ca4f5 100644
-Binary files a/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc and b/ROAR/perception_module/__pycache__/obstacle_from_depth.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc
-index 62e6f0c..d12d9b1 100644
-Binary files a/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc b/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc
-index dad5d0d..4359878 100644
-Binary files a/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc and b/ROAR/planning_module/__pycache__/abstract_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc
-index 7bc0045..97e7e25 100644
-Binary files a/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/behavior_planner/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc b/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc
-index 174b209..e379bfb 100644
-Binary files a/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc and b/ROAR/planning_module/behavior_planner/__pycache__/behavior_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc
-index 19daef3..cc05083 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc
-index 54bd8f0..28bf7ed 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/local_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc
-index 9b54d47..cc6755f 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/loop_simple_waypoint_following_local_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc b/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc
-index f666feb..cb597cd 100644
-Binary files a/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc and b/ROAR/planning_module/local_planner/__pycache__/simple_waypoint_following_local_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc b/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc
-index e339030..101f2a2 100644
-Binary files a/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc and b/ROAR/planning_module/mission_planner/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc b/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc
-index 3cf685f..d33614d 100644
-Binary files a/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc and b/ROAR/planning_module/mission_planner/__pycache__/mission_planner.cpython-37.pyc differ
-diff --git a/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc b/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc
-index 0250514..54573e9 100644
-Binary files a/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc and b/ROAR/planning_module/mission_planner/__pycache__/waypoint_following_mission_planner.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc b/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc
-index 00ab4de..e82ade8 100644
-Binary files a/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc b/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc
-index 86f93dc..221b205 100644
-Binary files a/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/camera_models.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc b/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc
-index d636bc0..58a5a70 100644
-Binary files a/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/data_structures_models.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc b/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc
-index d7e8cad..0c8dd30 100644
-Binary files a/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/errors.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/module.cpython-37.pyc b/ROAR/utilities_module/__pycache__/module.cpython-37.pyc
-index 1c8adb5..c6fc09d 100644
-Binary files a/ROAR/utilities_module/__pycache__/module.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/module.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc b/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc
-index 6e2c1e3..5744478 100644
-Binary files a/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/occupancy_map.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc b/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc
-index 7341979..dbdb981 100644
-Binary files a/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/utilities.cpython-37.pyc differ
-diff --git a/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc b/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc
-index 1152170..612c420 100644
-Binary files a/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc and b/ROAR/utilities_module/__pycache__/vehicle_models.cpython-37.pyc differ
-diff --git a/ROAR_Sim/__pycache__/__init__.cpython-37.pyc b/ROAR_Sim/__pycache__/__init__.cpython-37.pyc
-index 717c785..56330d4 100644
-Binary files a/ROAR_Sim/__pycache__/__init__.cpython-37.pyc and b/ROAR_Sim/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc b/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc
-index ad18fd4..5d4255f 100644
-Binary files a/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc and b/ROAR_Sim/carla_client/__pycache__/__init__.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc b/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc
-index 34f7870..ec9ba16 100644
-Binary files a/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc and b/ROAR_Sim/carla_client/__pycache__/carla_runner.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc
-index cab1782..565b192 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/camera_manager.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc
-index e5483e6..a515167 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/hud.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc
-index 67f0c8a..4bae8a1 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/keyboard_control.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc
-index a98bf88..f4a3fa9 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/sensors.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc
-index 15303f6..16733de 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/utilities.cpython-37.pyc differ
-diff --git a/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc b/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc
-index a3db8ca..6e26563 100644
-Binary files a/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc and b/ROAR_Sim/carla_client/util/__pycache__/world.cpython-37.pyc differ
-diff --git a/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc b/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc
-index 683efc4..4bf0e9c 100644
-Binary files a/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc and b/ROAR_Sim/configurations/__pycache__/configuration.cpython-37.pyc differ
-diff --git a/ROAR_gym/configurations/ppo_configuration.py b/ROAR_gym/configurations/ppo_configuration.py
-index e1e05ee..17b1310 100644
---- a/ROAR_gym/configurations/ppo_configuration.py
-+++ b/ROAR_gym/configurations/ppo_configuration.py
-@@ -10,8 +10,8 @@ sys.path.append(Path(os.getcwd()).parent.as_posix())
- misc_params = {
-   "env_name": 'roar-e2e-ppo-v0',
-   "run_fps": 8,  # TODO Link to the environment RUN_FPS
--  "model_directory": Path("./output/PPOe2e_Run_5"),
--  "run_name": "Run 5",
-+  "model_directory": Path("./output/Yunhao_PPOe2e_Input_Change"),
-+  "run_name": "Test Run 1",
-   "total_timesteps": int(1e6),
- }
- 
-diff --git a/ROAR_gym/configurations/wandb_configuration.json b/ROAR_gym/configurations/wandb_configuration.json
-index 80dc65d..cfb2610 100644
---- a/ROAR_gym/configurations/wandb_configuration.json
-+++ b/ROAR_gym/configurations/wandb_configuration.json
-@@ -1 +1 @@
--{"run_id": "Run 5", "name": "", "project_name": "Full_Control", "entity": "roar"}
-\ No newline at end of file
-+{"run_id": "Test Run 1", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
-\ No newline at end of file
-diff --git a/ROAR_gym/e2eModel.py b/ROAR_gym/e2eModel.py
-index f0a3788..0016e12 100644
---- a/ROAR_gym/e2eModel.py
-+++ b/ROAR_gym/e2eModel.py
-@@ -157,7 +157,7 @@ def wandb_run_init(wandb_hp_config, load=False, requested_run_id=None, use_rando
- 
-     # Create a wandb run variable
-     wandb.tensorboard.patch(
--        tensorboardX=False,
-+        tensorboard_x=False,
-         pytorch=True,
-     )
-     run = wandb.init(
diff --git a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/requirements.txt b/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/requirements.txt
deleted file mode 100644
index 80a907e..0000000
--- a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/requirements.txt	
+++ /dev/null
@@ -1,128 +0,0 @@
-absl-py==1.1.0
-anyio==3.6.1
-argon2-cffi-bindings==21.2.0
-argon2-cffi==21.3.0
-attrs==21.4.0
-babel==2.10.3
-backcall==0.2.0
-beautifulsoup4==4.11.1
-bleach==5.0.0
-cachetools==5.2.0
-carla==0.9.10
-certifi==2022.6.15
-cffi==1.15.0
-charset-normalizer==2.0.12
-click==8.1.3
-cloudpickle==2.1.0
-colorama==0.4.5
-cycler==0.11.0
-debugpy==1.6.0
-decorator==5.1.1
-defusedxml==0.7.1
-deprecation==2.1.0
-docker-pycreds==0.4.0
-entrypoints==0.4
-fastjsonschema==2.15.3
-fonttools==4.33.3
-gitdb==4.0.9
-gitpython==3.1.27
-google-auth-oauthlib==0.4.6
-google-auth==2.8.0
-grpcio==1.46.3
-gym==0.21.0
-idna==3.3
-importlib-metadata==4.11.4
-importlib-resources==5.8.0
-ipykernel==6.15.0
-ipython-genutils==0.2.0
-ipython==7.34.0
-ipywidgets==7.7.0
-jedi==0.18.1
-jinja2==3.1.2
-json5==0.9.8
-jsonschema==4.6.0
-jupyter-client==7.3.4
-jupyter-core==4.10.0
-jupyter-packaging==0.12.2
-jupyter-server==1.17.1
-jupyterlab-pygments==0.2.2
-jupyterlab-server==2.14.0
-jupyterlab-widgets==1.1.0
-jupyterlab==3.4.3
-kiwisolver==1.4.3
-markdown==3.3.7
-markupsafe==2.1.1
-matplotlib-inline==0.1.3
-matplotlib==3.5.2
-mistune==0.8.4
-nbclassic==0.3.7
-nbclient==0.6.4
-nbconvert==6.5.0
-nbformat==5.4.0
-nest-asyncio==1.5.5
-notebook-shim==0.1.0
-notebook==6.4.12
-numpy==1.21.6
-oauthlib==3.2.0
-open3d==0.15.1
-packaging==21.3
-pandas==1.3.5
-pandocfilters==1.5.0
-parso==0.8.3
-pathtools==0.1.2
-pickleshare==0.7.5
-pillow==9.1.1
-pip==22.1.2
-prometheus-client==0.14.1
-promise==2.3
-prompt-toolkit==3.0.29
-protobuf==3.19.4
-psutil==5.9.1
-pyasn1-modules==0.2.8
-pyasn1==0.4.8
-pycparser==2.21
-pydantic==1.9.1
-pygame==2.1.2
-pygments==2.12.0
-pyparsing==3.0.9
-pyrsistent==0.18.1
-python-dateutil==2.8.2
-pytz==2022.1
-pywin32==304
-pywinpty==2.0.5
-pyyaml==6.0
-pyzmq==23.2.0
-requests-oauthlib==1.3.1
-requests==2.28.0
-rsa==4.8
-scipy==1.7.3
-send2trash==1.8.0
-sentry-sdk==1.5.12
-setproctitle==1.2.3
-setuptools==62.6.0
-shortuuid==1.0.9
-six==1.16.0
-smmap==5.0.0
-sniffio==1.2.0
-soupsieve==2.3.2.post1
-stable-baselines3==1.5.0
-tensorboard-data-server==0.6.1
-tensorboard-plugin-wit==1.8.1
-tensorboard==2.9.1
-terminado==0.15.0
-tinycss2==1.1.1
-tomlkit==0.11.0
-torch==1.11.0
-torchvision==0.12.0
-tornado==6.1
-traitlets==5.3.0
-typing-extensions==4.2.0
-urllib3==1.26.9
-wandb==0.12.12
-wcwidth==0.2.5
-webencodings==0.5.1
-websocket-client==1.3.3
-werkzeug==2.1.2
-wheel==0.37.1
-widgetsnbextension==3.6.0
-zipp==3.8.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/wandb-metadata.json b/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/wandb-metadata.json
deleted file mode 100644
index 3a93295..0000000
--- a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/wandb-metadata.json	
+++ /dev/null
@@ -1,24 +0,0 @@
-{
-    "os": "Windows-10-10.0.22000-SP0",
-    "python": "3.7.9",
-    "heartbeatAt": "2022-06-21T15:13:58.444992",
-    "startedAt": "2022-06-21T15:13:56.390536",
-    "docker": null,
-    "gpu": "NVIDIA GeForce RTX 3080",
-    "gpu_count": 1,
-    "cpu_count": 20,
-    "cuda": null,
-    "args": [],
-    "state": "running",
-    "program": "e2eModel.py",
-    "codePath": "ROAR_Gym\\e2eModel.py",
-    "git": {
-        "remote": "https://github.com/FranardoHuang/ROAR",
-        "commit": "2e26a2b6e3f41d0ee21deb73c44a37983206fa5b"
-    },
-    "email": "1745500559@qq.com",
-    "root": "D:/Programming/Subjects/ROAR/ROAR_RL",
-    "host": "Windys-Desktop",
-    "username": "cxcyh",
-    "executable": "D:\\Programming\\Subjects\\ROAR\\ROAR_RL\\roar-dev\\Scripts\\python.exe"
-}
diff --git a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/wandb-summary.json
deleted file mode 100644
index 8bf99d1..0000000
--- a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 11}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/run-Test Run 1.wandb b/ROAR_gym/wandb/run-20220621_231356-Test Run 1/run-Test Run 1.wandb
deleted file mode 100644
index d32a398..0000000
Binary files a/ROAR_gym/wandb/run-20220621_231356-Test Run 1/run-Test Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/config.yaml
deleted file mode 100644
index c64d2bf..0000000
--- a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/config.yaml	
+++ /dev/null
@@ -1,298 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x0000027E58E878C8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.12
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655824501
-    t:
-      1:
-      - 1
-      - 41
-      - 55
-      2:
-      - 1
-      - 41
-      - 55
-      3:
-      - 1
-      - 3
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.12
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x0000027E591CF948>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0.0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000027E58F61F88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x0000027E27D678B8>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x0000027E591A2D48>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655824503.2783577
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Test Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/events.out.tfevents.1655824504.Windys-Desktop.22624.0 b/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/events.out.tfevents.1655824504.Windys-Desktop.22624.0
deleted file mode 120000
index 03d4596..0000000
--- a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/events.out.tfevents.1655824504.Windys-Desktop.22624.0	
+++ /dev/null
@@ -1 +0,0 @@
-D:/Programming/Subjects/ROAR/ROAR_RL/ROAR_Gym/runs/Test Run 1/PPO_0/events.out.tfevents.1655824504.Windys-Desktop.22624.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/model.zip b/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/model.zip
deleted file mode 120000
index 87b167b..0000000
--- a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/model.zip	
+++ /dev/null
@@ -1 +0,0 @@
-D:/Programming/Subjects/ROAR/ROAR_RL/ROAR_Gym/models/Test Run 1/model.zip
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/wandb-summary.json
deleted file mode 100644
index ad81cef..0000000
--- a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"Episode reward": -269.9, "Checkpoint reached": 60, "largest_steps": 207, "highest_speed": 103.44376296153804, "Episode_Sim_Time": 400, "episode Highspeed": 64.61080347064849, "avg10_checkpoints": 92.72727272727273, "avg10_score": -272.69090909090914, "_timestamp": 1655825389.0130992, "_runtime": 901, "_step": 324, "parameters/log_std": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0010138057405129075, -0.0009782923152670264, -0.0009427788900211453, -0.0009072654647752643, -0.0008717520395293832, -0.0008362386142835021, -0.000800725189037621, -0.0007652117637917399, -0.0007296983385458589, -0.0006941849132999778, -0.0006586714880540967, -0.0006231580628082156, -0.0005876446375623345, -0.0005521312123164535, -0.0005166177870705724, -0.00048110433272086084, -0.0004455908783711493, -0.0004100774531252682, -0.00037456402787938714, -0.00033905060263350606, -0.000303537177387625, -0.0002680237521417439, -0.00023251029779203236, -0.00019699687254615128, -0.00016148341819643974, -0.00012596999295055866, -9.045656042871997e-05, -5.494312790688127e-05, -1.9429702661000192e-05, 1.608372258488089e-05, 5.15971623826772e-05, 8.711058762855828e-05, 0.0001226239837706089, 0.00015813740901648998, 0.00019365083426237106, 0.00022916427406016737, 0.0002646776847541332, 0.0003001911100000143, 0.00033570456434972584, 0.0003712179895956069, 0.00040673138573765755, 0.00044224481098353863, 0.0004777582362294197, 0.0005132716614753008, 0.0005487850867211819, 0.000584298511967063, 0.000619811937212944, 0.0006553253624588251, 0.0006908388459123671, 0.0007263522711582482, 0.0007618656964041293, 0.0007973791216500103, 0.0008328925468958914, 0.0008684059721417725, 0.0009039194555953145, 0.0009394328808411956, 0.0009749463060870767, 0.0010104597313329577, 0.0010459731565788388, 0.00108148658182472, 0.001117000007070601, 0.001152513432316482, 0.0011880268575623631, 0.0012235402828082442, 0.0012590537080541253]}, "parameters/features_extractor.network.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 3.0, 1.0, 3.0, 4.0, 10.0, 14.0, 12.0, 26.0, 40.0, 44.0, 59.0, 97.0, 101.0, 143.0, 170.0, 253.0, 300.0, 361.0, 437.0, 529.0, 609.0, 694.0, 805.0, 865.0, 985.0, 1045.0, 1144.0, 1173.0, 1202.0, 1155.0, 1240.0, 1210.0, 1171.0, 1113.0, 1037.0, 963.0, 863.0, 779.0, 743.0, 629.0, 521.0, 424.0, 349.0, 278.0, 233.0, 181.0, 137.0, 123.0, 82.0, 68.0, 51.0, 32.0, 20.0, 13.0, 11.0, 4.0, 2.0, 8.0, 3.0, 1.0, 1.0, 1.0], "bins": [-0.2031766027212143, -0.19678597152233124, -0.19039534032344818, -0.18400470912456512, -0.17761406302452087, -0.17122343182563782, -0.16483280062675476, -0.1584421694278717, -0.15205153822898865, -0.1456609070301056, -0.13927027583122253, -0.13287964463233948, -0.12648901343345642, -0.12009837478399277, -0.11370773613452911, -0.10731710493564606, -0.100926473736763, -0.09453584253787994, -0.08814521133899689, -0.08175457268953323, -0.07536394149065018, -0.06897331029176712, -0.06258267164230347, -0.05619204044342041, -0.049801409244537354, -0.0434107780456543, -0.03702014312148094, -0.030629510059952736, -0.02423887699842453, -0.017848245799541473, -0.011457610875368118, -0.005066975951194763, 0.0013236552476882935, 0.007714288309216499, 0.014104921370744705, 0.02049555443227291, 0.026886187493801117, 0.033276818692684174, 0.03966745361685753, 0.046058088541030884, 0.05244871973991394, 0.058839350938797, 0.06522998213768005, 0.07162062078714371, 0.07801125198602676, 0.08440188318490982, 0.09079252183437347, 0.09718315303325653, 0.10357378423213959, 0.10996441543102264, 0.1163550466299057, 0.12274568527936935, 0.129136323928833, 0.13552695512771606, 0.14191758632659912, 0.14830821752548218, 0.15469884872436523, 0.1610894799232483, 0.16748011112213135, 0.1738707423210144, 0.18026137351989746, 0.18665200471878052, 0.19304265081882477, 0.19943328201770782, 0.20582391321659088]}, "parameters/features_extractor.network.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0028796992264688015, -0.00267196586355567, -0.002464232500642538, -0.0022564991377294064, -0.0020487657748162746, -0.001841032295487821, -0.0016332988161593676, -0.0014255654532462358, -0.0012178320903331041, -0.0010100987274199724, -0.0008023653062991798, -0.0005946318851783872, -0.00038689852226525545, -0.00017916515935212374, 2.8568319976329803e-05, 0.00023630168288946152, 0.00044403504580259323, 0.0006517684087157249, 0.0008595018298365176, 0.0010672352509573102, 0.001274968613870442, 0.0014827019767835736, 0.0016904354561120272, 0.0018981688190251589, 0.0021059024147689342, 0.002313635777682066, 0.0025213691405951977, 0.0027291025035083294, 0.002936835866421461, 0.003144569229334593, 0.003352302825078368, 0.0035600361879915, 0.0037677697837352753, 0.003975503146648407, 0.004183236509561539, 0.00439096987247467, 0.004598703235387802, 0.004806436598300934, 0.0050141699612140656, 0.005221903324127197, 0.005429636687040329, 0.005637370049953461, 0.005845103412866592, 0.006052836775779724, 0.006260570138692856, 0.0064683035016059875, 0.006676036864519119, 0.006883770227432251, 0.00709150405600667, 0.007299237418919802, 0.007506970781832933, 0.007714704144746065, 0.007922437973320484, 0.008130171336233616, 0.008337904699146748, 0.00854563806205988, 0.008753371424973011, 0.008961104787886143, 0.009168838150799274, 0.009376571513712406, 0.009584304876625538, 0.00979203823953867, 0.009999771602451801, 0.010207504965364933, 0.010415238328278065]}, "parameters/features_extractor.network.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 8.0, 9.0, 18.0, 23.0, 39.0, 50.0, 63.0, 92.0, 101.0, 142.0, 215.0, 233.0, 281.0, 394.0, 466.0, 591.0, 690.0, 786.0, 820.0, 1008.0, 1122.0, 1223.0, 1323.0, 1465.0, 1535.0, 1510.0, 1603.0, 1636.0, 1562.0, 1587.0, 1548.0, 1459.0, 1349.0, 1228.0, 1041.0, 914.0, 885.0, 714.0, 628.0, 515.0, 395.0, 361.0, 270.0, 220.0, 161.0, 148.0, 74.0, 68.0, 44.0, 46.0, 31.0, 21.0, 16.0, 11.0, 5.0, 2.0, 1.0, 7.0], "bins": [-0.2555253207683563, -0.24782463908195496, -0.2401239573955536, -0.23242327570915222, -0.22472257912158966, -0.2170218974351883, -0.20932121574878693, -0.20162053406238556, -0.193919837474823, -0.18621915578842163, -0.17851847410202026, -0.1708177924156189, -0.16311709582805634, -0.15541641414165497, -0.1477157324552536, -0.14001505076885223, -0.13231436908245087, -0.1246136873960495, -0.11691299825906754, -0.10921231657266617, -0.1015116274356842, -0.09381094574928284, -0.08611026406288147, -0.0784095823764801, -0.07070890069007874, -0.06300821900367737, -0.055307529866695404, -0.04760684818029404, -0.03990616276860237, -0.032205477356910706, -0.02450479567050934, -0.016804110258817673, -0.009103432297706604, -0.001402747817337513, 0.006297936663031578, 0.013998620212078094, 0.02169930562376976, 0.029399991035461426, 0.03710067272186279, 0.04480135813355446, 0.05250205099582672, 0.06020273640751839, 0.06790342181921005, 0.07560410350561142, 0.08330479264259338, 0.09100547432899475, 0.09870615601539612, 0.10640683770179749, 0.11410751938819885, 0.12180820107460022, 0.1295088827610016, 0.13720956444740295, 0.14491026103496552, 0.15261094272136688, 0.16031162440776825, 0.16801230609416962, 0.17571300268173218, 0.18341368436813354, 0.1911143660545349, 0.19881504774093628, 0.20651574432849884, 0.2142164260149002, 0.22191710770130157, 0.22961778938770294, 0.2373184710741043]}, "parameters/features_extractor.network.2.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0036541051231324673, -0.003476818324998021, -0.003299531526863575, -0.003122244728729129, -0.0029449579305946827, -0.0027676711324602365, -0.0025903843343257904, -0.0024130975361913443, -0.002235810738056898, -0.002058523939922452, -0.0018812371417880058, -0.0017039503436535597, -0.0015266635455191135, -0.0013493767473846674, -0.0011720899492502213, -0.000994803151115775, -0.000817516352981329, -0.0006402295548468828, -0.0004629427567124367, -0.00028565595857799053, -0.00010836916044354439, 6.891763769090176e-05, 0.0002462044358253479, 0.00042349123395979404, 0.0006007780320942402, 0.0007780648302286863, 0.0009553516283631325, 0.0011326384264975786, 0.0013099252246320248, 0.001487212022766471, 0.001664498820900917, 0.0018417856190353632, 0.0020190724171698093, 0.0021963592153042555, 0.0023736460134387016, 0.0025509328115731478, 0.002728219609707594, 0.00290550640784204, 0.003082793205976486, 0.0032600800041109324, 0.0034373668022453785, 0.0036146536003798246, 0.0037919403985142708, 0.003969226963818073, 0.004146513994783163, 0.004323801025748253, 0.004501087591052055, 0.004678374156355858, 0.004855661187320948, 0.0050329482182860374, 0.00521023478358984, 0.005387521348893642, 0.005564808379858732, 0.005742095410823822, 0.0059193819761276245, 0.006096668541431427, 0.006273955572396517, 0.006451242603361607, 0.006628529168665409, 0.006805815733969212, 0.006983102764934301, 0.007160389795899391, 0.007337676361203194, 0.007514962926506996, 0.007692249957472086]}, "parameters/features_extractor.network.4.weight": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 5.0, 4.0, 5.0, 8.0, 17.0, 29.0, 29.0, 46.0, 74.0, 106.0, 107.0, 191.0, 229.0, 304.0, 404.0, 536.0, 626.0, 700.0, 870.0, 1026.0, 1160.0, 1318.0, 1427.0, 1695.0, 1750.0, 1805.0, 1847.0, 1928.0, 1870.0, 1894.0, 1779.0, 1770.0, 1681.0, 1503.0, 1397.0, 1211.0, 1065.0, 892.0, 741.0, 615.0, 533.0, 398.0, 320.0, 250.0, 212.0, 127.0, 104.0, 80.0, 53.0, 41.0, 30.0, 18.0, 10.0, 4.0, 6.0, 4.0, 1.0, 0.0, 1.0, 3.0, 1.0], "bins": [-0.23849494755268097, -0.2307681441307068, -0.2230413407087326, -0.21531453728675842, -0.20758774876594543, -0.19986093044281006, -0.19213414192199707, -0.1844073385000229, -0.1766805350780487, -0.16895373165607452, -0.16122692823410034, -0.15350012481212616, -0.14577332139015198, -0.138046532869339, -0.1303197294473648, -0.12259292602539062, -0.11486612260341644, -0.10713931918144226, -0.09941251575946808, -0.0916857197880745, -0.08395891636610031, -0.07623211294412613, -0.06850531697273254, -0.06077851355075836, -0.05305171012878418, -0.04532490670681, -0.037598107010126114, -0.02987130545079708, -0.022144503891468048, -0.014417700469493866, -0.006690900772809982, 0.0010358989238739014, 0.008762717247009277, 0.01648951880633831, 0.024216320365667343, 0.03194312006235123, 0.03966992348432541, 0.04739672690629959, 0.055123526602983475, 0.06285032629966736, 0.07057712972164154, 0.07830393314361572, 0.0860307365655899, 0.09375753253698349, 0.10148433595895767, 0.10921113938093185, 0.11693793535232544, 0.12466473877429962, 0.1323915421962738, 0.14011834561824799, 0.14784514904022217, 0.15557195246219635, 0.16329875588417053, 0.17102554440498352, 0.1787523478269577, 0.18647915124893188, 0.19420595467090607, 0.20193275809288025, 0.20965956151485443, 0.2173863649368286, 0.2251131534576416, 0.23283997178077698, 0.24056676030158997, 0.24829356372356415, 0.25602036714553833]}, "parameters/features_extractor.network.4.bias": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 2.0, 3.0, 5.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.0002750238636508584, -0.00019424136553425342, -0.00011345886741764843, -3.267636930104345e-05, 4.810612881556153e-05, 0.00012888864148408175, 0.0002096711250487715, 0.00029045360861346126, 0.00037123612128198147, 0.0004520186339505017, 0.0005328011466190219, 0.0006135836010798812, 0.0006943661137484014, 0.0007751486264169216, 0.0008559310808777809, 0.0009367135935463011, 0.0010174961062148213, 0.0010982785606756806, 0.0011790611315518618, 0.001259843586012721, 0.0013406260404735804, 0.0014214086113497615, 0.0015021910658106208, 0.001582973636686802, 0.0016637560911476612, 0.0017445385456085205, 0.0018253211164847016, 0.001906103570945561, 0.001986886141821742, 0.0020676685962826014, 0.0021484510507434607, 0.00222923350520432, 0.002310016192495823, 0.002390798646956682, 0.0024715811014175415, 0.0025523637887090445, 0.0026331462431699038, 0.002713928697630763, 0.0027947111520916224, 0.0028754936065524817, 0.0029562762938439846, 0.003037058748304844, 0.003117841202765703, 0.003198623890057206, 0.0032794063445180655, 0.0033601887989789248, 0.003440971253439784, 0.0035217537079006433, 0.0036025361623615026, 0.003683318616822362, 0.0037641010712832212, 0.003844883758574724, 0.0039256662130355835, 0.004006448667496443, 0.004087231121957302, 0.004168013576418161, 0.004248796030879021, 0.00432957848533988, 0.004410360939800739, 0.004491143394261599, 0.004571925848722458, 0.0046527087688446045, 0.004733491223305464, 0.004814273677766323, 0.004895056132227182]}, "parameters/features_extractor.network.7.weight": {"_type": "histogram", "values": [2.0, 3.0, 2.0, 11.0, 12.0, 42.0, 55.0, 97.0, 167.0, 254.0, 400.0, 641.0, 964.0, 1372.0, 2107.0, 2959.0, 4102.0, 5500.0, 7571.0, 9820.0, 12364.0, 15495.0, 19248.0, 23167.0, 27032.0, 31379.0, 35255.0, 39028.0, 41930.0, 44667.0, 46138.0, 46455.0, 46345.0, 45026.0, 42768.0, 39405.0, 36540.0, 32476.0, 28443.0, 24235.0, 20039.0, 16514.0, 13396.0, 10558.0, 8199.0, 6113.0, 4571.0, 3281.0, 2200.0, 1508.0, 1044.0, 704.0, 496.0, 276.0, 178.0, 112.0, 55.0, 50.0, 15.0, 18.0, 8.0, 1.0, 1.0, 2.0], "bins": [-0.11672411859035492, -0.11303890496492386, -0.1093536913394928, -0.10566847771406174, -0.10198326408863068, -0.09829805791378021, -0.09461284428834915, -0.09092763066291809, -0.08724241703748703, -0.08355720341205597, -0.07987198978662491, -0.07618677616119385, -0.07250156998634338, -0.06881634891033173, -0.06513114273548126, -0.0614459291100502, -0.05776071548461914, -0.05407550185918808, -0.05039028823375702, -0.04670507833361626, -0.043019864708185196, -0.039334651082754135, -0.03564944118261337, -0.03196422755718231, -0.02827901393175125, -0.02459380030632019, -0.02090858854353428, -0.017223376780748367, -0.013538163155317307, -0.009852949529886246, -0.006167737767100334, -0.0024825260043144226, 0.0012026876211166382, 0.004887900315225124, 0.00857311300933361, 0.012258325703442097, 0.015943538397550583, 0.019628752022981644, 0.023313963785767555, 0.026999175548553467, 0.030684389173984528, 0.03436960279941559, 0.03805481642484665, 0.04174002632498741, 0.04542523995041847, 0.04911045357584953, 0.052795663475990295, 0.056480877101421356, 0.06016609072685242, 0.06385130435228348, 0.06753651797771454, 0.0712217316031456, 0.07490694522857666, 0.07859215140342712, 0.08227736502885818, 0.08596257865428925, 0.0896477922797203, 0.09333300590515137, 0.09701821953058243, 0.10070343315601349, 0.10438863933086395, 0.10807386040687561, 0.11175906658172607, 0.11544428020715714, 0.1191294938325882]}, "parameters/features_extractor.network.7.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 5.0, 4.0, 2.0, 8.0, 14.0, 7.0, 10.0, 12.0, 16.0, 10.0, 6.0, 5.0, 4.0, 1.0, 6.0, 3.0, 2.0, 4.0, 1.0, 3.0, 5.0, 0.0, 3.0, 4.0, 2.0, 2.0, 0.0, 1.0, 7.0, 1.0, 4.0, 3.0, 3.0, 6.0, 5.0, 3.0, 8.0, 8.0, 3.0, 9.0, 11.0, 14.0, 8.0, 6.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0], "bins": [-0.003265947801992297, -0.00317069748416543, -0.0030754473991692066, -0.002980197314172983, -0.002884946996346116, -0.002789696678519249, -0.0026944465935230255, -0.002599196508526802, -0.002503946190699935, -0.002408695872873068, -0.0023134457878768444, -0.002218195702880621, -0.002122945385053754, -0.0020276950672268867, -0.0019324449822306633, -0.001837194780819118, -0.0017419445794075727, -0.0016466943779960275, -0.0015514441765844822, -0.001456193975172937, -0.0013609437737613916, -0.0012656935723498464, -0.001170443370938301, -0.0010751931695267558, -0.0009799429681152105, -0.0008846927667036653, -0.00078944256529212, -0.0006941923638805747, -0.0005989421624690294, -0.0005036919610574841, -0.0004084417596459389, -0.0003131915582343936, -0.00021794135682284832, -0.00012269115541130304, -2.7440953999757767e-05, 6.780924741178751e-05, 0.0001630594488233328, 0.00025830965023487806, 0.00035355985164642334, 0.0004488100530579686, 0.0005440602544695139, 0.0006393104558810592, 0.0007345606572926044, 0.0008298108587041497, 0.000925061060115695, 0.0010203112615272403, 0.0011155614629387856, 0.0012108116643503308, 0.001306061865761876, 0.0014013120671734214, 0.0014965622685849667, 0.001591812469996512, 0.0016870626714080572, 0.0017823128728196025, 0.0018775630742311478, 0.001972813159227371, 0.0020680634770542383, 0.0021633137948811054, 0.002258563879877329, 0.0023538139648735523, 0.0024490642827004194, 0.0025443146005272865, 0.00263956468552351, 0.0027348147705197334, 0.0028300650883466005]}, "parameters/mlp_extractor.policy_net.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 2.0, 2.0, 6.0, 7.0, 13.0, 15.0, 17.0, 30.0, 47.0, 61.0, 83.0, 110.0, 138.0, 185.0, 190.0, 209.0, 273.0, 335.0, 384.0, 483.0, 499.0, 554.0, 611.0, 684.0, 721.0, 747.0, 811.0, 820.0, 779.0, 801.0, 765.0, 735.0, 689.0, 644.0, 577.0, 557.0, 451.0, 423.0, 352.0, 316.0, 287.0, 224.0, 199.0, 147.0, 106.0, 81.0, 51.0, 49.0, 35.0, 30.0, 15.0, 15.0, 7.0, 3.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3382904827594757, -0.32743504643440247, -0.3165796399116516, -0.30572420358657837, -0.2948687970638275, -0.2840133607387543, -0.2731579542160034, -0.2623025178909302, -0.2514471113681793, -0.24059168994426727, -0.22973626852035522, -0.21888084709644318, -0.20802542567253113, -0.19717000424861908, -0.18631458282470703, -0.1754591464996338, -0.16460372507572174, -0.1537483036518097, -0.14289288222789764, -0.1320374608039856, -0.12118203938007355, -0.1103266179561615, -0.09947118908166885, -0.0886157676577568, -0.07776033878326416, -0.06690491735935211, -0.056049495935440063, -0.04519407078623772, -0.03433864936232567, -0.02348322793841362, -0.012627802789211273, -0.0017723813652992249, 0.009083032608032227, 0.019938454031944275, 0.030793877318501472, 0.04164930060505867, 0.05250472202897072, 0.06336013972759247, 0.07421556860208511, 0.08507099002599716, 0.09592640399932861, 0.10678182542324066, 0.11763724684715271, 0.12849266827106476, 0.1393480896949768, 0.15020351111888885, 0.1610589325428009, 0.17191436886787415, 0.1827697902917862, 0.19362521171569824, 0.2044806331396103, 0.21533605456352234, 0.2261914759874344, 0.23704689741134644, 0.24790233373641968, 0.25875774025917053, 0.2696131765842438, 0.280468612909317, 0.29132401943206787, 0.3021794557571411, 0.31303486227989197, 0.3238902986049652, 0.33474570512771606, 0.3456011414527893, 0.35645654797554016]}, "parameters/mlp_extractor.policy_net.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 4.0, 4.0, 4.0, 7.0, 5.0, 2.0, 6.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0002619962324388325, -0.0002556283725425601, -0.0002492605126462877, -0.00024289263819810003, -0.00023652476374991238, -0.00023015690385363996, -0.00022378904395736754, -0.0002174211695091799, -0.00021105330961290747, -0.00020468544971663505, -0.0001983175752684474, -0.00019194971537217498, -0.00018558184092398733, -0.0001792139810277149, -0.00017284610657952726, -0.00016647824668325484, -0.00016011038678698242, -0.00015374252689071, -0.00014737465244252235, -0.00014100679254624993, -0.00013463891809806228, -0.00012827105820178986, -0.00012190319102955982, -0.00011553532385732979, -0.00010916744940914214, -0.0001027995822369121, -9.643171506468207e-05, -9.006385516840965e-05, -8.369598799617961e-05, -7.732812082394958e-05, -7.096025365171954e-05, -6.45923864794895e-05, -5.8224526583217084e-05, -5.185665941098705e-05, -4.548879587673582e-05, -3.9120928704505786e-05, -3.275306517025456e-05, -2.6385197998024523e-05, -2.0017330825794488e-05, -1.364946729154326e-05, -7.281603757292032e-06, -9.137379493040498e-07, 5.4541278586839326e-06, 1.1821994121419266e-05, 1.8189859474659897e-05, 2.455772482790053e-05, 3.0925592000130564e-05, 3.729345553438179e-05, 4.3661326344590634e-05, 5.002919351682067e-05, 5.63970570510719e-05, 6.276492786128074e-05, 6.913278775755316e-05, 7.55006549297832e-05, 8.186852210201323e-05, 8.823638199828565e-05, 9.46042564464733e-05, 0.00010097212361870334, 0.00010733999079093337, 0.00011370785068720579, 0.00012007571785943583, 0.00012644358503166586, 0.0001328114594798535, 0.00013917931937612593, 0.00014554717927239835]}, "parameters/mlp_extractor.policy_net.2.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 5.0, 13.0, 7.0, 20.0, 24.0, 20.0, 49.0, 45.0, 52.0, 56.0, 81.0, 71.0, 98.0, 108.0, 121.0, 137.0, 155.0, 179.0, 165.0, 180.0, 229.0, 204.0, 189.0, 198.0, 192.0, 174.0, 167.0, 157.0, 154.0, 137.0, 125.0, 116.0, 102.0, 79.0, 54.0, 48.0, 44.0, 29.0, 24.0, 18.0, 16.0, 11.0, 7.0, 11.0, 6.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6062250137329102, -0.5846587419509888, -0.5630924105644226, -0.5415261387825012, -0.5199598073959351, -0.49839353561401367, -0.4768272340297699, -0.4552609324455261, -0.43369463086128235, -0.4121283292770386, -0.3905620276927948, -0.368995726108551, -0.34742945432662964, -0.3258631229400635, -0.3042968511581421, -0.2827305495738983, -0.26116424798965454, -0.23959794640541077, -0.218031644821167, -0.1964653581380844, -0.17489905655384064, -0.15333275496959686, -0.13176646828651428, -0.11020016670227051, -0.08863389492034912, -0.06706759333610535, -0.04550129920244217, -0.02393500506877899, -0.0023687034845352173, 0.019197598099708557, 0.04076388478279114, 0.06233018636703491, 0.08389651775360107, 0.10546281933784485, 0.12702912092208862, 0.1485954076051712, 0.17016170918941498, 0.19172801077365875, 0.21329429745674133, 0.2348605990409851, 0.25642693042755127, 0.27799323201179504, 0.2995595335960388, 0.3211258053779602, 0.34269213676452637, 0.36425840854644775, 0.38582471013069153, 0.4073910117149353, 0.4289572834968567, 0.45052358508110046, 0.47208988666534424, 0.4936561584472656, 0.5152224898338318, 0.5367887616157532, 0.5583550930023193, 0.5799213647842407, 0.6014876365661621, 0.6230539083480835, 0.6446202397346497, 0.666186511516571, 0.6877528429031372, 0.7093191146850586, 0.73088538646698, 0.7524517178535461, 0.7740180492401123]}, "parameters/mlp_extractor.policy_net.2.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 5.0, 2.0, 0.0, 1.0, 2.0, 3.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.00011047152656828985, -0.00010675497469492257, -0.00010303842282155529, -9.932187094818801e-05, -9.560532635077834e-05, -9.188876720145345e-05, -8.817222260404378e-05, -8.44556707306765e-05, -8.073911885730922e-05, -7.702256698394194e-05, -7.330601511057466e-05, -6.958946323720738e-05, -6.58729113638401e-05, -6.215636676643044e-05, -5.843981489306316e-05, -5.472326301969588e-05, -5.10067111463286e-05, -4.729015927296132e-05, -4.357360739959404e-05, -3.9857059164205566e-05, -3.6140507290838286e-05, -3.2423955417471007e-05, -2.870740536309313e-05, -2.4990855308715254e-05, -2.1274303435347974e-05, -1.7557751561980695e-05, -1.3841201507602818e-05, -1.012465054373024e-05, -6.408099579857662e-06, -2.6915477064903826e-06, 1.0250023478874937e-06, 4.74155240226537e-06, 8.458111551590264e-06, 1.2174662515462842e-05, 1.589121347933542e-05, 1.9607763533713296e-05, 2.3324315407080576e-05, 2.7040867280447856e-05, 3.075741551583633e-05, 3.447396738920361e-05, 3.819051926257089e-05, 4.190707113593817e-05, 4.562362300930545e-05, 4.934017124469392e-05, 5.30567231180612e-05, 5.677327499142848e-05, 6.048982322681695e-05, 6.420637510018423e-05, 6.792292697355151e-05, 7.163947884691879e-05, 7.535603072028607e-05, 7.907258259365335e-05, 8.278913446702063e-05, 8.65056790644303e-05, 9.022223093779758e-05, 9.393878281116486e-05, 9.765533468453214e-05, 0.00010137188655789942, 0.0001050884384312667, 0.00010880499030463398, 0.00011252153490204364, 0.00011623809405136853, 0.0001199546386487782, 0.0001236711977981031, 0.00012738774239551276]}, "parameters/mlp_extractor.value_net.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 4.0, 7.0, 7.0, 13.0, 16.0, 26.0, 23.0, 40.0, 59.0, 74.0, 107.0, 119.0, 183.0, 197.0, 264.0, 282.0, 350.0, 422.0, 515.0, 579.0, 653.0, 708.0, 731.0, 792.0, 804.0, 904.0, 822.0, 804.0, 856.0, 741.0, 709.0, 671.0, 649.0, 547.0, 465.0, 435.0, 380.0, 288.0, 278.0, 200.0, 147.0, 124.0, 105.0, 82.0, 66.0, 39.0, 25.0, 21.0, 13.0, 8.0, 6.0, 8.0, 3.0, 6.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.35899344086647034, -0.3475782573223114, -0.33616310358047485, -0.3247479200363159, -0.313332736492157, -0.30191755294799805, -0.2905023992061615, -0.27908721566200256, -0.26767203211784363, -0.2562568485736847, -0.24484167993068695, -0.2334265112876892, -0.22201132774353027, -0.21059615910053253, -0.1991809904575348, -0.18776580691337585, -0.1763506382703781, -0.16493546962738037, -0.15352028608322144, -0.1421051174402237, -0.13068993389606476, -0.11927476525306702, -0.10785958915948868, -0.09644441306591034, -0.0850292444229126, -0.07361406832933426, -0.06219889223575592, -0.05078371986746788, -0.03936854377388954, -0.027953367680311203, -0.016538195312023163, -0.005123019218444824, 0.006292164325714111, 0.01770734041929245, 0.02912251465022564, 0.04053768888115883, 0.05195286497473717, 0.06336803734302521, 0.07478321343660355, 0.08619838953018188, 0.09761357307434082, 0.10902874916791916, 0.1204439252614975, 0.13185909390449524, 0.14327427744865417, 0.15468944609165192, 0.16610461473464966, 0.1775197982788086, 0.18893496692180634, 0.20035013556480408, 0.211765319108963, 0.22318048775196075, 0.2345956712961197, 0.24601083993911743, 0.25742602348327637, 0.2688412070274353, 0.28025636076927185, 0.2916715443134308, 0.30308669805526733, 0.31450188159942627, 0.3259170651435852, 0.33733224868774414, 0.3487474024295807, 0.3601625859737396, 0.37157776951789856]}, "parameters/mlp_extractor.value_net.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 1.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.0029172636568546295, -0.002827267860993743, -0.0027372722979635, -0.0026472765021026134, -0.002557280706241727, -0.0024672849103808403, -0.0023772893473505974, -0.002287293551489711, -0.0021972977556288242, -0.0021073019597679377, -0.0020173063967376947, -0.0019273106008768082, -0.0018373148050159216, -0.0017473191255703568, -0.001657323446124792, -0.0015673276502639055, -0.0014773319708183408, -0.001387336291372776, -0.0012973404955118895, -0.0012073448160663247, -0.0011173490202054381, -0.0010273533407598734, -0.0009373576031066477, -0.0008473618654534221, -0.0007573661860078573, -0.0006673704483546317, -0.000577374710701406, -0.0004873790021520108, -0.00039738326449878514, -0.0003073875268455595, -0.00021739181829616427, -0.00012739608064293861, -3.740028478205204e-05, 5.2595445595216006e-05, 0.00014259117597248405, 0.00023258689907379448, 0.00032258263672702014, 0.0004125783743802458, 0.000502574082929641, 0.0005925698205828667, 0.0006825656164437532, 0.0007725613540969789, 0.0008625570917502046, 0.0009525527711957693, 0.0010425485670566559, 0.0011325442465022206, 0.0012225399259477854, 0.001312535721808672, 0.0014025314012542367, 0.0014925270806998014, 0.001582522876560688, 0.0016725185560062528, 0.0017625143518671393, 0.001852510031312704, 0.0019425058271735907, 0.0020325016230344772, 0.00212249718606472, 0.0022124929819256067, 0.0023024885449558496, 0.0023924843408167362, 0.002482480136677623, 0.0025724759325385094, 0.0026624714955687523, 0.002752467291429639, 0.0028424630872905254]}, "parameters/mlp_extractor.value_net.2.weight": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 2.0, 4.0, 9.0, 4.0, 11.0, 12.0, 14.0, 10.0, 20.0, 25.0, 25.0, 37.0, 46.0, 49.0, 61.0, 89.0, 83.0, 101.0, 110.0, 119.0, 114.0, 147.0, 102.0, 138.0, 166.0, 159.0, 158.0, 162.0, 139.0, 161.0, 168.0, 142.0, 148.0, 157.0, 149.0, 123.0, 107.0, 120.0, 99.0, 107.0, 63.0, 77.0, 61.0, 48.0, 42.0, 34.0, 42.0, 27.0, 35.0, 19.0, 11.0, 10.0, 8.0, 4.0, 3.0, 2.0, 3.0, 1.0, 0.0, 2.0, 2.0], "bins": [-0.5723466277122498, -0.554155170917511, -0.5359637141227722, -0.5177722573280334, -0.4995807707309723, -0.4813893139362335, -0.46319782733917236, -0.4450063705444336, -0.4268149137496948, -0.40862345695495605, -0.3904320001602173, -0.37224051356315613, -0.35404905676841736, -0.3358575999736786, -0.31766611337661743, -0.29947465658187866, -0.2812831997871399, -0.2630917429924011, -0.24490027129650116, -0.2267087996006012, -0.20851734280586243, -0.19032588601112366, -0.1721344143152237, -0.15394294261932373, -0.13575148582458496, -0.1175600215792656, -0.09936855733394623, -0.08117709308862686, -0.0629856288433075, -0.04479416459798813, -0.026602700352668762, -0.008411228656768799, 0.009780287742614746, 0.027971751987934113, 0.04616321623325348, 0.06435468047857285, 0.08254614472389221, 0.10073760896921158, 0.11892907321453094, 0.1371205449104309, 0.15531200170516968, 0.17350345849990845, 0.1916949301958084, 0.20988640189170837, 0.22807785868644714, 0.2462693154811859, 0.26446080207824707, 0.28265225887298584, 0.3008437156677246, 0.3190351724624634, 0.33722662925720215, 0.3554181158542633, 0.3736095726490021, 0.39180102944374084, 0.409992516040802, 0.42818397283554077, 0.44637542963027954, 0.4645668864250183, 0.4827583432197571, 0.5009498000144958, 0.5191413164138794, 0.5373327732086182, 0.5555242300033569, 0.5737156867980957, 0.5919071435928345]}, "parameters/mlp_extractor.value_net.2.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 7.0, 1.0, 3.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-0.027860920876264572, -0.027030091732740402, -0.026199262589216232, -0.025368433445692062, -0.024537604302167892, -0.023706775158643723, -0.022875946015119553, -0.022045116871595383, -0.021214287728071213, -0.020383458584547043, -0.019552629441022873, -0.018721800297498703, -0.017890971153974533, -0.017060142010450363, -0.016229312866926193, -0.015398483723402023, -0.014567654579877853, -0.013736825436353683, -0.012905996292829514, -0.012075167149305344, -0.011244338005781174, -0.010413508862257004, -0.009582679718732834, -0.008751850575208664, -0.007921021431684494, -0.007090192288160324, -0.006259363144636154, -0.005428534001111984, -0.004597704857587814, -0.0037668757140636444, -0.0029360465705394745, -0.0021052174270153046, -0.0012743864208459854, -0.0004435572773218155, 0.00038727186620235443, 0.0012181010097265244, 0.0020489301532506943, 0.002879759296774864, 0.003710588440299034, 0.004541417583823204, 0.005372246727347374, 0.006203075870871544, 0.007033905014395714, 0.007864734157919884, 0.008695563301444054, 0.009526392444968224, 0.010357221588492393, 0.011188050732016563, 0.012018879875540733, 0.012849709019064903, 0.013680538162589073, 0.014511367306113243, 0.015342196449637413, 0.016173025593161583, 0.017003854736685753, 0.017834683880209923, 0.018665513023734093, 0.019496342167258263, 0.020327171310782433, 0.021158000454306602, 0.021988829597830772, 0.022819658741354942, 0.023650487884879112, 0.024481317028403282, 0.025312146171927452]}, "parameters/action_net.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 9.0, 4.0, 7.0, 3.0, 7.0, 6.0, 6.0, 5.0, 7.0, 8.0, 10.0, 5.0, 7.0, 4.0, 8.0, 6.0, 6.0, 7.0, 8.0, 11.0, 6.0, 4.0, 0.0, 2.0, 2.0, 6.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.006362736225128174, -0.006135996431112289, -0.005909256637096405, -0.005682517308741808, -0.0054557775147259235, -0.005229037720710039, -0.005002297926694155, -0.004775558598339558, -0.004548818804323673, -0.004322079010307789, -0.0040953392162919044, -0.0038685996551066637, -0.003641860093921423, -0.0034151202999055386, -0.003188380505889654, -0.0029616409447044134, -0.002734901150688529, -0.0025081613566726446, -0.002281421795487404, -0.0020546820014715195, -0.0018279424402862787, -0.0016012026462703943, -0.0013744629686698318, -0.0011477232910692692, -0.0009209834970533848, -0.0006942438194528222, -0.0004675041127484292, -0.00024076440604403615, -1.4024728443473577e-05, 0.0002127150073647499, 0.0004394546849653125, 0.000666194362565875, 0.0008929339237511158, 0.0011196736013516784, 0.001346413278952241, 0.0015731530729681253, 0.001799892634153366, 0.0020266324281692505, 0.002253372222185135, 0.0024801117833703756, 0.0027068513445556164, 0.0029335911385715008, 0.0031603306997567415, 0.003387070493772626, 0.0036138100549578667, 0.003840549848973751, 0.0040672896429896355, 0.00429402943700552, 0.004520769231021404, 0.004747509025037289, 0.004974248819053173, 0.00520098814740777, 0.0054277279414236546, 0.005654467735439539, 0.005881207529455423, 0.0061079468578100204, 0.006334686651825905, 0.006561426445841789, 0.006788166239857674, 0.007014905568212271, 0.007241645362228155, 0.0074683851562440395, 0.007695124950259924, 0.007921864278614521, 0.008148604072630405]}, "parameters/action_net.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0006908389623276889, -0.0006490708328783512, -0.0006073027616366744, -0.0005655346321873367, -0.0005237665609456599, -0.00048199843149632215, -0.0004402303311508149, -0.0003984622308053076, -0.00035669413045980036, -0.0003149260301142931, -0.00027315792976878583, -0.00023138981487136334, -0.00018962171452585608, -0.0001478536141803488, -0.00010608549928292632, -6.431739893741906e-05, -2.2549298591911793e-05, 1.921880539157428e-05, 6.098690937506035e-05, 0.00010275501699652523, 0.0001445231173420325, 0.00018629121768753976, 0.00022805933258496225, 0.0002698274329304695, 0.00031159556237980723, 0.0003533636627253145, 0.00039513176307082176, 0.0004368998925201595, 0.0004786679637618363, 0.000520436093211174, 0.0005622041644528508, 0.0006039722939021885, 0.0006457403069362044, 0.0006875084363855422, 0.000729276507627219, 0.0007710446370765567, 0.0008128127083182335, 0.0008545808377675712, 0.0008963489672169089, 0.0009381170384585857, 0.0009798851097002625, 0.0010216531809419394, 0.001063421368598938, 0.0011051894398406148, 0.0011469575110822916, 0.0011887255823239684, 0.001230493769980967, 0.0012722618412226439, 0.0013140300288796425, 0.0013557981001213193, 0.001397566287778318, 0.0014393343590199947, 0.0014811024302616715, 0.0015228705015033484, 0.001564638689160347, 0.0016064067604020238, 0.0016481748316437006, 0.0016899429028853774, 0.001731711090542376, 0.0017734791617840528, 0.0018152472330257297, 0.0018570153042674065, 0.001898783491924405, 0.001940551563166082, 0.0019823196344077587]}, "parameters/value_net.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 6.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.29225996136665344, -0.28363439440727234, -0.27500882744789124, -0.26638326048851013, -0.25775769352912903, -0.24913212656974792, -0.24050654470920563, -0.23188097774982452, -0.22325541079044342, -0.21462984383106232, -0.2060042768716812, -0.1973787099123001, -0.1887531280517578, -0.1801275610923767, -0.1715019941329956, -0.1628764271736145, -0.1542508602142334, -0.1456252932548523, -0.1369997262954712, -0.1283741593360901, -0.11974858492612839, -0.11112301796674728, -0.10249744355678558, -0.09387187659740448, -0.08524630963802338, -0.07662074267864227, -0.06799517571926117, -0.05936960130929947, -0.050744034349918365, -0.04211846739053726, -0.03349289670586586, -0.024867326021194458, -0.016241729259490967, -0.007616160437464714, 0.0010094083845615387, 0.009634977206587791, 0.018260546028614044, 0.026886112987995148, 0.03551168367266655, 0.04413725435733795, 0.052762821316719055, 0.06138838827610016, 0.07001395523548126, 0.07863952964544296, 0.08726509660482407, 0.09589066356420517, 0.10451623797416687, 0.11314180493354797, 0.12176737189292908, 0.13039293885231018, 0.13901850581169128, 0.1476440727710724, 0.1562696397304535, 0.1648952066898346, 0.1735207885503769, 0.182146355509758, 0.1907719224691391, 0.1993974894285202, 0.2080230563879013, 0.2166486233472824, 0.2252742052078247, 0.2338997721672058, 0.24252533912658691, 0.251150906085968, 0.2597764730453491]}, "parameters/value_net.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621]}, "global_step": 24576, "rollout/ep_len_mean": 75.86000061035156, "rollout/ep_rew_mean": -261.47698974609375, "time/fps": 27.0, "train/entropy_loss": -4.257534980773926, "train/value_loss": 4489.5986328125, "train/std": 1.000327467918396, "train/policy_gradient_loss": -0.0004989735898561776, "train/loss": 2029.021240234375, "train/learning_rate": 9.999999747378752e-06, "train/clip_range": 0.20000000298023224, "train/explained_variance": 0.00013047456741333008, "train/clip_fraction": 0.0, "train/approx_kl": 0.0010396146681159735, "_wandb": {"runtime": 977}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/run-Test Run 1.wandb b/ROAR_gym/wandb/run-20220621_231501-Test Run 1/run-Test Run 1.wandb
deleted file mode 100644
index 7996778..0000000
Binary files a/ROAR_gym/wandb/run-20220621_231501-Test Run 1/run-Test Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/config.yaml
deleted file mode 100644
index a4e1d3f..0000000
--- a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/config.yaml	
+++ /dev/null
@@ -1,295 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x0000027E58E878C8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2emodel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655826708
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 1
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x0000027E591CF948>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000027E58F61F88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x0000027E27D678B8>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x0000027E591A2D48>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655824503.2783575
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Test Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/events.out.tfevents.1655826712.Windys-Desktop.17432.0 b/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/events.out.tfevents.1655826712.Windys-Desktop.17432.0
deleted file mode 120000
index 680c5cd..0000000
--- a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/events.out.tfevents.1655826712.Windys-Desktop.17432.0	
+++ /dev/null
@@ -1 +0,0 @@
-D:/Programming/Subjects/ROAR/ROAR_RL/ROAR_Gym/runs/Test Run 1/PPO_0/events.out.tfevents.1655826712.Windys-Desktop.17432.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/wandb-summary.json
deleted file mode 100644
index 44ac9f8..0000000
--- a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"avg10_checkpoints": 105.0, "rollout/ep_len_mean": 75.86000061035156, "train/clip_fraction": 0, "train/entropy_loss": -4.257534980773926, "train/approx_kl": 0.0010396146681159737, "parameters/value_net.bias": {"_type": "histogram", "bins": [-0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621, -0.02568851411342621], "values": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, "parameters/mlp_extractor.value_net.2.bias": {"_type": "histogram", "bins": [-0.027860920876264572, -0.027030091732740402, -0.026199262589216232, -0.025368433445692062, -0.024537604302167892, -0.023706775158643723, -0.022875946015119553, -0.022045116871595383, -0.021214287728071213, -0.020383458584547043, -0.019552629441022873, -0.018721800297498703, -0.017890971153974533, -0.017060142010450363, -0.016229312866926193, -0.015398483723402023, -0.014567654579877853, -0.013736825436353683, -0.012905996292829514, -0.012075167149305344, -0.011244338005781174, -0.010413508862257004, -0.009582679718732834, -0.008751850575208664, -0.007921021431684494, -0.007090192288160324, -0.006259363144636154, -0.005428534001111984, -0.004597704857587814, -0.0037668757140636444, -0.0029360465705394745, -0.0021052174270153046, -0.0012743864208459854, -0.0004435572773218155, 0.00038727186620235443, 0.0012181010097265244, 0.0020489301532506943, 0.002879759296774864, 0.003710588440299034, 0.004541417583823204, 0.005372246727347374, 0.006203075870871544, 0.007033905014395714, 0.007864734157919884, 0.008695563301444054, 0.009526392444968224, 0.010357221588492393, 0.011188050732016563, 0.012018879875540733, 0.012849709019064903, 0.013680538162589073, 0.014511367306113243, 0.015342196449637413, 0.016173025593161583, 0.017003854736685753, 0.017834683880209923, 0.018665513023734093, 0.019496342167258263, 0.020327171310782433, 0.021158000454306602, 0.021988829597830772, 0.022819658741354942, 0.023650487884879112, 0.024481317028403282, 0.025312146171927452], "values": [1, 0, 1, 0, 1, 0, 1, 0, 0, 3, 2, 1, 2, 1, 2, 2, 4, 2, 3, 0, 0, 1, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 7, 1, 3, 4, 0, 0, 1, 0, 0, 0, 0, 2, 1]}, "_runtime": 990, "parameters/features_extractor.network.2.bias": {"_type": "histogram", "bins": [-0.0036541051231324673, -0.003476818324998021, -0.003299531526863575, -0.003122244728729129, -0.0029449579305946827, -0.0027676711324602365, -0.0025903843343257904, -0.0024130975361913443, -0.002235810738056898, -0.002058523939922452, -0.0018812371417880058, -0.0017039503436535597, -0.0015266635455191135, -0.0013493767473846674, -0.0011720899492502213, -0.000994803151115775, -0.000817516352981329, -0.0006402295548468828, -0.0004629427567124367, -0.00028565595857799053, -0.00010836916044354439, 6.891763769090176e-05, 0.0002462044358253479, 0.00042349123395979404, 0.0006007780320942402, 0.0007780648302286863, 0.0009553516283631325, 0.0011326384264975786, 0.0013099252246320248, 0.001487212022766471, 0.001664498820900917, 0.0018417856190353632, 0.0020190724171698093, 0.0021963592153042555, 0.0023736460134387016, 0.0025509328115731478, 0.002728219609707594, 0.00290550640784204, 0.003082793205976486, 0.0032600800041109324, 0.0034373668022453785, 0.0036146536003798246, 0.0037919403985142708, 0.003969226963818073, 0.004146513994783163, 0.004323801025748253, 0.004501087591052055, 0.004678374156355858, 0.004855661187320948, 0.0050329482182860374, 0.00521023478358984, 0.005387521348893642, 0.005564808379858732, 0.005742095410823822, 0.0059193819761276245, 0.006096668541431427, 0.006273955572396517, 0.006451242603361607, 0.006628529168665409, 0.006805815733969212, 0.006983102764934301, 0.007160389795899391, 0.007337676361203194, 0.007514962926506996, 0.007692249957472086], "values": [1, 0, 0, 0, 0, 1, 0, 2, 3, 2, 3, 0, 1, 1, 1, 3, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 4, 2, 3, 2, 3, 3, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 1]}, "Checkpoint reached": 30, "Episode reward": -249.4, "parameters/mlp_extractor.policy_net.2.weight": {"values": [1, 3, 0, 2, 2, 2, 5, 13, 7, 20, 24, 20, 49, 45, 52, 56, 81, 71, 98, 108, 121, 137, 155, 179, 165, 180, 229, 204, 189, 198, 192, 174, 167, 157, 154, 137, 125, 116, 102, 79, 54, 48, 44, 29, 24, 18, 16, 11, 7, 11, 6, 3, 3, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1], "_type": "histogram", "bins": [-0.6062250137329102, -0.5846587419509888, -0.5630924105644226, -0.5415261387825012, -0.5199598073959351, -0.49839353561401367, -0.4768272340297699, -0.4552609324455261, -0.43369463086128235, -0.4121283292770386, -0.3905620276927948, -0.368995726108551, -0.34742945432662964, -0.3258631229400635, -0.3042968511581421, -0.2827305495738983, -0.26116424798965454, -0.23959794640541077, -0.218031644821167, -0.1964653581380844, -0.17489905655384064, -0.15333275496959686, -0.13176646828651428, -0.11020016670227051, -0.08863389492034912, -0.06706759333610535, -0.04550129920244217, -0.02393500506877899, -0.0023687034845352173, 0.019197598099708557, 0.04076388478279114, 0.06233018636703491, 0.08389651775360107, 0.10546281933784485, 0.12702912092208862, 0.1485954076051712, 0.17016170918941498, 0.19172801077365875, 0.21329429745674133, 0.2348605990409851, 0.25642693042755127, 0.27799323201179504, 0.2995595335960388, 0.3211258053779602, 0.34269213676452637, 0.36425840854644775, 0.38582471013069153, 0.4073910117149353, 0.4289572834968567, 0.45052358508110046, 0.47208988666534424, 0.4936561584472656, 0.5152224898338318, 0.5367887616157532, 0.5583550930023193, 0.5799213647842407, 0.6014876365661621, 0.6230539083480835, 0.6446202397346497, 0.666186511516571, 0.6877528429031372, 0.7093191146850586, 0.73088538646698, 0.7524517178535461, 0.7740180492401123]}, "train/clip_range": 0.20000000298023224, "parameters/mlp_extractor.policy_net.2.bias": {"_type": "histogram", "values": [1, 1, 1, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 1, 3, 1, 2, 3, 2, 2, 3, 1, 1, 3, 2, 0, 5, 2, 0, 1, 2, 3, 0, 2, 3, 2, 1, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [-0.00011047152656828985, -0.00010675497469492257, -0.00010303842282155529, -9.932187094818801e-05, -9.560532635077834e-05, -9.188876720145345e-05, -8.817222260404378e-05, -8.44556707306765e-05, -8.073911885730922e-05, -7.702256698394194e-05, -7.330601511057466e-05, -6.958946323720738e-05, -6.58729113638401e-05, -6.215636676643044e-05, -5.843981489306316e-05, -5.472326301969588e-05, -5.10067111463286e-05, -4.729015927296132e-05, -4.357360739959404e-05, -3.9857059164205566e-05, -3.6140507290838286e-05, -3.2423955417471007e-05, -2.870740536309313e-05, -2.4990855308715254e-05, -2.1274303435347974e-05, -1.7557751561980695e-05, -1.3841201507602818e-05, -1.012465054373024e-05, -6.408099579857662e-06, -2.6915477064903826e-06, 1.0250023478874937e-06, 4.74155240226537e-06, 8.458111551590264e-06, 1.2174662515462842e-05, 1.589121347933542e-05, 1.9607763533713296e-05, 2.3324315407080576e-05, 2.7040867280447856e-05, 3.075741551583633e-05, 3.447396738920361e-05, 3.819051926257089e-05, 4.190707113593817e-05, 4.562362300930545e-05, 4.934017124469392e-05, 5.30567231180612e-05, 5.677327499142848e-05, 6.048982322681695e-05, 6.420637510018423e-05, 6.792292697355151e-05, 7.163947884691879e-05, 7.535603072028607e-05, 7.907258259365335e-05, 8.278913446702063e-05, 8.65056790644303e-05, 9.022223093779758e-05, 9.393878281116486e-05, 9.765533468453214e-05, 0.00010137188655789942, 0.0001050884384312667, 0.00010880499030463398, 0.00011252153490204364, 0.00011623809405136853, 0.0001199546386487782, 0.0001236711977981031, 0.00012738774239551276]}, "largest_steps": 100, "parameters/action_net.bias": {"_type": "histogram", "bins": [-0.0006908389623276889, -0.0006490708328783512, -0.0006073027616366744, -0.0005655346321873367, -0.0005237665609456599, -0.00048199843149632215, -0.0004402303311508149, -0.0003984622308053076, -0.00035669413045980036, -0.0003149260301142931, -0.00027315792976878583, -0.00023138981487136334, -0.00018962171452585608, -0.0001478536141803488, -0.00010608549928292632, -6.431739893741906e-05, -2.2549298591911793e-05, 1.921880539157428e-05, 6.098690937506035e-05, 0.00010275501699652523, 0.0001445231173420325, 0.00018629121768753976, 0.00022805933258496225, 0.0002698274329304695, 0.00031159556237980723, 0.0003533636627253145, 0.00039513176307082176, 0.0004368998925201595, 0.0004786679637618363, 0.000520436093211174, 0.0005622041644528508, 0.0006039722939021885, 0.0006457403069362044, 0.0006875084363855422, 0.000729276507627219, 0.0007710446370765567, 0.0008128127083182335, 0.0008545808377675712, 0.0008963489672169089, 0.0009381170384585857, 0.0009798851097002625, 0.0010216531809419394, 0.001063421368598938, 0.0011051894398406148, 0.0011469575110822916, 0.0011887255823239684, 0.001230493769980967, 0.0012722618412226439, 0.0013140300288796425, 0.0013557981001213193, 0.001397566287778318, 0.0014393343590199947, 0.0014811024302616715, 0.0015228705015033484, 0.001564638689160347, 0.0016064067604020238, 0.0016481748316437006, 0.0016899429028853774, 0.001731711090542376, 0.0017734791617840528, 0.0018152472330257297, 0.0018570153042674065, 0.001898783491924405, 0.001940551563166082, 0.0019823196344077587], "values": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, "rollout/ep_rew_mean": -261.47698974609375, "parameters/mlp_extractor.value_net.0.weight": {"values": [1, 0, 0, 1, 2, 4, 7, 7, 13, 16, 26, 23, 40, 59, 74, 107, 119, 183, 197, 264, 282, 350, 422, 515, 579, 653, 708, 731, 792, 804, 904, 822, 804, 856, 741, 709, 671, 649, 547, 465, 435, 380, 288, 278, 200, 147, 124, 105, 82, 66, 39, 25, 21, 13, 8, 6, 8, 3, 6, 1, 1, 0, 0, 1], "_type": "histogram", "bins": [-0.35899344086647034, -0.3475782573223114, -0.33616310358047485, -0.3247479200363159, -0.313332736492157, -0.30191755294799805, -0.2905023992061615, -0.27908721566200256, -0.26767203211784363, -0.2562568485736847, -0.24484167993068695, -0.2334265112876892, -0.22201132774353027, -0.21059615910053253, -0.1991809904575348, -0.18776580691337585, -0.1763506382703781, -0.16493546962738037, -0.15352028608322144, -0.1421051174402237, -0.13068993389606476, -0.11927476525306702, -0.10785958915948868, -0.09644441306591034, -0.0850292444229126, -0.07361406832933426, -0.06219889223575592, -0.05078371986746788, -0.03936854377388954, -0.027953367680311203, -0.016538195312023163, -0.005123019218444824, 0.006292164325714111, 0.01770734041929245, 0.02912251465022564, 0.04053768888115883, 0.05195286497473717, 0.06336803734302521, 0.07478321343660355, 0.08619838953018188, 0.09761357307434082, 0.10902874916791916, 0.1204439252614975, 0.13185909390449524, 0.14327427744865417, 0.15468944609165192, 0.16610461473464966, 0.1775197982788086, 0.18893496692180634, 0.20035013556480408, 0.211765319108963, 0.22318048775196075, 0.2345956712961197, 0.24601083993911743, 0.25742602348327637, 0.2688412070274353, 0.28025636076927185, 0.2916715443134308, 0.30308669805526733, 0.31450188159942627, 0.3259170651435852, 0.33733224868774414, 0.3487474024295807, 0.3601625859737396, 0.37157776951789856]}, "train/loss": 2029.021240234375, "_timestamp": 1655826717, "time/fps": 27, "train/value_loss": 4489.5986328125, "highest_speed": 83.89974998346548, "parameters/features_extractor.network.7.weight": {"_type": "histogram", "bins": [-0.11672411859035492, -0.11303890496492386, -0.1093536913394928, -0.10566847771406174, -0.10198326408863068, -0.09829805791378021, -0.09461284428834915, -0.09092763066291809, -0.08724241703748703, -0.08355720341205597, -0.07987198978662491, -0.07618677616119385, -0.07250156998634338, -0.06881634891033173, -0.06513114273548126, -0.0614459291100502, -0.05776071548461914, -0.05407550185918808, -0.05039028823375702, -0.04670507833361626, -0.043019864708185196, -0.039334651082754135, -0.03564944118261337, -0.03196422755718231, -0.02827901393175125, -0.02459380030632019, -0.02090858854353428, -0.017223376780748367, -0.013538163155317307, -0.009852949529886246, -0.006167737767100334, -0.0024825260043144226, 0.0012026876211166382, 0.004887900315225124, 0.00857311300933361, 0.012258325703442097, 0.015943538397550583, 0.019628752022981644, 0.023313963785767555, 0.026999175548553467, 0.030684389173984528, 0.03436960279941559, 0.03805481642484665, 0.04174002632498741, 0.04542523995041847, 0.04911045357584953, 0.052795663475990295, 0.056480877101421356, 0.06016609072685242, 0.06385130435228348, 0.06753651797771454, 0.0712217316031456, 0.07490694522857666, 0.07859215140342712, 0.08227736502885818, 0.08596257865428925, 0.0896477922797203, 0.09333300590515137, 0.09701821953058243, 0.10070343315601349, 0.10438863933086395, 0.10807386040687561, 0.11175906658172607, 0.11544428020715714, 0.1191294938325882], "values": [2, 3, 2, 11, 12, 42, 55, 97, 167, 254, 400, 641, 964, 1372, 2107, 2959, 4102, 5500, 7571, 9820, 12364, 15495, 19248, 23167, 27032, 31379, 35255, 39028, 41930, 44667, 46138, 46455, 46345, 45026, 42768, 39405, 36540, 32476, 28443, 24235, 20039, 16514, 13396, 10558, 8199, 6113, 4571, 3281, 2200, 1508, 1044, 704, 496, 276, 178, 112, 55, 50, 15, 18, 8, 1, 1, 2]}, "parameters/mlp_extractor.value_net.2.weight": {"values": [2, 2, 1, 2, 4, 9, 4, 11, 12, 14, 10, 20, 25, 25, 37, 46, 49, 61, 89, 83, 101, 110, 119, 114, 147, 102, 138, 166, 159, 158, 162, 139, 161, 168, 142, 148, 157, 149, 123, 107, 120, 99, 107, 63, 77, 61, 48, 42, 34, 42, 27, 35, 19, 11, 10, 8, 4, 3, 2, 3, 1, 0, 2, 2], "_type": "histogram", "bins": [-0.5723466277122498, -0.554155170917511, -0.5359637141227722, -0.5177722573280334, -0.4995807707309723, -0.4813893139362335, -0.46319782733917236, -0.4450063705444336, -0.4268149137496948, -0.40862345695495605, -0.3904320001602173, -0.37224051356315613, -0.35404905676841736, -0.3358575999736786, -0.31766611337661743, -0.29947465658187866, -0.2812831997871399, -0.2630917429924011, -0.24490027129650116, -0.2267087996006012, -0.20851734280586243, -0.19032588601112366, -0.1721344143152237, -0.15394294261932373, -0.13575148582458496, -0.1175600215792656, -0.09936855733394623, -0.08117709308862686, -0.0629856288433075, -0.04479416459798813, -0.026602700352668762, -0.008411228656768799, 0.009780287742614746, 0.027971751987934113, 0.04616321623325348, 0.06435468047857285, 0.08254614472389221, 0.10073760896921158, 0.11892907321453094, 0.1371205449104309, 0.15531200170516968, 0.17350345849990845, 0.1916949301958084, 0.20988640189170837, 0.22807785868644714, 0.2462693154811859, 0.26446080207824707, 0.28265225887298584, 0.3008437156677246, 0.3190351724624634, 0.33722662925720215, 0.3554181158542633, 0.3736095726490021, 0.39180102944374084, 0.409992516040802, 0.42818397283554077, 0.44637542963027954, 0.4645668864250183, 0.4827583432197571, 0.5009498000144958, 0.5191413164138794, 0.5373327732086182, 0.5555242300033569, 0.5737156867980957, 0.5919071435928345]}, "parameters/value_net.weight": {"values": [1, 0, 0, 0, 0, 1, 3, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 0, 3, 2, 1, 2, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 3, 6, 2, 1, 3, 2, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1], "_type": "histogram", "bins": [-0.29225996136665344, -0.28363439440727234, -0.27500882744789124, -0.26638326048851013, -0.25775769352912903, -0.24913212656974792, -0.24050654470920563, -0.23188097774982452, -0.22325541079044342, -0.21462984383106232, -0.2060042768716812, -0.1973787099123001, -0.1887531280517578, -0.1801275610923767, -0.1715019941329956, -0.1628764271736145, -0.1542508602142334, -0.1456252932548523, -0.1369997262954712, -0.1283741593360901, -0.11974858492612839, -0.11112301796674728, -0.10249744355678558, -0.09387187659740448, -0.08524630963802338, -0.07662074267864227, -0.06799517571926117, -0.05936960130929947, -0.050744034349918365, -0.04211846739053726, -0.03349289670586586, -0.024867326021194458, -0.016241729259490967, -0.007616160437464714, 0.0010094083845615387, 0.009634977206587791, 0.018260546028614044, 0.026886112987995148, 0.03551168367266655, 0.04413725435733795, 0.052762821316719055, 0.06138838827610016, 0.07001395523548126, 0.07863952964544296, 0.08726509660482407, 0.09589066356420517, 0.10451623797416687, 0.11314180493354797, 0.12176737189292908, 0.13039293885231018, 0.13901850581169128, 0.1476440727710724, 0.1562696397304535, 0.1648952066898346, 0.1735207885503769, 0.182146355509758, 0.1907719224691391, 0.1993974894285202, 0.2080230563879013, 0.2166486233472824, 0.2252742052078247, 0.2338997721672058, 0.24252533912658691, 0.251150906085968, 0.2597764730453491]}, "train/explained_variance": 0.00013047456741333008, "parameters/features_extractor.network.0.weight": {"_type": "histogram", "bins": [-0.2031766027212143, -0.19678597152233124, -0.19039534032344818, -0.18400470912456512, -0.17761406302452087, -0.17122343182563782, -0.16483280062675476, -0.1584421694278717, -0.15205153822898865, -0.1456609070301056, -0.13927027583122253, -0.13287964463233948, -0.12648901343345642, -0.12009837478399277, -0.11370773613452911, -0.10731710493564606, -0.100926473736763, -0.09453584253787994, -0.08814521133899689, -0.08175457268953323, -0.07536394149065018, -0.06897331029176712, -0.06258267164230347, -0.05619204044342041, -0.049801409244537354, -0.0434107780456543, -0.03702014312148094, -0.030629510059952736, -0.02423887699842453, -0.017848245799541473, -0.011457610875368118, -0.005066975951194763, 0.0013236552476882935, 0.007714288309216499, 0.014104921370744705, 0.02049555443227291, 0.026886187493801117, 0.033276818692684174, 0.03966745361685753, 0.046058088541030884, 0.05244871973991394, 0.058839350938797, 0.06522998213768005, 0.07162062078714371, 0.07801125198602676, 0.08440188318490982, 0.09079252183437347, 0.09718315303325653, 0.10357378423213959, 0.10996441543102264, 0.1163550466299057, 0.12274568527936935, 0.129136323928833, 0.13552695512771606, 0.14191758632659912, 0.14830821752548218, 0.15469884872436523, 0.1610894799232483, 0.16748011112213135, 0.1738707423210144, 0.18026137351989746, 0.18665200471878052, 0.19304265081882477, 0.19943328201770782, 0.20582391321659088], "values": [1, 0, 3, 1, 3, 4, 10, 14, 12, 26, 40, 44, 59, 97, 101, 143, 170, 253, 300, 361, 437, 529, 609, 694, 805, 865, 985, 1045, 1144, 1173, 1202, 1155, 1240, 1210, 1171, 1113, 1037, 963, 863, 779, 743, 629, 521, 424, 349, 278, 233, 181, 137, 123, 82, 68, 51, 32, 20, 13, 11, 4, 2, 8, 3, 1, 1, 1]}, "parameters/mlp_extractor.value_net.0.bias": {"bins": [-0.0029172636568546295, -0.002827267860993743, -0.0027372722979635, -0.0026472765021026134, -0.002557280706241727, -0.0024672849103808403, -0.0023772893473505974, -0.002287293551489711, -0.0021972977556288242, -0.0021073019597679377, -0.0020173063967376947, -0.0019273106008768082, -0.0018373148050159216, -0.0017473191255703568, -0.001657323446124792, -0.0015673276502639055, -0.0014773319708183408, -0.001387336291372776, -0.0012973404955118895, -0.0012073448160663247, -0.0011173490202054381, -0.0010273533407598734, -0.0009373576031066477, -0.0008473618654534221, -0.0007573661860078573, -0.0006673704483546317, -0.000577374710701406, -0.0004873790021520108, -0.00039738326449878514, -0.0003073875268455595, -0.00021739181829616427, -0.00012739608064293861, -3.740028478205204e-05, 5.2595445595216006e-05, 0.00014259117597248405, 0.00023258689907379448, 0.00032258263672702014, 0.0004125783743802458, 0.000502574082929641, 0.0005925698205828667, 0.0006825656164437532, 0.0007725613540969789, 0.0008625570917502046, 0.0009525527711957693, 0.0010425485670566559, 0.0011325442465022206, 0.0012225399259477854, 0.001312535721808672, 0.0014025314012542367, 0.0014925270806998014, 0.001582522876560688, 0.0016725185560062528, 0.0017625143518671393, 0.001852510031312704, 0.0019425058271735907, 0.0020325016230344772, 0.00212249718606472, 0.0022124929819256067, 0.0023024885449558496, 0.0023924843408167362, 0.002482480136677623, 0.0025724759325385094, 0.0026624714955687523, 0.002752467291429639, 0.0028424630872905254], "values": [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 4, 3, 4, 4, 3, 2, 2, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 3, 1, 5, 4, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1], "_type": "histogram"}, "train/std": 1.000327467918396, "Episode_Sim_Time": 400, "parameters/action_net.weight": {"_type": "histogram", "bins": [-0.006362736225128174, -0.006135996431112289, -0.005909256637096405, -0.005682517308741808, -0.0054557775147259235, -0.005229037720710039, -0.005002297926694155, -0.004775558598339558, -0.004548818804323673, -0.004322079010307789, -0.0040953392162919044, -0.0038685996551066637, -0.003641860093921423, -0.0034151202999055386, -0.003188380505889654, -0.0029616409447044134, -0.002734901150688529, -0.0025081613566726446, -0.002281421795487404, -0.0020546820014715195, -0.0018279424402862787, -0.0016012026462703943, -0.0013744629686698318, -0.0011477232910692692, -0.0009209834970533848, -0.0006942438194528222, -0.0004675041127484292, -0.00024076440604403615, -1.4024728443473577e-05, 0.0002127150073647499, 0.0004394546849653125, 0.000666194362565875, 0.0008929339237511158, 0.0011196736013516784, 0.001346413278952241, 0.0015731530729681253, 0.001799892634153366, 0.0020266324281692505, 0.002253372222185135, 0.0024801117833703756, 0.0027068513445556164, 0.0029335911385715008, 0.0031603306997567415, 0.003387070493772626, 0.0036138100549578667, 0.003840549848973751, 0.0040672896429896355, 0.00429402943700552, 0.004520769231021404, 0.004747509025037289, 0.004974248819053173, 0.00520098814740777, 0.0054277279414236546, 0.005654467735439539, 0.005881207529455423, 0.0061079468578100204, 0.006334686651825905, 0.006561426445841789, 0.006788166239857674, 0.007014905568212271, 0.007241645362228155, 0.0074683851562440395, 0.007695124950259924, 0.007921864278614521, 0.008148604072630405], "values": [3, 0, 0, 1, 0, 2, 1, 0, 1, 2, 0, 1, 3, 2, 2, 3, 1, 3, 9, 4, 7, 3, 7, 6, 6, 5, 7, 8, 10, 5, 7, 4, 8, 6, 6, 7, 8, 11, 6, 4, 0, 2, 2, 6, 1, 2, 1, 1, 2, 1, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]}, "parameters/mlp_extractor.policy_net.0.bias": {"_type": "histogram", "bins": [-0.0002619962324388325, -0.0002556283725425601, -0.0002492605126462877, -0.00024289263819810003, -0.00023652476374991238, -0.00023015690385363996, -0.00022378904395736754, -0.0002174211695091799, -0.00021105330961290747, -0.00020468544971663505, -0.0001983175752684474, -0.00019194971537217498, -0.00018558184092398733, -0.0001792139810277149, -0.00017284610657952726, -0.00016647824668325484, -0.00016011038678698242, -0.00015374252689071, -0.00014737465244252235, -0.00014100679254624993, -0.00013463891809806228, -0.00012827105820178986, -0.00012190319102955982, -0.00011553532385732979, -0.00010916744940914214, -0.0001027995822369121, -9.643171506468207e-05, -9.006385516840965e-05, -8.369598799617961e-05, -7.732812082394958e-05, -7.096025365171954e-05, -6.45923864794895e-05, -5.8224526583217084e-05, -5.185665941098705e-05, -4.548879587673582e-05, -3.9120928704505786e-05, -3.275306517025456e-05, -2.6385197998024523e-05, -2.0017330825794488e-05, -1.364946729154326e-05, -7.281603757292032e-06, -9.137379493040498e-07, 5.4541278586839326e-06, 1.1821994121419266e-05, 1.8189859474659897e-05, 2.455772482790053e-05, 3.0925592000130564e-05, 3.729345553438179e-05, 4.3661326344590634e-05, 5.002919351682067e-05, 5.63970570510719e-05, 6.276492786128074e-05, 6.913278775755316e-05, 7.55006549297832e-05, 8.186852210201323e-05, 8.823638199828565e-05, 9.46042564464733e-05, 0.00010097212361870334, 0.00010733999079093337, 0.00011370785068720579, 0.00012007571785943583, 0.00012644358503166586, 0.0001328114594798535, 0.00013917931937612593, 0.00014554717927239835], "values": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 1, 4, 4, 4, 7, 5, 2, 6, 3, 1, 2, 2, 2, 2, 1, 0, 0, 3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]}, "parameters/features_extractor.network.0.bias": {"bins": [-0.0028796992264688015, -0.00267196586355567, -0.002464232500642538, -0.0022564991377294064, -0.0020487657748162746, -0.001841032295487821, -0.0016332988161593676, -0.0014255654532462358, -0.0012178320903331041, -0.0010100987274199724, -0.0008023653062991798, -0.0005946318851783872, -0.00038689852226525545, -0.00017916515935212374, 2.8568319976329803e-05, 0.00023630168288946152, 0.00044403504580259323, 0.0006517684087157249, 0.0008595018298365176, 0.0010672352509573102, 0.001274968613870442, 0.0014827019767835736, 0.0016904354561120272, 0.0018981688190251589, 0.0021059024147689342, 0.002313635777682066, 0.0025213691405951977, 0.0027291025035083294, 0.002936835866421461, 0.003144569229334593, 0.003352302825078368, 0.0035600361879915, 0.0037677697837352753, 0.003975503146648407, 0.004183236509561539, 0.00439096987247467, 0.004598703235387802, 0.004806436598300934, 0.0050141699612140656, 0.005221903324127197, 0.005429636687040329, 0.005637370049953461, 0.005845103412866592, 0.006052836775779724, 0.006260570138692856, 0.0064683035016059875, 0.006676036864519119, 0.006883770227432251, 0.00709150405600667, 0.007299237418919802, 0.007506970781832933, 0.007714704144746065, 0.007922437973320484, 0.008130171336233616, 0.008337904699146748, 0.00854563806205988, 0.008753371424973011, 0.008961104787886143, 0.009168838150799274, 0.009376571513712406, 0.009584304876625538, 0.00979203823953867, 0.009999771602451801, 0.010207504965364933, 0.010415238328278065], "values": [1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 0, 0, 2, 1, 1, 1, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], "_type": "histogram"}, "parameters/features_extractor.network.4.bias": {"_type": "histogram", "bins": [-0.0002750238636508584, -0.00019424136553425342, -0.00011345886741764843, -3.267636930104345e-05, 4.810612881556153e-05, 0.00012888864148408175, 0.0002096711250487715, 0.00029045360861346126, 0.00037123612128198147, 0.0004520186339505017, 0.0005328011466190219, 0.0006135836010798812, 0.0006943661137484014, 0.0007751486264169216, 0.0008559310808777809, 0.0009367135935463011, 0.0010174961062148213, 0.0010982785606756806, 0.0011790611315518618, 0.001259843586012721, 0.0013406260404735804, 0.0014214086113497615, 0.0015021910658106208, 0.001582973636686802, 0.0016637560911476612, 0.0017445385456085205, 0.0018253211164847016, 0.001906103570945561, 0.001986886141821742, 0.0020676685962826014, 0.0021484510507434607, 0.00222923350520432, 0.002310016192495823, 0.002390798646956682, 0.0024715811014175415, 0.0025523637887090445, 0.0026331462431699038, 0.002713928697630763, 0.0027947111520916224, 0.0028754936065524817, 0.0029562762938439846, 0.003037058748304844, 0.003117841202765703, 0.003198623890057206, 0.0032794063445180655, 0.0033601887989789248, 0.003440971253439784, 0.0035217537079006433, 0.0036025361623615026, 0.003683318616822362, 0.0037641010712832212, 0.003844883758574724, 0.0039256662130355835, 0.004006448667496443, 0.004087231121957302, 0.004168013576418161, 0.004248796030879021, 0.00432957848533988, 0.004410360939800739, 0.004491143394261599, 0.004571925848722458, 0.0046527087688446045, 0.004733491223305464, 0.004814273677766323, 0.004895056132227182], "values": [1, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 3, 3, 2, 3, 5, 1, 1, 1, 2, 2, 1, 2, 2, 1, 4, 1, 3, 1, 0, 2, 1, 3, 1, 1, 0, 1, 0, 0, 1]}, "parameters/mlp_extractor.policy_net.0.weight": {"values": [1, 1, 0, 2, 2, 6, 7, 13, 15, 17, 30, 47, 61, 83, 110, 138, 185, 190, 209, 273, 335, 384, 483, 499, 554, 611, 684, 721, 747, 811, 820, 779, 801, 765, 735, 689, 644, 577, 557, 451, 423, 352, 316, 287, 224, 199, 147, 106, 81, 51, 49, 35, 30, 15, 15, 7, 3, 2, 1, 3, 0, 0, 0, 1], "bins": [-0.3382904827594757, -0.32743504643440247, -0.3165796399116516, -0.30572420358657837, -0.2948687970638275, -0.2840133607387543, -0.2731579542160034, -0.2623025178909302, -0.2514471113681793, -0.24059168994426727, -0.22973626852035522, -0.21888084709644318, -0.20802542567253113, -0.19717000424861908, -0.18631458282470703, -0.1754591464996338, -0.16460372507572174, -0.1537483036518097, -0.14289288222789764, -0.1320374608039856, -0.12118203938007355, -0.1103266179561615, -0.09947118908166885, -0.0886157676577568, -0.07776033878326416, -0.06690491735935211, -0.056049495935440063, -0.04519407078623772, -0.03433864936232567, -0.02348322793841362, -0.012627802789211273, -0.0017723813652992249, 0.009083032608032227, 0.019938454031944275, 0.030793877318501472, 0.04164930060505867, 0.05250472202897072, 0.06336013972759247, 0.07421556860208511, 0.08507099002599716, 0.09592640399932861, 0.10678182542324066, 0.11763724684715271, 0.12849266827106476, 0.1393480896949768, 0.15020351111888885, 0.1610589325428009, 0.17191436886787415, 0.1827697902917862, 0.19362521171569824, 0.2044806331396103, 0.21533605456352234, 0.2261914759874344, 0.23704689741134644, 0.24790233373641968, 0.25875774025917053, 0.2696131765842438, 0.280468612909317, 0.29132401943206787, 0.3021794557571411, 0.31303486227989197, 0.3238902986049652, 0.33474570512771606, 0.3456011414527893, 0.35645654797554016], "_type": "histogram"}, "parameters/features_extractor.network.7.bias": {"_type": "histogram", "bins": [-0.003265947801992297, -0.00317069748416543, -0.0030754473991692066, -0.002980197314172983, -0.002884946996346116, -0.002789696678519249, -0.0026944465935230255, -0.002599196508526802, -0.002503946190699935, -0.002408695872873068, -0.0023134457878768444, -0.002218195702880621, -0.002122945385053754, -0.0020276950672268867, -0.0019324449822306633, -0.001837194780819118, -0.0017419445794075727, -0.0016466943779960275, -0.0015514441765844822, -0.001456193975172937, -0.0013609437737613916, -0.0012656935723498464, -0.001170443370938301, -0.0010751931695267558, -0.0009799429681152105, -0.0008846927667036653, -0.00078944256529212, -0.0006941923638805747, -0.0005989421624690294, -0.0005036919610574841, -0.0004084417596459389, -0.0003131915582343936, -0.00021794135682284832, -0.00012269115541130304, -2.7440953999757767e-05, 6.780924741178751e-05, 0.0001630594488233328, 0.00025830965023487806, 0.00035355985164642334, 0.0004488100530579686, 0.0005440602544695139, 0.0006393104558810592, 0.0007345606572926044, 0.0008298108587041497, 0.000925061060115695, 0.0010203112615272403, 0.0011155614629387856, 0.0012108116643503308, 0.001306061865761876, 0.0014013120671734214, 0.0014965622685849667, 0.001591812469996512, 0.0016870626714080572, 0.0017823128728196025, 0.0018775630742311478, 0.001972813159227371, 0.0020680634770542383, 0.0021633137948811054, 0.002258563879877329, 0.0023538139648735523, 0.0024490642827004194, 0.0025443146005272865, 0.00263956468552351, 0.0027348147705197334, 0.0028300650883466005], "values": [1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 5, 4, 2, 8, 14, 7, 10, 12, 16, 10, 6, 5, 4, 1, 6, 3, 2, 4, 1, 3, 5, 0, 3, 4, 2, 2, 0, 1, 7, 1, 4, 3, 3, 6, 5, 3, 8, 8, 3, 9, 11, 14, 8, 6, 2, 3, 1, 2, 0, 2, 0, 0, 2]}, "avg10_score": -273.55, "train/policy_gradient_loss": -0.0004989735898561776, "train/learning_rate": 9.999999747378752e-06, "parameters/log_std": {"_type": "histogram", "bins": [-0.0010138057405129075, -0.0009782923152670264, -0.0009427788900211453, -0.0009072654647752643, -0.0008717520395293832, -0.0008362386142835021, -0.000800725189037621, -0.0007652117637917399, -0.0007296983385458589, -0.0006941849132999778, -0.0006586714880540967, -0.0006231580628082156, -0.0005876446375623345, -0.0005521312123164535, -0.0005166177870705724, -0.00048110433272086084, -0.0004455908783711493, -0.0004100774531252682, -0.00037456402787938714, -0.00033905060263350606, -0.000303537177387625, -0.0002680237521417439, -0.00023251029779203236, -0.00019699687254615128, -0.00016148341819643974, -0.00012596999295055866, -9.045656042871997e-05, -5.494312790688127e-05, -1.9429702661000192e-05, 1.608372258488089e-05, 5.15971623826772e-05, 8.711058762855828e-05, 0.0001226239837706089, 0.00015813740901648998, 0.00019365083426237106, 0.00022916427406016737, 0.0002646776847541332, 0.0003001911100000143, 0.00033570456434972584, 0.0003712179895956069, 0.00040673138573765755, 0.00044224481098353863, 0.0004777582362294197, 0.0005132716614753008, 0.0005487850867211819, 0.000584298511967063, 0.000619811937212944, 0.0006553253624588251, 0.0006908388459123671, 0.0007263522711582482, 0.0007618656964041293, 0.0007973791216500103, 0.0008328925468958914, 0.0008684059721417725, 0.0009039194555953145, 0.0009394328808411956, 0.0009749463060870767, 0.0010104597313329577, 0.0010459731565788388, 0.00108148658182472, 0.001117000007070601, 0.001152513432316482, 0.0011880268575623631, 0.0012235402828082442, 0.0012590537080541253], "values": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, "_step": 326, "global_step": 24576, "parameters/features_extractor.network.4.weight": {"_type": "histogram", "bins": [-0.23849494755268097, -0.2307681441307068, -0.2230413407087326, -0.21531453728675842, -0.20758774876594543, -0.19986093044281006, -0.19213414192199707, -0.1844073385000229, -0.1766805350780487, -0.16895373165607452, -0.16122692823410034, -0.15350012481212616, -0.14577332139015198, -0.138046532869339, -0.1303197294473648, -0.12259292602539062, -0.11486612260341644, -0.10713931918144226, -0.09941251575946808, -0.0916857197880745, -0.08395891636610031, -0.07623211294412613, -0.06850531697273254, -0.06077851355075836, -0.05305171012878418, -0.04532490670681, -0.037598107010126114, -0.02987130545079708, -0.022144503891468048, -0.014417700469493866, -0.006690900772809982, 0.0010358989238739014, 0.008762717247009277, 0.01648951880633831, 0.024216320365667343, 0.03194312006235123, 0.03966992348432541, 0.04739672690629959, 0.055123526602983475, 0.06285032629966736, 0.07057712972164154, 0.07830393314361572, 0.0860307365655899, 0.09375753253698349, 0.10148433595895767, 0.10921113938093185, 0.11693793535232544, 0.12466473877429962, 0.1323915421962738, 0.14011834561824799, 0.14784514904022217, 0.15557195246219635, 0.16329875588417053, 0.17102554440498352, 0.1787523478269577, 0.18647915124893188, 0.19420595467090607, 0.20193275809288025, 0.20965956151485443, 0.2173863649368286, 0.2251131534576416, 0.23283997178077698, 0.24056676030158997, 0.24829356372356415, 0.25602036714553833], "values": [1, 1, 2, 5, 4, 5, 8, 17, 29, 29, 46, 74, 106, 107, 191, 229, 304, 404, 536, 626, 700, 870, 1026, 1160, 1318, 1427, 1695, 1750, 1805, 1847, 1928, 1870, 1894, 1779, 1770, 1681, 1503, 1397, 1211, 1065, 892, 741, 615, 533, 398, 320, 250, 212, 127, 104, 80, 53, 41, 30, 18, 10, 4, 6, 4, 1, 0, 1, 3, 1]}, "parameters/features_extractor.network.2.weight": {"values": [1, 0, 1, 2, 3, 4, 8, 9, 18, 23, 39, 50, 63, 92, 101, 142, 215, 233, 281, 394, 466, 591, 690, 786, 820, 1008, 1122, 1223, 1323, 1465, 1535, 1510, 1603, 1636, 1562, 1587, 1548, 1459, 1349, 1228, 1041, 914, 885, 714, 628, 515, 395, 361, 270, 220, 161, 148, 74, 68, 44, 46, 31, 21, 16, 11, 5, 2, 1, 7], "_type": "histogram", "bins": [-0.2555253207683563, -0.24782463908195496, -0.2401239573955536, -0.23242327570915222, -0.22472257912158966, -0.2170218974351883, -0.20932121574878693, -0.20162053406238556, -0.193919837474823, -0.18621915578842163, -0.17851847410202026, -0.1708177924156189, -0.16311709582805634, -0.15541641414165497, -0.1477157324552536, -0.14001505076885223, -0.13231436908245087, -0.1246136873960495, -0.11691299825906754, -0.10921231657266617, -0.1015116274356842, -0.09381094574928284, -0.08611026406288147, -0.0784095823764801, -0.07070890069007874, -0.06300821900367737, -0.055307529866695404, -0.04760684818029404, -0.03990616276860237, -0.032205477356910706, -0.02450479567050934, -0.016804110258817673, -0.009103432297706604, -0.001402747817337513, 0.006297936663031578, 0.013998620212078094, 0.02169930562376976, 0.029399991035461426, 0.03710067272186279, 0.04480135813355446, 0.05250205099582672, 0.06020273640751839, 0.06790342181921005, 0.07560410350561142, 0.08330479264259338, 0.09100547432899475, 0.09870615601539612, 0.10640683770179749, 0.11410751938819885, 0.12180820107460022, 0.1295088827610016, 0.13720956444740295, 0.14491026103496552, 0.15261094272136688, 0.16031162440776825, 0.16801230609416962, 0.17571300268173218, 0.18341368436813354, 0.1911143660545349, 0.19881504774093628, 0.20651574432849884, 0.2142164260149002, 0.22191710770130157, 0.22961778938770294, 0.2373184710741043]}, "episode Highspeed": 51.70259820751078, "_wandb": {"runtime": 985}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/run-Test Run 1.wandb b/ROAR_gym/wandb/run-20220621_235148-Test Run 1/run-Test Run 1.wandb
deleted file mode 100644
index 9d1cbfe..0000000
Binary files a/ROAR_gym/wandb/run-20220621_235148-Test Run 1/run-Test Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220621_235255-Test Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220621_235255-Test Run 1/files/config.yaml
deleted file mode 100644
index 0db8089..0000000
--- a/ROAR_gym/wandb/run-20220621_235255-Test Run 1/files/config.yaml	
+++ /dev/null
@@ -1,289 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x0000027E58E878C8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2emodel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655826775
-    t:
-      1:
-      - 1
-      - 41
-      3:
-      - 13
-      - 14
-      - 16
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x0000027E591CF948>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000027E58F61F88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x0000027E27D678B8>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
-    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x0000027E591A2D48>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655824503.2783575
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/Test Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220621_235255-Test Run 1/run-Test Run 1.wandb b/ROAR_gym/wandb/run-20220621_235255-Test Run 1/run-Test Run 1.wandb
deleted file mode 100644
index 224f665..0000000
Binary files a/ROAR_gym/wandb/run-20220621_235255-Test Run 1/run-Test Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/code/ROAR_Gym/e2eModel.py b/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/code/ROAR_Gym/e2eModel.py
deleted file mode 100644
index 5d146a1..0000000
--- a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/code/ROAR_Gym/e2eModel.py	
+++ /dev/null
@@ -1,352 +0,0 @@
-"""
-IMPORTANT
-IF YOU HAVE NOT RUN THIS FILE AS 'ADMIN' (OR OPENED PYCHARM AS 'ADMIN')
-STOP AND RESTART WITH ADMIN PRIVILEGES
-
-TODO: Before Running this file make the following changes:
-1. Add the following line:
-    self._last_obs = np.nan_to_num(self._last_obs)
-
-to the following file:
-    ROAR\venv\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py
-
-2. Add this line after line 167 such that:
-with th.no_grad():
-    # Convert to pytorch tensor or to TensorDict
-    self._last_obs = np.nan_to_num(self._last_obs)
-    obs_tensor = obs_as_tensor(self._last_obs, self.device)
-    actions, values, log_probs = self.policy.forward(obs_tensor)
-
-3. Add: #############################################################################still needed?###########
-
-        data.pop('_last_obs')
-
-    in  line 652 of base_class.py for sb3
-    possible location of file: \envs\ROAR\Lib\site-packages\stable_baselines3\common\base_class.py
-
-4. Change for on_policy_algorithm.py, in function collect_rollouts add:
-
-        self.env.reset()
-
-    before the following while loop:
-
-        while n_steps < n_rollout_steps:
-"""
-
-# IMPORTS
-# imports for logs and warnings
-import warnings
-import logging
-
-from typing import Optional, Dict
-
-# imports for weights and biases integration
-import wandb
-from wandb.integration.sb3 import WandbCallback
-
-# imports for file path handling
-import os
-import sys
-from pathlib import Path
-sys.path.append(Path(os.getcwd()).parent.as_posix())
-
-# imports for reading and writing json config files
-import json
-
-# imports from the ROAR module
-from ROAR_Sim.configurations.configuration import Configuration as CarlaConfig
-from ROAR.configurations.configuration import Configuration as AgentConfig
-from ROAR.agent_module.agent import Agent
-from ROAR.agent_module.rl_e2e_ppo_agent import RLe2ePPOAgent
-from ROAR.agent_module.forward_only_agent import ForwardOnlyAgent   # testing stuff
-
-# imports for reinforcement learning
-import gym
-import torch as th
-from stable_baselines3.ppo.ppo import PPO
-from stable_baselines3.ppo.policies import CnnPolicy
-from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps, CallbackList, BaseCallback
-from stable_baselines3.common.monitor import Monitor
-from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder
-
-
-# imports for helper functions and torch cnn models
-from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN, YunhaoModifiedAtariCNN
-
-
-
-# imports from config files
-from configurations.ppo_configuration import PPO_params, misc_params, wandb_saves
-agent_config = AgentConfig.parse_file(Path("configurations/agent_configuration.json"))
-carla_config = CarlaConfig.parse_file(Path("configurations/carla_configuration.json"))
-
-# Setup for the loggers
-logging.getLogger("tensorflow").setLevel(logging.ERROR)
-logging.getLogger("numpy").setLevel(logging.ERROR)
-warnings.filterwarnings('ignore')
-try:
-    from ROAR_Gym.envs.roar_env import LoggingCallback
-except:
-    from ROAR_Gym.ROAR_Gym.envs.roar_env import LoggingCallback
-
-# os.environ["CUDA_VISIBLE_DEVICES"]="0,1"
-#  Parameters & Constants
-CUDA_VISIBLE_DEVICES = 1
-RUN_FPS = misc_params["run_fps"]
-MODEL_DIR = misc_params["model_directory"]
-WANDB_CONFIG_DIR = "configurations/wandb_configuration.json"
-
-
-def json_read_write(file, load_var=None, mode='r'):
-    """
-
-    Args:
-        file: address of json file to be loaded
-        load_var: variable to be written to, or read from
-        mode: 'r' to read from json, 'w' to write to json
-
-    Returns:
-        load_var: variable with data that has been read in mode 'r'
-                  original variable in case of 'w'
-
-    """
-    if mode == 'r':
-        with open(file, mode) as json_file:
-            load_var = json.load(json_file)  # Reading the file
-            print(f"{file} json config read successful")
-            json_file.close()
-            return load_var
-    elif mode == 'w':
-        assert load_var is not None, "load_var was None"
-        with open(file, mode) as json_file:
-            json.dump(load_var, json_file)  # Writing to the file
-            print(f"{file} json config write successful")
-            json_file.close()
-            return load_var
-    else:
-        assert mode == 'w' or 'r', f"unsupported mode type: {mode}"
-        return None
-
-# TODO track previously used run IDs
-def wandb_run_init(wandb_hp_config, load=False, requested_run_id=None, use_random_id=False):
-
-    wandb_config = json_read_write(
-        file=WANDB_CONFIG_DIR,
-        mode='r',
-    )
-
-    if load is True:
-        # Load run_id from the config file
-        run_id = wandb_config["run_id"]
-        assert run_id != "", "Run ID not set even though previous run exists"
-    else:
-        # Create wandb run id
-        if requested_run_id is not None:
-            run_id = requested_run_id
-        else:
-            assert use_random_id is True, "RUN ID NOT SET FOR NEW RUN"
-            run_id = wandb.util.generate_id()
-
-        # Store run_id to wandb_configuration file
-        wandb_config["run_id"] = run_id
-        wandb_config = json_read_write(
-            file=WANDB_CONFIG_DIR,
-            load_var=wandb_config,
-            mode='w',
-        )
-
-    # Create a wandb run variable
-    wandb.tensorboard.patch(
-        tensorboardX=False,
-        pytorch=True,
-    )
-    run = wandb.init(
-        project=wandb_config["project_name"],
-        entity=wandb_config["entity"],  # Change to whoever wants to log the data
-        config=wandb_hp_config,
-        # sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics
-        save_code=True,  # Allows us to check diff of code between runs
-        resume="allow",
-        # magic=True,
-        id=run_id,
-        name=run_id,
-        #monitor_gym=True,  # auto-upload the videos of agents playing the game,
-    )
-
-    return run
-
-
-class Tensorboard_Faster_Logger(BaseCallback):
-    """
-    Callback for saving a model (the check is done every ``check_freq`` steps)
-    based on the training reward (in practice, we recommend using ``EvalCallback``).
-
-    :param check_freq:
-    :param log_dir: Path to the folder where the model will be saved.
-      It must contains the file created by the ``Monitor`` wrapper.
-    :param verbose: Verbosity level.
-    """
-    def __init__(self, check_freq: int, verbose: int = 1):
-        super(Tensorboard_Faster_Logger, self).__init__(verbose)
-        self.check_freq = check_freq
-
-    # def _init_callback(self) -> None:
-
-    def _on_step(self) -> bool:
-        if self.n_calls % self.check_freq == 0:
-            self.logger.dump(self.num_timesteps)
-        return True
-
-
-def main(pass_num):
-    # Create the gym environment using the configs
-    env = gym.make(
-        id=misc_params["env_name"],
-        params={
-            "agent_config": agent_config,
-            "carla_config": carla_config,
-            "ego_agent_class": RLe2ePPOAgent,
-        }
-    )
-    #print(th.cuda.is_available())
-
-    # Setting the feature extract or based on the environment mode
-    if env.mode == 'baseline':
-        policy_kwargs = dict(
-            features_extractor_class=YunhaoModifiedAtariCNN, #Atari_PPO_Adapted_CNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-    else:
-        policy_kwargs = dict(
-            features_extractor_class=CustomMaxPoolCNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-
-    # training kwargs for PPO init
-    training_kwargs = PPO_params
-
-    # wandb config for current run hyper-parameters
-    wandb_hp_config = {
-        "policy_type": "CnnPolicy",
-        "env_name": misc_params["env_name"],
-        "training_kwargs": training_kwargs,
-    }
-
-    # Try to find latest model path if we have trained previously
-    latest_model_path = find_latest_model(MODEL_DIR)
-    print(latest_model_path)
-    # FIXME wandb may continue old run if the run crashes before it is logged
-    if latest_model_path is None:
-        # Create new wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=False,
-            requested_run_id=misc_params["run_name"],
-        )
-
-        # Create model with tensorboard log
-        model = PPO(
-            CnnPolicy,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs
-        )
-
-        print(f"Starting new run {run.id}")
-    else:
-        # Load wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=True,
-        )
-
-        # Load the model
-        model = PPO.load(
-            latest_model_path,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs,
-        )
-
-        print(f"Loading old run {run.id}")
-
-    print("Model Loaded Successfully")
-
-    # Defining Callback Functions
-
-    logging_callback = LoggingCallback(model=model)
-
-    faster_Logging_Callback = Tensorboard_Faster_Logger(check_freq=wandb_saves["model_save_freq"])
-
-    checkpoint_callback = CheckpointCallback(
-        save_freq=wandb_saves["model_save_freq"],
-        verbose=2,
-        save_path=(MODEL_DIR / "logs").as_posix()
-    )
-
-    event_callback = EveryNTimesteps(
-        n_steps=wandb_saves["model_save_freq"],
-        callback=checkpoint_callback
-    )
-
-    wandb_callback = WandbCallback(
-        verbose=2,
-        model_save_path=f"models/{run.id}",
-        gradient_save_freq=PPO_params["n_steps"],
-        model_save_freq=wandb_saves["model_save_freq"],
-    )
-
-    callbacks = CallbackList([
-        wandb_callback,
-        checkpoint_callback,
-        event_callback,
-        logging_callback
-        # faster_Logging_Callback
-    ])
-
-    # Begin learning
-    model = model.learn(
-        total_timesteps=misc_params["total_timesteps"],
-        callback=callbacks,
-        reset_num_timesteps=False,
-        # tb_log_name=wandb_config["run_id"],
-    )
-
-    # Save Model
-    model.save(MODEL_DIR / f"roar_e2e_model_{pass_num}")  # TODO fix naming convention
-    print("Successful Save!")
-    # # Finish wandb run
-    # run.finish()
-
-if __name__ == '__main__':
-    logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
-                        datefmt="%H:%M:%S", level=logging.INFO)
-    logging.getLogger("Controller").setLevel(logging.ERROR)
-    logging.getLogger("SimplePathFollowingLocalPlanner").setLevel(logging.ERROR)
-    i=0
-    while True:
-        main(i)
-        i += 1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
diff --git a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/config.yaml
deleted file mode 100644
index 8338ae8..0000000
--- a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,46 +0,0 @@
-wandb_version: 1
-
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655863217
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 13
-      - 14
-      - 16
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-policy_type:
-  desc: null
-  value: CnnPolicy
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
diff --git a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/diff.patch b/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/diff.patch
deleted file mode 100644
index 4de5e05..0000000
--- a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/diff.patch	
+++ /dev/null
@@ -1,86 +0,0 @@
-diff --git a/ROAR_gym/configurations/ppo_configuration.py b/ROAR_gym/configurations/ppo_configuration.py
-index 17b1310..df404a5 100644
---- a/ROAR_gym/configurations/ppo_configuration.py
-+++ b/ROAR_gym/configurations/ppo_configuration.py
-@@ -11,7 +11,7 @@ misc_params = {
-   "env_name": 'roar-e2e-ppo-v0',
-   "run_fps": 8,  # TODO Link to the environment RUN_FPS
-   "model_directory": Path("./output/Yunhao_PPOe2e_Input_Change"),
--  "run_name": "Test Run 1",
-+  "run_name": "CNN Modified Run 1",
-   "total_timesteps": int(1e6),
- }
- 
-diff --git a/ROAR_gym/configurations/wandb_configuration.json b/ROAR_gym/configurations/wandb_configuration.json
-index cfb2610..8a4106f 100644
---- a/ROAR_gym/configurations/wandb_configuration.json
-+++ b/ROAR_gym/configurations/wandb_configuration.json
-@@ -1 +1 @@
--{"run_id": "Test Run 1", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
-\ No newline at end of file
-+{"run_id": "CNN Modified Run 1", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
-\ No newline at end of file
-diff --git a/ROAR_gym/e2eModel.py b/ROAR_gym/e2eModel.py
-index f0a3788..5d146a1 100644
---- a/ROAR_gym/e2eModel.py
-+++ b/ROAR_gym/e2eModel.py
-@@ -71,7 +71,7 @@ from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder
- 
- 
- # imports for helper functions and torch cnn models
--from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN
-+from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN, YunhaoModifiedAtariCNN
- 
- 
- 
-@@ -213,7 +213,7 @@ def main(pass_num):
-     # Setting the feature extract or based on the environment mode
-     if env.mode == 'baseline':
-         policy_kwargs = dict(
--            features_extractor_class=Atari_PPO_Adapted_CNN,
-+            features_extractor_class=YunhaoModifiedAtariCNN, #Atari_PPO_Adapted_CNN,
-             features_extractor_kwargs=dict(features_dim=256)
-         )
-     else:
-diff --git a/ROAR_gym/ppo_util.py b/ROAR_gym/ppo_util.py
-index 6702b99..fb8e2d9 100644
---- a/ROAR_gym/ppo_util.py
-+++ b/ROAR_gym/ppo_util.py
-@@ -173,7 +173,6 @@ class CustomMaxPoolCNN_attention(BaseFeaturesExtractor):
-         return self.fullStack(observations[0])
- 
- 
--
- class CustomMaxPoolCNN(BaseFeaturesExtractor):
-     """
-     the CNN network that interleaves convolution & maxpooling layers, used in a
-@@ -424,6 +423,29 @@ class Atari_PPO_Adapted_CNN(BaseFeaturesExtractor):
-         observations=observations.view(observations.shape[0],-1,*observations.shape[3:])
-         return self.network(observations)
- 
-+class YunhaoModifiedAtariCNN(BaseFeaturesExtractor):
-+    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):
-+        super(Atari_PPO_Adapted_CNN, self).__init__(observation_space,features_dim)
-+        channels = observation_space.shape[0]*observation_space.shape[1]
-+        self.network = nn.Sequential(
-+            # Scale(1/255),
-+            layer_init(nn.Conv2d(channels, 32, 8, stride=4)),
-+            nn.ReLU(),
-+            layer_init(nn.Conv2d(32, 64, 4, stride=2)),
-+            nn.ReLU(),
-+            layer_init(nn.Conv2d(64, 64, 3, stride=1)),
-+            nn.ReLU(),
-+            layer_init(nn.Conv2d(64,16,1,stride=1)), #added
-+            nn.ReLU(),
-+            nn.Flatten(),
-+            layer_init(nn.Linear(784, features_dim)), #shrinked
-+            # nn.ReLU(),
-+        )
-+
-+    def forward(self, observations: th.Tensor) -> th.Tensor:
-+        observations=observations.view(observations.shape[0],-1,*observations.shape[3:])
-+        return self.network(observations)
-+
- def find_latest_model(root_path: Path) -> Optional[Path]:
-     import os
-     from pathlib import Path
diff --git a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/requirements.txt b/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/requirements.txt
deleted file mode 100644
index 65dc1e5..0000000
--- a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/requirements.txt	
+++ /dev/null
@@ -1,130 +0,0 @@
-absl-py==1.1.0
-anyio==3.6.1
-argon2-cffi-bindings==21.2.0
-argon2-cffi==21.3.0
-attrs==21.4.0
-babel==2.10.3
-backcall==0.2.0
-beautifulsoup4==4.11.1
-bleach==5.0.0
-cachetools==5.2.0
-carla==0.9.10
-certifi==2022.6.15
-cffi==1.15.0
-charset-normalizer==2.0.12
-click==8.1.3
-cloudpickle==2.1.0
-colorama==0.4.5
-cycler==0.11.0
-debugpy==1.6.0
-decorator==5.1.1
-defusedxml==0.7.1
-deprecation==2.1.0
-docker-pycreds==0.4.0
-entrypoints==0.4
-fastjsonschema==2.15.3
-fonttools==4.33.3
-gitdb==4.0.9
-gitpython==3.1.27
-google-auth-oauthlib==0.4.6
-google-auth==2.8.0
-grpcio==1.46.3
-gym==0.21.0
-idna==3.3
-importlib-metadata==4.11.4
-importlib-resources==5.8.0
-ipykernel==6.15.0
-ipython-genutils==0.2.0
-ipython==7.34.0
-ipywidgets==7.7.0
-jedi==0.18.1
-jinja2==3.1.2
-json5==0.9.8
-jsonschema==4.6.0
-jupyter-client==7.3.4
-jupyter-core==4.10.0
-jupyter-packaging==0.12.2
-jupyter-server==1.17.1
-jupyterlab-pygments==0.2.2
-jupyterlab-server==2.14.0
-jupyterlab-widgets==1.1.0
-jupyterlab==3.4.3
-kiwisolver==1.4.3
-markdown==3.3.7
-markupsafe==2.1.1
-matplotlib-inline==0.1.3
-matplotlib==3.5.2
-mistune==0.8.4
-nbclassic==0.3.7
-nbclient==0.6.4
-nbconvert==6.5.0
-nbformat==5.4.0
-nest-asyncio==1.5.5
-notebook-shim==0.1.0
-notebook==6.4.12
-numpy==1.21.6
-oauthlib==3.2.0
-open3d==0.15.1
-packaging==21.3
-pandas==1.3.5
-pandocfilters==1.5.0
-parso==0.8.3
-pathtools==0.1.2
-pickleshare==0.7.5
-pillow==9.1.1
-pip==22.1.2
-prometheus-client==0.14.1
-promise==2.3
-prompt-toolkit==3.0.29
-protobuf==3.19.4
-psutil==5.9.1
-pyasn1-modules==0.2.8
-pyasn1==0.4.8
-pycparser==2.21
-pydantic==1.9.1
-pygame==2.1.2
-pygments==2.12.0
-pyparsing==3.0.9
-pyrsistent==0.18.1
-python-dateutil==2.8.2
-pytz==2022.1
-pywin32==304
-pywinpty==2.0.5
-pyyaml==6.0
-pyzmq==23.2.0
-requests-oauthlib==1.3.1
-requests==2.28.0
-rsa==4.8
-scipy==1.7.3
-send2trash==1.8.0
-sentry-sdk==1.5.12
-setproctitle==1.2.3
-setuptools==62.6.0
-shortuuid==1.0.9
-six==1.16.0
-smmap==5.0.0
-sniffio==1.2.0
-soupsieve==2.3.2.post1
-stable-baselines3==1.5.0
-tensorboard-data-server==0.6.1
-tensorboard-plugin-wit==1.8.1
-tensorboard==2.9.1
-termcolor==1.1.0
-terminado==0.15.0
-tinycss2==1.1.1
-tomlkit==0.11.0
-torch==1.11.0
-torchvision==0.12.0
-tornado==6.1
-traitlets==5.3.0
-typing-extensions==4.2.0
-urllib3==1.26.9
-wandb==0.12.11
-wcwidth==0.2.5
-webencodings==0.5.1
-websocket-client==1.3.3
-werkzeug==2.1.2
-wheel==0.37.1
-widgetsnbextension==3.6.0
-yaspin==2.1.0
-zipp==3.8.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/wandb-metadata.json b/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/wandb-metadata.json
deleted file mode 100644
index 6d43e15..0000000
--- a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/wandb-metadata.json	
+++ /dev/null
@@ -1,24 +0,0 @@
-{
-    "os": "Windows-10-10.0.22000-SP0",
-    "python": "3.7.9",
-    "heartbeatAt": "2022-06-22T02:00:19.140337",
-    "startedAt": "2022-06-22T02:00:17.424019",
-    "docker": null,
-    "gpu": "NVIDIA GeForce RTX 3080",
-    "gpu_count": 1,
-    "cpu_count": 20,
-    "cuda": null,
-    "args": [],
-    "state": "running",
-    "program": "e2eModel.py",
-    "codePath": "ROAR_Gym\\e2eModel.py",
-    "git": {
-        "remote": "https://github.com/ToiletCommander/ROAR_RL",
-        "commit": "932723adf08dc8f0c0fe7f8317822ae1da9daced"
-    },
-    "email": "1745500559@qq.com",
-    "root": "D:/Programming/Subjects/ROAR/ROAR_RL",
-    "host": "Windys-Desktop",
-    "username": "cxcyh",
-    "executable": "D:\\Programming\\Subjects\\ROAR\\ROAR_RL\\roar-dev\\Scripts\\python.exe"
-}
diff --git a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 6a2353d..0000000
--- a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 2}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/run-CNN Modified Run 1.wandb b/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/run-CNN Modified Run 1.wandb
deleted file mode 100644
index a6bbd29..0000000
Binary files a/ROAR_gym/wandb/run-20220622_100017-CNN Modified Run 1/run-CNN Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/files/config.yaml
deleted file mode 100644
index 47c4ba9..0000000
--- a/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,47 +0,0 @@
-wandb_version: 1
-
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655863468
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 5
-      - 13
-      - 14
-      - 16
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-policy_type:
-  desc: null
-  value: CnnPolicy
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
diff --git a/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 4ac1ba9..0000000
--- a/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 3}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/run-CNN Modified Run 1.wandb b/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/run-CNN Modified Run 1.wandb
deleted file mode 100644
index d771ba8..0000000
Binary files a/ROAR_gym/wandb/run-20220622_100428-CNN Modified Run 1/run-CNN Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/config.yaml
deleted file mode 100644
index 36a3961..0000000
--- a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,297 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
-    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
-    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
-    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
-    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
-    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
-    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
-    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
-    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
-    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
-    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
-    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
-    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
-    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000002949FA1D288>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1655863482
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 1
-      - 3
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x00000294933C5708>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0.0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000293EDB25A88>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x00000293EDC64438>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
-    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
-    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
-    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
-    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x00000293EDD86E48>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1655863484.9925604
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/events.out.tfevents.1655863487.Windys-Desktop.10552.0 b/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/events.out.tfevents.1655863487.Windys-Desktop.10552.0
deleted file mode 120000
index f016758..0000000
--- a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/events.out.tfevents.1655863487.Windys-Desktop.10552.0	
+++ /dev/null
@@ -1 +0,0 @@
-D:/Programming/Subjects/ROAR/ROAR_RL/ROAR_Gym/runs/CNN Modified Run 1/PPO_0/events.out.tfevents.1655863487.Windys-Desktop.10552.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/model.zip b/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/model.zip
deleted file mode 120000
index f854bf6..0000000
--- a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/model.zip	
+++ /dev/null
@@ -1 +0,0 @@
-D:/Programming/Subjects/ROAR/ROAR_RL/ROAR_Gym/models/CNN Modified Run 1/model.zip
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index f9c0bac..0000000
--- a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"Episode reward": -269.9, "Checkpoint reached": 60, "largest_steps": 240, "highest_speed": 100.13699132178076, "Episode_Sim_Time": 400, "episode Highspeed": 65.30104815818997, "avg10_checkpoints": 88.63636363636364, "avg10_score": -272.43181818181824, "_timestamp": 1655864396.7995486, "_runtime": 920, "_step": 377, "parameters/log_std": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.00112298340536654, -0.0010460230987519026, -0.0009690626757219434, -0.0008921023108996451, -0.0008151419460773468, -0.0007381815812550485, -0.0006612212164327502, -0.0005842608516104519, -0.0005073004867881536, -0.00043034012196585536, -0.00035337975714355707, -0.0002764193923212588, -0.0001994590274989605, -0.0001224986626766622, -4.553829785436392e-05, 3.142206696793437e-05, 0.00010838243179023266, 0.00018534279661253095, 0.00026230316143482924, 0.0003392635262571275, 0.0004162238910794258, 0.0004931842559017241, 0.0005701446207240224, 0.0006471049855463207, 0.000724065350368619, 0.0008010257151909173, 0.0008779860800132155, 0.0009549464448355138, 0.0010319068096578121, 0.0011088671162724495, 0.0011858275393024087, 0.001262787962332368, 0.0013397480361163616, 0.001416708342730999, 0.0014936687657609582, 0.0015706291887909174, 0.0016475894954055548, 0.0017245498020201921, 0.0018015102250501513, 0.0018784706480801105, 0.001955430954694748, 0.0020323912613093853, 0.0021093515679240227, 0.0021863121073693037, 0.002263272413983941, 0.0023402327205985785, 0.0024171932600438595, 0.002494153566658497, 0.0025711138732731342, 0.0026480741798877716, 0.002725034486502409, 0.00280199502594769, 0.0028789553325623274, 0.0029559156391769648, 0.003032876178622246, 0.003109836485236883, 0.0031867967918515205, 0.003263757098466158, 0.0033407174050807953, 0.0034176779445260763, 0.0034946382511407137, 0.003571598557755351, 0.003648559097200632, 0.0037255194038152695, 0.003802479710429907]}, "parameters/features_extractor.network.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 9.0, 12.0, 12.0, 22.0, 31.0, 52.0, 72.0, 99.0, 124.0, 168.0, 262.0, 262.0, 329.0, 435.0, 534.0, 587.0, 702.0, 765.0, 905.0, 1021.0, 1046.0, 1160.0, 1203.0, 1182.0, 1259.0, 1322.0, 1277.0, 1224.0, 1137.0, 1044.0, 1006.0, 889.0, 762.0, 696.0, 599.0, 526.0, 414.0, 303.0, 278.0, 221.0, 176.0, 110.0, 85.0, 81.0, 40.0, 48.0, 28.0, 20.0, 11.0, 6.0, 5.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.20483674108982086, -0.19817747175693512, -0.19151820242404938, -0.18485894799232483, -0.1781996786594391, -0.17154040932655334, -0.1648811399936676, -0.15822187066078186, -0.15156260132789612, -0.14490333199501038, -0.13824406266212463, -0.1315847933292389, -0.12492553144693375, -0.1182662695646286, -0.11160700023174286, -0.10494773089885712, -0.09828846901655197, -0.09162919968366623, -0.08496993780136108, -0.07831066846847534, -0.0716513991355896, -0.06499212980270386, -0.05833286792039871, -0.05167359858751297, -0.045014336705207825, -0.03835507109761238, -0.03169580176472664, -0.025036536157131195, -0.018377268686890602, -0.01171800121665001, -0.005058735609054565, 0.0016005337238311768, 0.008259803056716919, 0.014919070526957512, 0.021578337997198105, 0.02823760360479355, 0.03489687293767929, 0.041556138545274734, 0.04821540415287018, 0.05487467348575592, 0.06153394281864166, 0.0681932121515274, 0.07485247403383255, 0.08151174336671829, 0.08817101269960403, 0.09483027458190918, 0.10148954391479492, 0.10814881324768066, 0.11480807512998581, 0.12146734446287155, 0.1281266063451767, 0.13478587567806244, 0.14144514501094818, 0.14810441434383392, 0.15476366877555847, 0.1614229381084442, 0.16808220744132996, 0.1747414767742157, 0.18140074610710144, 0.18806001543998718, 0.19471926987171173, 0.20137853920459747, 0.20803780853748322, 0.21469707787036896, 0.2213563472032547]}, "parameters/features_extractor.network.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.0024143403861671686, -0.0022064493969082832, -0.001998558174818754, -0.0017906671855598688, -0.0015827761963009834, -0.001374885207042098, -0.0011669941013678908, -0.0009591029956936836, -0.0007512120064347982, -0.0005433209589682519, -0.00033542991150170565, -0.00012753886403515935, 8.035218343138695e-05, 0.00028824317269027233, 0.0004961342783644795, 0.0007040253840386868, 0.0009119163732975721, 0.0011198073625564575, 0.0013276984682306647, 0.001535589573904872, 0.0017434805631637573, 0.0019513715524226427, 0.002159262541681528, 0.002367153763771057, 0.0025750447530299425, 0.002782935742288828, 0.002990826964378357, 0.0031987179536372423, 0.0034066089428961277, 0.003614499932155013, 0.0038223909214138985, 0.0040302821435034275, 0.0042381733655929565, 0.004446064587682486, 0.004653955344110727, 0.004861846566200256, 0.005069737322628498, 0.005277628544718027, 0.005485519766807556, 0.005693410523235798, 0.005901301745325327, 0.006109192967414856, 0.006317083723843098, 0.006524974945932627, 0.006732866168022156, 0.0069407569244503975, 0.0071486481465399265, 0.007356539368629456, 0.007564430125057697, 0.007772321347147226, 0.007980212569236755, 0.008188103325664997, 0.008395994082093239, 0.008603885769844055, 0.008811776526272297, 0.009019667282700539, 0.009227558970451355, 0.009435449726879597, 0.009643341414630413, 0.009851232171058655, 0.010059122927486897, 0.010267013683915138, 0.010474905371665955, 0.010682796128094196, 0.010890686884522438]}, "parameters/features_extractor.network.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 4.0, 12.0, 16.0, 15.0, 28.0, 40.0, 65.0, 75.0, 110.0, 137.0, 174.0, 264.0, 348.0, 418.0, 498.0, 571.0, 740.0, 861.0, 1028.0, 1094.0, 1302.0, 1410.0, 1487.0, 1580.0, 1678.0, 1603.0, 1677.0, 1675.0, 1623.0, 1582.0, 1436.0, 1400.0, 1233.0, 1089.0, 1036.0, 872.0, 717.0, 632.0, 517.0, 406.0, 327.0, 260.0, 179.0, 155.0, 113.0, 84.0, 57.0, 53.0, 27.0, 27.0, 6.0, 11.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0], "bins": [-0.26188039779663086, -0.25375989079475403, -0.245639368891716, -0.23751884698867798, -0.22939833998680115, -0.22127781808376312, -0.2131572961807251, -0.20503678917884827, -0.19691626727581024, -0.18879574537277222, -0.18067523837089539, -0.17255471646785736, -0.16443419456481934, -0.1563136875629425, -0.14819316565990448, -0.14007264375686646, -0.13195213675498962, -0.1238316223025322, -0.11571110785007477, -0.10759058594703674, -0.09947007149457932, -0.09134955704212189, -0.08322903513908386, -0.07510852068662643, -0.066988006234169, -0.05886749178171158, -0.05074697360396385, -0.042626455426216125, -0.0345059409737587, -0.02638542652130127, -0.018264908343553543, -0.010144390165805817, -0.002023845911026001, 0.006096670404076576, 0.014217186719179153, 0.02233770303428173, 0.030458219349384308, 0.038578733801841736, 0.04669925197958946, 0.05481977015733719, 0.06294028460979462, 0.07106079906225204, 0.07918131351470947, 0.0873018354177475, 0.09542234987020493, 0.10354286432266235, 0.11166338622570038, 0.1197839006781578, 0.12790441513061523, 0.13602493703365326, 0.1441454440355301, 0.15226596593856812, 0.16038647294044495, 0.16850699484348297, 0.176627516746521, 0.18474802374839783, 0.19286854565143585, 0.20098906755447388, 0.2091095745563507, 0.21723009645938873, 0.22535061836242676, 0.2334711253643036, 0.2415916472673416, 0.24971216917037964, 0.25783267617225647]}, "parameters/features_extractor.network.2.bias": {"_type": "histogram", "values": [2.0, 4.0, 0.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 1.0, 3.0, 2.0, 0.0, 5.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.002694893628358841, -0.0024931076914072037, -0.00229132198728621, -0.002089536050334573, -0.0018877501133829355, -0.00168596429284662, -0.0014841784723103046, -0.0012823925353586674, -0.001080606714822352, -0.0008788208360783756, -0.0006770349573343992, -0.0004752491367980838, -0.00027346325805410743, -7.167737931013107e-05, 0.00013010844122618437, 0.00033189437817782164, 0.0005336801987141371, 0.0007354660774581134, 0.0009372519562020898, 0.0011390377767384052, 0.0013408237136900425, 0.001542609534226358, 0.0017443953547626734, 0.0019461812917143106, 0.0021479669958353043, 0.0023497529327869415, 0.002551538636907935, 0.0027533245738595724, 0.0029551105108112097, 0.0031568962149322033, 0.0033586821518838406, 0.003560468088835478, 0.003762254025787115, 0.003964039962738752, 0.00416582589969039, 0.00436761137098074, 0.004569397307932377, 0.004771183244884014, 0.004972969181835651, 0.005174755118787289, 0.005376541055738926, 0.005578326992690563, 0.0057801129296422005, 0.005981898866593838, 0.006183684337884188, 0.006385470274835825, 0.006587256211787462, 0.0067890421487390995, 0.0069908276200294495, 0.007192613556981087, 0.007394399493932724, 0.007596185430884361, 0.007797970902174711, 0.007999757304787636, 0.008201543241739273, 0.00840332917869091, 0.008605115115642548, 0.008806901052594185, 0.009008686989545822, 0.00921047292649746, 0.009412258863449097, 0.009614044800400734, 0.009815830737352371, 0.010017616674304008, 0.010219401679933071]}, "parameters/features_extractor.network.4.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 2.0, 7.0, 11.0, 9.0, 18.0, 33.0, 40.0, 50.0, 78.0, 108.0, 157.0, 196.0, 267.0, 335.0, 397.0, 533.0, 628.0, 760.0, 882.0, 1039.0, 1210.0, 1350.0, 1469.0, 1604.0, 1769.0, 1852.0, 1889.0, 1932.0, 1941.0, 1911.0, 1857.0, 1667.0, 1628.0, 1520.0, 1275.0, 1155.0, 1036.0, 868.0, 750.0, 600.0, 489.0, 365.0, 313.0, 258.0, 177.0, 127.0, 98.0, 53.0, 49.0, 34.0, 21.0, 17.0, 11.0, 5.0, 4.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.23807509243488312, -0.23033463954925537, -0.22259418666362762, -0.21485373377799988, -0.20711328089237213, -0.19937282800674438, -0.19163239002227783, -0.1838919222354889, -0.17615148425102234, -0.1684110313653946, -0.16067057847976685, -0.1529301255941391, -0.14518967270851135, -0.1374492198228836, -0.12970876693725586, -0.12196832150220871, -0.11422786116600037, -0.10648740828037262, -0.09874695539474487, -0.09100650250911713, -0.08326604962348938, -0.07552559673786163, -0.06778515130281448, -0.06004469841718674, -0.05230425298213959, -0.04456380009651184, -0.036823347210884094, -0.029082898050546646, -0.0213424451649189, -0.013601992279291153, -0.005861543118953705, 0.0018789097666740417, 0.009619355201721191, 0.017359808087348938, 0.025100259110331535, 0.03284071013331413, 0.04058116301894188, 0.048321615904569626, 0.056062065064907074, 0.06380251795053482, 0.07154297828674316, 0.07928343117237091, 0.08702388405799866, 0.0947643369436264, 0.10250478982925415, 0.1102452427148819, 0.11798568814992905, 0.1257261335849762, 0.13346658647060394, 0.1412070393562317, 0.14894749224185944, 0.15668794512748718, 0.16442839801311493, 0.17216885089874268, 0.17990928888320923, 0.18764975666999817, 0.19539019465446472, 0.20313064754009247, 0.21087110042572021, 0.21861155331134796, 0.2263520061969757, 0.23409245908260345, 0.2418329119682312, 0.24957334995269775, 0.2573138177394867]}, "parameters/features_extractor.network.4.bias": {"_type": "histogram", "values": [2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 0.0, 4.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.0037220390513539314, -0.003564669517800212, -0.0034072999842464924, -0.003249930450692773, -0.0030925609171390533, -0.002935191383585334, -0.0027778218500316143, -0.0026204525493085384, -0.0024630827829241753, -0.0023057132493704557, -0.0021483437158167362, -0.0019909741822630167, -0.0018336046487092972, -0.0016762351151555777, -0.00151886569801718, -0.0013614961644634604, -0.0012041267473250628, -0.0010467572137713432, -0.0008893876802176237, -0.0007320182048715651, -0.0005746486713178456, -0.00041727913776412606, -0.00025990966241806746, -0.00010254012886434793, 5.482928827404976e-05, 0.00021219880727585405, 0.00036956832627765834, 0.0005269378307275474, 0.0006843073642812669, 0.0008416768978349864, 0.000999046373181045, 0.0011564159067347646, 0.001313785556703806, 0.0014711550902575254, 0.001628524623811245, 0.0017858941573649645, 0.001943263690918684, 0.0021006332244724035, 0.002258002758026123, 0.002415372058749199, 0.002572741825133562, 0.0027301113586872816, 0.002887480892241001, 0.0030448504257947206, 0.00320221995934844, 0.0033595894929021597, 0.003516959026455879, 0.003674328327178955, 0.0038316978607326746, 0.003989067394286394, 0.00414643669500947, 0.004303806461393833, 0.004461175762116909, 0.004618545528501272, 0.004775914829224348, 0.004933284595608711, 0.005090653896331787, 0.005248023197054863, 0.005405392963439226, 0.005562762264162302, 0.005720132030546665, 0.005877501331269741, 0.006034871097654104, 0.00619224039837718, 0.006349610164761543]}, "parameters/features_extractor.network.6.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 5.0, 3.0, 8.0, 1.0, 7.0, 10.0, 13.0, 18.0, 15.0, 22.0, 27.0, 24.0, 39.0, 32.0, 30.0, 40.0, 46.0, 51.0, 36.0, 43.0, 49.0, 33.0, 40.0, 42.0, 45.0, 37.0, 25.0, 33.0, 32.0, 32.0, 19.0, 20.0, 20.0, 21.0, 22.0, 10.0, 15.0, 6.0, 6.0, 5.0, 6.0, 5.0, 10.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5540357828140259, -0.5353848338127136, -0.5167338848114014, -0.4980829954147339, -0.47943204641342163, -0.4607810974121094, -0.4421301782131195, -0.42347925901412964, -0.4048283100128174, -0.3861773610115051, -0.36752644181251526, -0.3488755226135254, -0.33022457361221313, -0.3115736246109009, -0.292922705411911, -0.27427178621292114, -0.2556208372116089, -0.23696990311145782, -0.21831896901130676, -0.1996680349111557, -0.18101710081100464, -0.16236616671085358, -0.14371523261070251, -0.12506429851055145, -0.10641336441040039, -0.08776243031024933, -0.06911149621009827, -0.050460562109947205, -0.03180962800979614, -0.01315869390964508, 0.0054922401905059814, 0.024143174290657043, 0.042794108390808105, 0.06144504249095917, 0.08009597659111023, 0.09874691069126129, 0.11739784479141235, 0.13604877889156342, 0.15469971299171448, 0.17335064709186554, 0.1920015811920166, 0.21065251529216766, 0.22930344939231873, 0.2479543834924698, 0.26660531759262085, 0.2852562665939331, 0.303907185792923, 0.32255810499191284, 0.3412090539932251, 0.35986000299453735, 0.3785109221935272, 0.3971618413925171, 0.41581279039382935, 0.4344637393951416, 0.45311465859413147, 0.47176557779312134, 0.4904165267944336, 0.5090674757957458, 0.5277184247970581, 0.5463693141937256, 0.5650202631950378, 0.5836712121963501, 0.6023221015930176, 0.6209730505943298, 0.6396239995956421]}, "parameters/features_extractor.network.6.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.001586601254530251, -0.0014813964953646064, -0.00137619161978364, -0.0012709868606179953, -0.0011657821014523506, -0.0010605772258713841, -0.0009553724667057395, -0.0008501676493324339, -0.0007449628319591284, -0.0006397580145858228, -0.0005345531972125173, -0.0004293484380468726, -0.00032414362067356706, -0.0002189388033002615, -0.00011373404413461685, -8.529226761311293e-06, 9.667559061199427e-05, 0.0002018803934333846, 0.00030708519625477493, 0.00041228998452425003, 0.0005174948018975556, 0.0006226996192708611, 0.0007279043784365058, 0.0008331091958098114, 0.0009383138967677951, 0.0010435186559334397, 0.0011487235315144062, 0.0012539282906800508, 0.0013591330498456955, 0.001464337925426662, 0.0015695426845923066, 0.001674747560173273, 0.0017799525521695614, 0.001885157311335206, 0.0019903620705008507, 0.002095567062497139, 0.0022007718216627836, 0.0023059765808284283, 0.002411181339994073, 0.0025163860991597176, 0.002621591091156006, 0.0027267958503216505, 0.002832000609487295, 0.0029372056014835835, 0.003042410360649228, 0.0031476151198148727, 0.0032528198789805174, 0.003358024638146162, 0.0034632293973118067, 0.0035684341564774513, 0.003673638915643096, 0.0037788436748087406, 0.003884048666805029, 0.00398925319314003, 0.004094458185136318, 0.0041996631771326065, 0.0043048677034676075, 0.004410072695463896, 0.004515277221798897, 0.004620482213795185, 0.004725686740130186, 0.004830891732126474, 0.004936096258461475, 0.005041301250457764, 0.005146506242454052]}, "parameters/features_extractor.network.9.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 5.0, 5.0, 8.0, 11.0, 39.0, 48.0, 84.0, 99.0, 170.0, 294.0, 424.0, 622.0, 866.0, 1160.0, 1638.0, 2195.0, 2745.0, 3511.0, 4303.0, 5204.0, 6200.0, 7292.0, 8277.0, 9404.0, 10219.0, 10750.0, 11344.0, 11678.0, 11683.0, 11247.0, 11048.0, 10399.0, 9448.0, 8652.0, 7680.0, 6600.0, 5469.0, 4674.0, 3702.0, 3059.0, 2330.0, 1749.0, 1338.0, 953.0, 666.0, 487.0, 318.0, 223.0, 134.0, 103.0, 43.0, 42.0, 22.0, 19.0, 6.0, 3.0, 6.0, 0.0, 1.0, 1.0], "bins": [-0.2368641197681427, -0.2294933795928955, -0.22212262451648712, -0.21475188434123993, -0.20738112926483154, -0.20001038908958435, -0.19263964891433716, -0.18526889383792877, -0.17789815366268158, -0.1705274134874344, -0.163156658411026, -0.1557859182357788, -0.14841516315937042, -0.14104442298412323, -0.13367366790771484, -0.12630292773246765, -0.11893218010663986, -0.11156143248081207, -0.10419068485498428, -0.0968199372291565, -0.0894491970539093, -0.08207844942808151, -0.07470770180225372, -0.06733696162700653, -0.059966206550598145, -0.052595458924770355, -0.045224715024232864, -0.037853967398405075, -0.030483221635222435, -0.023112475872039795, -0.015741728246212006, -0.008370984345674515, -0.001000240445137024, 0.0063705057837069035, 0.01374125201255083, 0.021111998707056046, 0.028482744470238686, 0.035853490233421326, 0.043224237859249115, 0.050594981759786606, 0.0579657256603241, 0.06533647328615189, 0.07270722091197968, 0.08007796108722687, 0.08744870871305466, 0.09481945633888245, 0.10219020396471024, 0.10956095159053802, 0.11693169921636581, 0.1243024468421936, 0.1316731870174408, 0.13904394209384918, 0.14641468226909637, 0.15378543734550476, 0.16115617752075195, 0.16852691769599915, 0.17589767277240753, 0.18326841294765472, 0.1906391680240631, 0.1980099081993103, 0.2053806632757187, 0.21275140345096588, 0.22012215852737427, 0.22749289870262146, 0.23486363887786865]}, "parameters/features_extractor.network.9.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 5.0, 2.0, 2.0, 1.0, 6.0, 6.0, 10.0, 9.0, 10.0, 10.0, 10.0, 1.0, 8.0, 4.0, 6.0, 7.0, 4.0, 4.0, 4.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 5.0, 4.0, 0.0, 0.0, 1.0, 3.0, 1.0, 8.0, 4.0, 4.0, 7.0, 7.0, 11.0, 15.0, 13.0, 13.0, 11.0, 4.0, 3.0, 4.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.003848309861496091, -0.003721710294485092, -0.00359511049464345, -0.0034685106948018074, -0.0033419111277908087, -0.00321531156077981, -0.0030887117609381676, -0.002962111961096525, -0.0028355123940855265, -0.0027089128270745277, -0.0025823130272328854, -0.002455713227391243, -0.0023291136603802443, -0.0022025140933692455, -0.002075914293527603, -0.0019493146101012826, -0.001822714926674962, -0.0016961152432486415, -0.001569515559822321, -0.0014429158763960004, -0.0013163161929696798, -0.0011897165095433593, -0.0010631168261170387, -0.0009365171426907182, -0.0008099174592643976, -0.0006833177758380771, -0.0005567180924117565, -0.00043011840898543596, -0.0003035187255591154, -0.00017691904213279486, -5.0319358706474304e-05, 7.628032471984625e-05, 0.00020288024097681046, 0.000329479924403131, 0.00045607960782945156, 0.0005826792912557721, 0.0007092789746820927, 0.0008358786581084132, 0.0009624783415347338, 0.0010890780249610543, 0.0012156777083873749, 0.0013422773918136954, 0.001468877075240016, 0.0015954767586663365, 0.001722076442092657, 0.0018486761255189776, 0.001975275808945298, 0.002101875375956297, 0.0022284751757979393, 0.0023550749756395817, 0.0024816745426505804, 0.002608274109661579, 0.0027348739095032215, 0.002861473709344864, 0.0029880732763558626, 0.0031146728433668613, 0.0032412726432085037, 0.003367872443050146, 0.003494472010061145, 0.0036210715770721436, 0.003747671376913786, 0.0038742711767554283, 0.004000870510935783, 0.004127470310777426, 0.004254070110619068]}, "parameters/mlp_extractor.policy_net.0.weight": {"_type": "histogram", "values": [4.0, 4.0, 4.0, 8.0, 11.0, 13.0, 26.0, 27.0, 28.0, 44.0, 60.0, 68.0, 80.0, 126.0, 140.0, 164.0, 209.0, 253.0, 332.0, 355.0, 381.0, 437.0, 493.0, 565.0, 530.0, 618.0, 684.0, 720.0, 713.0, 724.0, 749.0, 708.0, 713.0, 696.0, 720.0, 639.0, 560.0, 525.0, 493.0, 435.0, 362.0, 382.0, 284.0, 275.0, 195.0, 175.0, 145.0, 112.0, 81.0, 77.0, 61.0, 54.0, 33.0, 20.0, 16.0, 19.0, 10.0, 6.0, 9.0, 6.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.3044450581073761, -0.29444971680641174, -0.2844543755054474, -0.27445903420448303, -0.2644636929035187, -0.2544683516025543, -0.24447299540042877, -0.23447765409946442, -0.22448231279850006, -0.2144869714975357, -0.20449163019657135, -0.194496288895607, -0.18450093269348145, -0.1745055913925171, -0.16451025009155273, -0.15451490879058838, -0.14451956748962402, -0.13452422618865967, -0.12452888488769531, -0.11453353613615036, -0.104538194835186, -0.09454285353422165, -0.0845475047826767, -0.07455216348171234, -0.06455682218074799, -0.05456148087978363, -0.044566135853528976, -0.03457079082727432, -0.024575449526309967, -0.014580108225345612, -0.004584763199090958, 0.005410581827163696, 0.015405923128128052, 0.025401266291737556, 0.03539660945534706, 0.045391954481601715, 0.05538729578256607, 0.06538263708353043, 0.07537798583507538, 0.08537332713603973, 0.09536866843700409, 0.10536400973796844, 0.1153593510389328, 0.12535469233989716, 0.1353500485420227, 0.14534538984298706, 0.15534073114395142, 0.16533607244491577, 0.17533141374588013, 0.18532675504684448, 0.19532209634780884, 0.2053174376487732, 0.21531277894973755, 0.2253081202507019, 0.23530347645282745, 0.2452988177537918, 0.25529414415359497, 0.2652894854545593, 0.2752848267555237, 0.28528016805648804, 0.2952755093574524, 0.30527085065841675, 0.3152661919593811, 0.32526153326034546, 0.3352569043636322]}, "parameters/mlp_extractor.policy_net.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 4.0, 3.0, 1.0, 2.0, 19.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.000628679059445858, -0.0006072067772038281, -0.0005857345531694591, -0.0005642622709274292, -0.0005427900468930602, -0.0005213177646510303, -0.0004998454824090004, -0.0004783732583746314, -0.00045690100523643196, -0.0004354287520982325, -0.00041395649896003306, -0.0003924842458218336, -0.0003710119635798037, -0.0003495397395454347, -0.0003280674573034048, -0.00030659520416520536, -0.0002851229510270059, -0.00026365069788880646, -0.00024217844475060701, -0.00022070617706049234, -0.0001992339239222929, -0.00017776167078409344, -0.00015628940309397876, -0.00013481714995577931, -0.00011334486771374941, -9.187261457554996e-05, -7.04003541613929e-05, -4.8928093747235835e-05, -2.7455840609036386e-05, -5.9835874708369374e-06, 1.548868021927774e-05, 3.696093335747719e-05, 5.8433215599507093e-05, 7.990546873770654e-05, 0.0001013777291518636, 0.00012284998956602067, 0.00014432224270422012, 0.00016579449584241956, 0.00018726676353253424, 0.0002087390166707337, 0.00023021124070510268, 0.00025168349384330213, 0.0002731557469815016, 0.0002946280292235315, 0.0003161002532579005, 0.0003375725354999304, 0.00035904478863812983, 0.0003805170417763293, 0.0004019893240183592, 0.00042346157715655863, 0.0004449338302947581, 0.000466406112536788, 0.000487878336571157, 0.0005093506188131869, 0.0005308229010552168, 0.0005522951250895858, 0.0005737673491239548, 0.0005952396313659847, 0.0006167118554003537, 0.0006381841376423836, 0.0006596563616767526, 0.0006811286439187825, 0.0007026009261608124, 0.0007240731501951814, 0.0007455454324372113]}, "parameters/mlp_extractor.policy_net.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 7.0, 4.0, 4.0, 11.0, 12.0, 17.0, 18.0, 31.0, 29.0, 30.0, 53.0, 36.0, 66.0, 62.0, 77.0, 90.0, 104.0, 114.0, 120.0, 119.0, 141.0, 140.0, 166.0, 177.0, 165.0, 172.0, 176.0, 170.0, 193.0, 163.0, 176.0, 140.0, 125.0, 124.0, 110.0, 113.0, 100.0, 84.0, 80.0, 77.0, 59.0, 50.0, 39.0, 29.0, 30.0, 17.0, 18.0, 12.0, 12.0, 4.0, 10.0, 3.0, 6.0, 3.0, 2.0, 1.0, 1.0], "bins": [-0.6355253458023071, -0.6165757775306702, -0.5976262092590332, -0.5786766409873962, -0.5597270727157593, -0.5407775640487671, -0.5218279957771301, -0.5028784275054932, -0.4839288592338562, -0.46497929096221924, -0.4460297226905823, -0.4270801842212677, -0.40813061594963074, -0.3891810476779938, -0.3702315092086792, -0.35128194093704224, -0.3323323726654053, -0.3133828043937683, -0.29443323612213135, -0.2754836976528168, -0.2565341293811798, -0.23758456110954285, -0.21863500773906708, -0.1996854543685913, -0.18073588609695435, -0.16178631782531738, -0.1428367644548416, -0.12388720363378525, -0.10493764281272888, -0.08598808199167252, -0.06703852117061615, -0.04808896780014038, -0.029139339923858643, -0.010189779102802277, 0.00875978171825409, 0.027709342539310455, 0.04665890336036682, 0.06560846418142319, 0.08455802500247955, 0.10350757837295532, 0.12245714664459229, 0.14140671491622925, 0.16035626828670502, 0.1793058216571808, 0.19825538992881775, 0.2172049582004547, 0.23615451157093048, 0.25510406494140625, 0.2740536332130432, 0.2930032014846802, 0.31195276975631714, 0.3309023082256317, 0.3498518764972687, 0.36880144476890564, 0.3877509832382202, 0.4067005515098572, 0.42565011978149414, 0.4445996880531311, 0.46354925632476807, 0.48249879479408264, 0.501448392868042, 0.5203979015350342, 0.5393474698066711, 0.5582970380783081, 0.5772466063499451]}, "parameters/mlp_extractor.policy_net.2.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 5.0, 4.0, 11.0, 6.0, 6.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0005116321844980121, -0.0004974657204002142, -0.00048329922719858587, -0.00046913273399695754, -0.00045496626989915967, -0.00044079977669753134, -0.000426633283495903, -0.00041246681939810514, -0.0003983003553003073, -0.00038413386209867895, -0.0003699673980008811, -0.00035580090479925275, -0.0003416344407014549, -0.00032746794749982655, -0.0003133014542981982, -0.00029913499020040035, -0.000284968496998772, -0.0002708020037971437, -0.0002566355396993458, -0.0002424690464977175, -0.00022830258239991963, -0.0002141360891982913, -0.0001999696105485782, -0.0001858031318988651, -0.00017163663869723678, -0.00015747016004752368, -0.00014330368139781058, -0.00012913718819618225, -0.00011497071682242677, -0.00010080423817271367, -8.663775224704295e-05, -7.247127359732985e-05, -5.830478039570153e-05, -4.413830174598843e-05, -2.9971819458296522e-05, -1.5805337170604616e-05, -1.6388585208915174e-06, 1.2527620128821582e-05, 2.6694106054492295e-05, 4.0860584704205394e-05, 5.5027048802003264e-05, 6.919352745171636e-05, 8.336000610142946e-05, 9.752649202710018e-05, 0.00011169297067681327, 0.000125859456602484, 0.0001400259352521971, 0.00015419241390191019, 0.0001683589071035385, 0.0001825253857532516, 0.0001966918644029647, 0.00021085835760459304, 0.0002250248217023909, 0.00023919131490401924, 0.00025335780810564756, 0.00026752427220344543, 0.0002816907363012433, 0.00029585722950287163, 0.0003100236936006695, 0.00032419018680229783, 0.0003383566509000957, 0.00035252314410172403, 0.00036668963730335236, 0.0003808561014011502, 0.00039502259460277855]}, "parameters/mlp_extractor.value_net.0.weight": {"_type": "histogram", "values": [3.0, 2.0, 5.0, 4.0, 8.0, 22.0, 18.0, 25.0, 39.0, 31.0, 57.0, 79.0, 95.0, 144.0, 167.0, 221.0, 257.0, 276.0, 350.0, 427.0, 461.0, 535.0, 598.0, 654.0, 681.0, 717.0, 783.0, 795.0, 732.0, 738.0, 798.0, 748.0, 714.0, 663.0, 630.0, 564.0, 502.0, 452.0, 447.0, 381.0, 292.0, 266.0, 226.0, 165.0, 155.0, 111.0, 92.0, 59.0, 70.0, 32.0, 28.0, 20.0, 11.0, 10.0, 5.0, 3.0, 6.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.30998149514198303, -0.29931893944740295, -0.2886563837528229, -0.2779938280582428, -0.26733124256134033, -0.25666868686676025, -0.24600613117218018, -0.2353435754776001, -0.22468101978302002, -0.21401846408843994, -0.20335590839385986, -0.1926933377981186, -0.1820307821035385, -0.17136822640895844, -0.16070565581321716, -0.15004310011863708, -0.139380544424057, -0.12871798872947693, -0.11805542558431625, -0.10739286243915558, -0.0967303067445755, -0.08606775104999542, -0.07540518790483475, -0.06474262475967407, -0.054080069065093994, -0.04341750964522362, -0.03275495022535324, -0.022092390805482864, -0.011429831385612488, -0.0007672719657421112, 0.009895287454128265, 0.02055785059928894, 0.03122037649154663, 0.04188293591141701, 0.052545495331287384, 0.06320805847644806, 0.07387061417102814, 0.08453316986560822, 0.09519573301076889, 0.10585829615592957, 0.11652085185050964, 0.12718340754508972, 0.1378459632396698, 0.14850853383541107, 0.15917108952999115, 0.16983364522457123, 0.1804962158203125, 0.19115877151489258, 0.20182132720947266, 0.21248388290405273, 0.2231464385986328, 0.23380900919437408, 0.24447156488895416, 0.25513413548469543, 0.2657966911792755, 0.2764592468738556, 0.28712180256843567, 0.29778435826301575, 0.3084469139575958, 0.3191094696521759, 0.32977205514907837, 0.34043461084365845, 0.3510971665382385, 0.3617597222328186, 0.3724222779273987]}, "parameters/mlp_extractor.value_net.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 1.0, 5.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 7.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.003972472157329321, -0.003832321148365736, -0.003692170139402151, -0.003552019130438566, -0.0034118681214749813, -0.0032717171125113964, -0.003131565870717168, -0.002991414861753583, -0.002851263852789998, -0.002711112843826413, -0.0025709618348628283, -0.0024308108258992434, -0.002290659584105015, -0.00215050857514143, -0.002010357566177845, -0.00187020655721426, -0.0017300555482506752, -0.0015899045392870903, -0.0014497535303235054, -0.0013096024049445987, -0.0011694513959810138, -0.0010293003870174289, -0.0008891493198461831, -0.0007489982526749372, -0.0006088472437113523, -0.000468696205643937, -0.00032854516757652164, -0.00018839412950910628, -4.824309144169092e-05, 9.190791752189398e-05, 0.0002320589846931398, 0.0003722100518643856, 0.0005123615264892578, 0.0006525125354528427, 0.0007926636026240885, 0.0009328146697953343, 0.0010729656787589192, 0.0012131166877225041, 0.0013532678131014109, 0.0014934188220649958, 0.0016335698310285807, 0.0017737208399921656, 0.0019138718489557505, 0.0020540228579193354, 0.002194174099713564, 0.002334325108677149, 0.0024744761176407337, 0.0026146271266043186, 0.0027547781355679035, 0.0028949291445314884, 0.0030350801534950733, 0.0031752311624586582, 0.003315382171422243, 0.003455533180385828, 0.0035956844221800566, 0.0037358354311436415, 0.0038759864401072264, 0.004016137681901455, 0.00415628869086504, 0.004296439699828625, 0.00443659070879221, 0.0045767417177557945, 0.004716892726719379, 0.004857043735682964, 0.004997194744646549]}, "parameters/mlp_extractor.value_net.2.weight": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 1.0, 7.0, 5.0, 3.0, 6.0, 15.0, 21.0, 31.0, 31.0, 42.0, 44.0, 44.0, 61.0, 63.0, 67.0, 79.0, 99.0, 111.0, 113.0, 125.0, 134.0, 156.0, 179.0, 162.0, 189.0, 160.0, 173.0, 161.0, 182.0, 151.0, 169.0, 153.0, 145.0, 117.0, 134.0, 113.0, 93.0, 78.0, 87.0, 68.0, 71.0, 56.0, 38.0, 36.0, 30.0, 24.0, 15.0, 14.0, 10.0, 10.0, 7.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.577177882194519, -0.5578351020812988, -0.5384922623634338, -0.5191494822502136, -0.4998067021369934, -0.4804638922214508, -0.4611210823059082, -0.441778302192688, -0.4224355220794678, -0.40309271216392517, -0.38374993205070496, -0.36440712213516235, -0.34506434202194214, -0.32572153210639954, -0.30637872219085693, -0.2870359420776367, -0.2676931321620941, -0.2483503371477127, -0.2290075421333313, -0.2096647322177887, -0.19032195210456848, -0.17097914218902588, -0.15163634717464447, -0.13229355216026306, -0.11295074224472046, -0.09360794723033905, -0.07426515221595764, -0.054922349750995636, -0.03557955473661423, -0.01623675972223282, 0.003106042742729187, 0.022448837757110596, 0.04179161787033081, 0.06113441288471222, 0.08047720789909363, 0.09982001036405563, 0.11916280537843704, 0.13850560784339905, 0.15784840285778046, 0.17719119787216187, 0.19653397798538208, 0.2158767729997635, 0.2352195680141449, 0.2545623779296875, 0.2739051580429077, 0.2932479679584503, 0.3125907778739929, 0.33193355798721313, 0.35127636790275574, 0.37061917781829834, 0.38996195793151855, 0.40930476784706116, 0.42864754796028137, 0.447990357875824, 0.4673331379890442, 0.4866759479045868, 0.5060187578201294, 0.5253615379333496, 0.5447043776512146, 0.5640471577644348, 0.583389937877655, 0.6027327179908752, 0.6220755577087402, 0.6414183378219604, 0.6607611179351807]}, "parameters/mlp_extractor.value_net.2.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 7.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.027528326958417892, -0.026700060814619064, -0.025871796533465385, -0.025043530389666557, -0.02421526610851288, -0.02338699996471405, -0.022558733820915222, -0.021730467677116394, -0.020902203395962715, -0.020073937252163887, -0.019245672971010208, -0.01841740682721138, -0.017589140683412552, -0.016760876402258873, -0.015932610258460045, -0.015104345045983791, -0.014276079833507538, -0.013447814621031284, -0.01261954940855503, -0.011791283264756203, -0.01096301805227995, -0.010134752839803696, -0.009306486696004868, -0.008478221483528614, -0.0076499562710523605, -0.006821691058576107, -0.005993425380438566, -0.005165159702301025, -0.004336894489824772, -0.0035086292773485184, -0.0026803635992109776, -0.0018520979210734367, -0.0010238345712423325, -0.0001955691259354353, 0.0006326963193714619, 0.001460961764678359, 0.002289227209985256, 0.0031174924224615097, 0.0039457581005990505, 0.004774023778736591, 0.005602288991212845, 0.006430554203689098, 0.007258819881826639, 0.00808708555996418, 0.008915350772440434, 0.009743615984916687, 0.010571882128715515, 0.011400147341191769, 0.012228412553668022, 0.013056677766144276, 0.01388494297862053, 0.014713209122419357, 0.01554147433489561, 0.016369739547371864, 0.017198005691170692, 0.01802626997232437, 0.0188545361161232, 0.019682802259922028, 0.020511066541075706, 0.021339332684874535, 0.022167596966028214, 0.02299586310982704, 0.02382412925362587, 0.024652395397424698, 0.025480659678578377]}, "parameters/action_net.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 4.0, 4.0, 6.0, 13.0, 11.0, 19.0, 18.0, 11.0, 15.0, 15.0, 14.0, 14.0, 8.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.01475998479872942, -0.01432120893150568, -0.01388243306428194, -0.0134436571970582, -0.013004881329834461, -0.012566105462610722, -0.012127328664064407, -0.011688552796840668, -0.011249776929616928, -0.010811001062393188, -0.010372225195169449, -0.00993344932794571, -0.00949467346072197, -0.00905589759349823, -0.00861712172627449, -0.00817834585905075, -0.007739569991827011, -0.0073007941246032715, -0.006862018257379532, -0.006423242390155792, -0.005984466522932053, -0.005545690655708313, -0.005106914322823286, -0.004668138455599546, -0.0042293621227145195, -0.00379058625549078, -0.0033518103882670403, -0.002913034288212657, -0.0024742584209889174, -0.0020354825537651777, -0.0015967064537107944, -0.0011579305864870548, -0.0007191551849246025, -0.00028037925949320197, 0.00015839666593819857, 0.00059717264957726, 0.0010359485168009996, 0.0014747243840247393, 0.0019135004840791225, 0.002352276351302862, 0.0027910517528653145, 0.003229827620089054, 0.0036686034873127937, 0.004107379354536533, 0.004546155221760273, 0.004984931088984013, 0.0054237074218690395, 0.005862483289092779, 0.006301259621977806, 0.006740035489201546, 0.007178811356425285, 0.007617587223649025, 0.008056363090872765, 0.008495138958096504, 0.008933914825320244, 0.009372690692543983, 0.009811466559767723, 0.010250242426991463, 0.010689018294215202, 0.011127794161438942, 0.011566570028662682, 0.012005345895886421, 0.01244412176311016, 0.0128828976303339, 0.013321674428880215]}, "parameters/action_net.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0006915316334925592, -0.0006730504683218896, -0.0006545692449435592, -0.0006360880797728896, -0.0006176069146022201, -0.0005991256912238896, -0.00058064452605322, -0.0005621633026748896, -0.00054368213750422, -0.0005252009723335505, -0.00050671974895522, -0.00048823858378455043, -0.0004697573895100504, -0.0004512761952355504, -0.00043279503006488085, -0.00041431383579038084, -0.0003958326415158808, -0.0003773514472413808, -0.0003588702529668808, -0.00034038908779621124, -0.00032190789352171123, -0.0003034266992472112, -0.00028494553407654166, -0.00026646433980204165, -0.00024798314552754164, -0.00022950195125304163, -0.00021102077153045684, -0.00019253959180787206, -0.00017405839753337204, -0.00015557720325887203, -0.00013709602353628725, -0.00011861484381370246, -0.00010013359133154154, -8.165240433299914e-05, -6.317121733445674e-05, -4.4690030335914344e-05, -2.6208843337371945e-05, -7.727656338829547e-06, 1.0753530659712851e-05, 2.9234710382297635e-05, 4.771590465679765e-05, 6.619709165534005e-05, 8.467827865388244e-05, 0.00010315946565242484, 0.00012164065265096724, 0.00014012184692546725, 0.00015860302664805204, 0.00017708420637063682, 0.00019556540064513683, 0.00021404659491963685, 0.00023252777464222163, 0.0002510089543648064, 0.0002694901486393064, 0.00028797134291380644, 0.000306452508084476, 0.000324933702358976, 0.000343414896633476, 0.00036189609090797603, 0.00038037728518247604, 0.0003988584503531456, 0.0004173396446276456, 0.0004358208389021456, 0.0004543020040728152, 0.0004727831983473152, 0.0004912643926218152]}, "parameters/value_net.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 4.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 5.0, 4.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.3650323450565338, -0.3546864092350006, -0.3443405032157898, -0.3339945673942566, -0.3236486315727234, -0.3133027255535126, -0.30295678973197937, -0.29261088371276855, -0.28226494789123535, -0.27191901206970215, -0.26157310605049133, -0.25122717022895813, -0.24088124930858612, -0.2305353283882141, -0.2201893925666809, -0.2098434716463089, -0.1994975507259369, -0.18915162980556488, -0.17880570888519287, -0.16845977306365967, -0.15811385214328766, -0.14776793122291565, -0.13742199540138245, -0.12707607448101044, -0.11673015356063843, -0.10638423264026642, -0.09603830426931381, -0.0856923758983612, -0.0753464549779892, -0.06500053405761719, -0.05465460568666458, -0.044308677315711975, -0.03396272659301758, -0.02361680194735527, -0.013270877301692963, -0.002924952656030655, 0.007420971989631653, 0.01776689663529396, 0.02811282128095627, 0.038458749651908875, 0.048804670572280884, 0.05915059521794319, 0.0694965198636055, 0.0798424482345581, 0.09018836915493011, 0.10053429007530212, 0.11088021844625473, 0.12122614681720734, 0.13157206773757935, 0.14191798865795135, 0.15226390957832336, 0.16260984539985657, 0.17295576632022858, 0.18330168724060059, 0.1936476230621338, 0.2039935439825058, 0.2143394649028778, 0.22468538582324982, 0.23503130674362183, 0.24537724256515503, 0.25572317838668823, 0.26606908440589905, 0.27641502022743225, 0.28676092624664307, 0.29710686206817627]}, "parameters/value_net.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629, -0.02589552290737629]}, "global_step": 24576, "rollout/ep_len_mean": 87.41000366210938, "rollout/ep_rew_mean": -268.7934875488281, "time/fps": 26.0, "train/entropy_loss": -4.26094913482666, "train/value_loss": 4448.46044921875, "train/std": 1.0018759965896606, "train/policy_gradient_loss": -0.0022994312457740307, "train/loss": 1937.3460693359375, "train/learning_rate": 9.999999747378752e-06, "train/clip_range": 0.20000000298023224, "train/explained_variance": 0.0002124309539794922, "train/clip_fraction": 0.0006469726795330644, "train/approx_kl": 0.0008602659218013287, "_wandb": {"runtime": 1231}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/run-CNN Modified Run 1.wandb b/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/run-CNN Modified Run 1.wandb
deleted file mode 100644
index a0744b5..0000000
Binary files a/ROAR_gym/wandb/run-20220622_100442-CNN Modified Run 1/run-CNN Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/code/ROAR_Gym/e2eModel.py b/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/code/ROAR_Gym/e2eModel.py
deleted file mode 100644
index 5d146a1..0000000
--- a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/code/ROAR_Gym/e2eModel.py	
+++ /dev/null
@@ -1,352 +0,0 @@
-"""
-IMPORTANT
-IF YOU HAVE NOT RUN THIS FILE AS 'ADMIN' (OR OPENED PYCHARM AS 'ADMIN')
-STOP AND RESTART WITH ADMIN PRIVILEGES
-
-TODO: Before Running this file make the following changes:
-1. Add the following line:
-    self._last_obs = np.nan_to_num(self._last_obs)
-
-to the following file:
-    ROAR\venv\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py
-
-2. Add this line after line 167 such that:
-with th.no_grad():
-    # Convert to pytorch tensor or to TensorDict
-    self._last_obs = np.nan_to_num(self._last_obs)
-    obs_tensor = obs_as_tensor(self._last_obs, self.device)
-    actions, values, log_probs = self.policy.forward(obs_tensor)
-
-3. Add: #############################################################################still needed?###########
-
-        data.pop('_last_obs')
-
-    in  line 652 of base_class.py for sb3
-    possible location of file: \envs\ROAR\Lib\site-packages\stable_baselines3\common\base_class.py
-
-4. Change for on_policy_algorithm.py, in function collect_rollouts add:
-
-        self.env.reset()
-
-    before the following while loop:
-
-        while n_steps < n_rollout_steps:
-"""
-
-# IMPORTS
-# imports for logs and warnings
-import warnings
-import logging
-
-from typing import Optional, Dict
-
-# imports for weights and biases integration
-import wandb
-from wandb.integration.sb3 import WandbCallback
-
-# imports for file path handling
-import os
-import sys
-from pathlib import Path
-sys.path.append(Path(os.getcwd()).parent.as_posix())
-
-# imports for reading and writing json config files
-import json
-
-# imports from the ROAR module
-from ROAR_Sim.configurations.configuration import Configuration as CarlaConfig
-from ROAR.configurations.configuration import Configuration as AgentConfig
-from ROAR.agent_module.agent import Agent
-from ROAR.agent_module.rl_e2e_ppo_agent import RLe2ePPOAgent
-from ROAR.agent_module.forward_only_agent import ForwardOnlyAgent   # testing stuff
-
-# imports for reinforcement learning
-import gym
-import torch as th
-from stable_baselines3.ppo.ppo import PPO
-from stable_baselines3.ppo.policies import CnnPolicy
-from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps, CallbackList, BaseCallback
-from stable_baselines3.common.monitor import Monitor
-from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder
-
-
-# imports for helper functions and torch cnn models
-from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN, YunhaoModifiedAtariCNN
-
-
-
-# imports from config files
-from configurations.ppo_configuration import PPO_params, misc_params, wandb_saves
-agent_config = AgentConfig.parse_file(Path("configurations/agent_configuration.json"))
-carla_config = CarlaConfig.parse_file(Path("configurations/carla_configuration.json"))
-
-# Setup for the loggers
-logging.getLogger("tensorflow").setLevel(logging.ERROR)
-logging.getLogger("numpy").setLevel(logging.ERROR)
-warnings.filterwarnings('ignore')
-try:
-    from ROAR_Gym.envs.roar_env import LoggingCallback
-except:
-    from ROAR_Gym.ROAR_Gym.envs.roar_env import LoggingCallback
-
-# os.environ["CUDA_VISIBLE_DEVICES"]="0,1"
-#  Parameters & Constants
-CUDA_VISIBLE_DEVICES = 1
-RUN_FPS = misc_params["run_fps"]
-MODEL_DIR = misc_params["model_directory"]
-WANDB_CONFIG_DIR = "configurations/wandb_configuration.json"
-
-
-def json_read_write(file, load_var=None, mode='r'):
-    """
-
-    Args:
-        file: address of json file to be loaded
-        load_var: variable to be written to, or read from
-        mode: 'r' to read from json, 'w' to write to json
-
-    Returns:
-        load_var: variable with data that has been read in mode 'r'
-                  original variable in case of 'w'
-
-    """
-    if mode == 'r':
-        with open(file, mode) as json_file:
-            load_var = json.load(json_file)  # Reading the file
-            print(f"{file} json config read successful")
-            json_file.close()
-            return load_var
-    elif mode == 'w':
-        assert load_var is not None, "load_var was None"
-        with open(file, mode) as json_file:
-            json.dump(load_var, json_file)  # Writing to the file
-            print(f"{file} json config write successful")
-            json_file.close()
-            return load_var
-    else:
-        assert mode == 'w' or 'r', f"unsupported mode type: {mode}"
-        return None
-
-# TODO track previously used run IDs
-def wandb_run_init(wandb_hp_config, load=False, requested_run_id=None, use_random_id=False):
-
-    wandb_config = json_read_write(
-        file=WANDB_CONFIG_DIR,
-        mode='r',
-    )
-
-    if load is True:
-        # Load run_id from the config file
-        run_id = wandb_config["run_id"]
-        assert run_id != "", "Run ID not set even though previous run exists"
-    else:
-        # Create wandb run id
-        if requested_run_id is not None:
-            run_id = requested_run_id
-        else:
-            assert use_random_id is True, "RUN ID NOT SET FOR NEW RUN"
-            run_id = wandb.util.generate_id()
-
-        # Store run_id to wandb_configuration file
-        wandb_config["run_id"] = run_id
-        wandb_config = json_read_write(
-            file=WANDB_CONFIG_DIR,
-            load_var=wandb_config,
-            mode='w',
-        )
-
-    # Create a wandb run variable
-    wandb.tensorboard.patch(
-        tensorboardX=False,
-        pytorch=True,
-    )
-    run = wandb.init(
-        project=wandb_config["project_name"],
-        entity=wandb_config["entity"],  # Change to whoever wants to log the data
-        config=wandb_hp_config,
-        # sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics
-        save_code=True,  # Allows us to check diff of code between runs
-        resume="allow",
-        # magic=True,
-        id=run_id,
-        name=run_id,
-        #monitor_gym=True,  # auto-upload the videos of agents playing the game,
-    )
-
-    return run
-
-
-class Tensorboard_Faster_Logger(BaseCallback):
-    """
-    Callback for saving a model (the check is done every ``check_freq`` steps)
-    based on the training reward (in practice, we recommend using ``EvalCallback``).
-
-    :param check_freq:
-    :param log_dir: Path to the folder where the model will be saved.
-      It must contains the file created by the ``Monitor`` wrapper.
-    :param verbose: Verbosity level.
-    """
-    def __init__(self, check_freq: int, verbose: int = 1):
-        super(Tensorboard_Faster_Logger, self).__init__(verbose)
-        self.check_freq = check_freq
-
-    # def _init_callback(self) -> None:
-
-    def _on_step(self) -> bool:
-        if self.n_calls % self.check_freq == 0:
-            self.logger.dump(self.num_timesteps)
-        return True
-
-
-def main(pass_num):
-    # Create the gym environment using the configs
-    env = gym.make(
-        id=misc_params["env_name"],
-        params={
-            "agent_config": agent_config,
-            "carla_config": carla_config,
-            "ego_agent_class": RLe2ePPOAgent,
-        }
-    )
-    #print(th.cuda.is_available())
-
-    # Setting the feature extract or based on the environment mode
-    if env.mode == 'baseline':
-        policy_kwargs = dict(
-            features_extractor_class=YunhaoModifiedAtariCNN, #Atari_PPO_Adapted_CNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-    else:
-        policy_kwargs = dict(
-            features_extractor_class=CustomMaxPoolCNN,
-            features_extractor_kwargs=dict(features_dim=256)
-        )
-
-    # training kwargs for PPO init
-    training_kwargs = PPO_params
-
-    # wandb config for current run hyper-parameters
-    wandb_hp_config = {
-        "policy_type": "CnnPolicy",
-        "env_name": misc_params["env_name"],
-        "training_kwargs": training_kwargs,
-    }
-
-    # Try to find latest model path if we have trained previously
-    latest_model_path = find_latest_model(MODEL_DIR)
-    print(latest_model_path)
-    # FIXME wandb may continue old run if the run crashes before it is logged
-    if latest_model_path is None:
-        # Create new wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=False,
-            requested_run_id=misc_params["run_name"],
-        )
-
-        # Create model with tensorboard log
-        model = PPO(
-            CnnPolicy,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs
-        )
-
-        print(f"Starting new run {run.id}")
-    else:
-        # Load wandb run
-        run = wandb_run_init(
-            wandb_hp_config,
-            load=True,
-        )
-
-        # Load the model
-        model = PPO.load(
-            latest_model_path,
-            env=env,
-            policy_kwargs=policy_kwargs,
-            tensorboard_log=f"runs/{run.name}",  # TODO add "tensorboard" to logdir name
-            **training_kwargs,
-        )
-
-        print(f"Loading old run {run.id}")
-
-    print("Model Loaded Successfully")
-
-    # Defining Callback Functions
-
-    logging_callback = LoggingCallback(model=model)
-
-    faster_Logging_Callback = Tensorboard_Faster_Logger(check_freq=wandb_saves["model_save_freq"])
-
-    checkpoint_callback = CheckpointCallback(
-        save_freq=wandb_saves["model_save_freq"],
-        verbose=2,
-        save_path=(MODEL_DIR / "logs").as_posix()
-    )
-
-    event_callback = EveryNTimesteps(
-        n_steps=wandb_saves["model_save_freq"],
-        callback=checkpoint_callback
-    )
-
-    wandb_callback = WandbCallback(
-        verbose=2,
-        model_save_path=f"models/{run.id}",
-        gradient_save_freq=PPO_params["n_steps"],
-        model_save_freq=wandb_saves["model_save_freq"],
-    )
-
-    callbacks = CallbackList([
-        wandb_callback,
-        checkpoint_callback,
-        event_callback,
-        logging_callback
-        # faster_Logging_Callback
-    ])
-
-    # Begin learning
-    model = model.learn(
-        total_timesteps=misc_params["total_timesteps"],
-        callback=callbacks,
-        reset_num_timesteps=False,
-        # tb_log_name=wandb_config["run_id"],
-    )
-
-    # Save Model
-    model.save(MODEL_DIR / f"roar_e2e_model_{pass_num}")  # TODO fix naming convention
-    print("Successful Save!")
-    # # Finish wandb run
-    # run.finish()
-
-if __name__ == '__main__':
-    logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
-                        datefmt="%H:%M:%S", level=logging.INFO)
-    logging.getLogger("Controller").setLevel(logging.ERROR)
-    logging.getLogger("SimplePathFollowingLocalPlanner").setLevel(logging.ERROR)
-    i=0
-    while True:
-        main(i)
-        i += 1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
diff --git a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index 791e45b..0000000
--- a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,46 +0,0 @@
-wandb_version: 1
-
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656467536
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 13
-      - 14
-      - 16
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-policy_type:
-  desc: null
-  value: CnnPolicy
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
diff --git a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/diff.patch b/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/diff.patch
deleted file mode 100644
index 057a3b3..0000000
--- a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/diff.patch	
+++ /dev/null
@@ -1,135 +0,0 @@
-diff --git a/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py b/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py
-index 32b5134..1ad7df6 100644
---- a/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py
-+++ b/ROAR_gym/ROAR_Gym/envs/e2eModel_roar_env.py
-@@ -57,7 +57,10 @@ class ROARppoEnvE2E(ROAREnv):
-         elif self.mode=='combine':
-             self.observation_space = Box(-10, 1, shape=(FRAME_STACK,3, CONFIG["x_res"], CONFIG["y_res"]), dtype=np.float32)
-         elif self.mode=='baseline':
--            self.observation_space = Box(-10, 1, shape=(FRAME_STACK,3, CONFIG["x_res"], CONFIG["y_res"]), dtype=np.float32)
-+            self.observation_space = gym.spaces.Tuple((
-+                Box(-10, 1, shape=(FRAME_STACK,3, CONFIG["x_res"], CONFIG["y_res"]), dtype=np.float32), # Occupancy Map
-+                Box(np.array([-1.0,0,0]),1.0,shape = (3,), dtype=np.float32) #steering, throttle, braking
-+            ))
-         else:
-             self.observation_space = Box(-10, 1, shape=(FRAME_STACK, CONFIG["x_res"], CONFIG["y_res"]), dtype=np.float32)
-         self.prev_speed = 0
-@@ -254,7 +257,16 @@ class ROARppoEnvE2E(ROAREnv):
-             cv2.imshow("data", np.hstack(np.hstack(map_list))) # uncomment to show occu map
-             cv2.waitKey(1)
- 
--            return map_list[:,:-1]
-+            cnnObs = map_list[:,:-1]
-+            last_control = self.agent.kwargs["control"]
-+            last_control_array = np.array([
-+                last_control.get_steering(),
-+                last_control.get_throttle(),
-+                last_control.get_braking()
-+            ])#steering, throttle, braking
-+
-+
-+            return (cnnObs,last_control)
- 
-         else:
-             data = self.agent.occupancy_map.get_map(transform=self.agent.vehicle.transform,
-diff --git a/ROAR_gym/configurations/ppo_configuration.py b/ROAR_gym/configurations/ppo_configuration.py
-index 17b1310..7e6c1d3 100644
---- a/ROAR_gym/configurations/ppo_configuration.py
-+++ b/ROAR_gym/configurations/ppo_configuration.py
-@@ -10,8 +10,8 @@ sys.path.append(Path(os.getcwd()).parent.as_posix())
- misc_params = {
-   "env_name": 'roar-e2e-ppo-v0',
-   "run_fps": 8,  # TODO Link to the environment RUN_FPS
--  "model_directory": Path("./output/Yunhao_PPOe2e_Input_Change"),
--  "run_name": "Test Run 1",
-+  "model_directory": Path("./output/Yunhao_PPOe2e_CNN_Modified_Change_V2"),
-+  "run_name": "CNN V2 Modified Run 1",
-   "total_timesteps": int(1e6),
- }
- 
-diff --git a/ROAR_gym/configurations/wandb_configuration.json b/ROAR_gym/configurations/wandb_configuration.json
-index cfb2610..2476cda 100644
---- a/ROAR_gym/configurations/wandb_configuration.json
-+++ b/ROAR_gym/configurations/wandb_configuration.json
-@@ -1 +1 @@
--{"run_id": "Test Run 1", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
-\ No newline at end of file
-+{"run_id": "CNN V2 Modified Run 1", "name": "", "project_name": "Yunhao_Minor_Map_Input_Change", "entity": "roar"}
-\ No newline at end of file
-diff --git a/ROAR_gym/e2eModel.py b/ROAR_gym/e2eModel.py
-index f0a3788..5d146a1 100644
---- a/ROAR_gym/e2eModel.py
-+++ b/ROAR_gym/e2eModel.py
-@@ -71,7 +71,7 @@ from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder
- 
- 
- # imports for helper functions and torch cnn models
--from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN
-+from ppo_util import find_latest_model, CustomMaxPoolCNN, Atari_PPO_Adapted_CNN, YunhaoModifiedAtariCNN
- 
- 
- 
-@@ -213,7 +213,7 @@ def main(pass_num):
-     # Setting the feature extract or based on the environment mode
-     if env.mode == 'baseline':
-         policy_kwargs = dict(
--            features_extractor_class=Atari_PPO_Adapted_CNN,
-+            features_extractor_class=YunhaoModifiedAtariCNN, #Atari_PPO_Adapted_CNN,
-             features_extractor_kwargs=dict(features_dim=256)
-         )
-     else:
-diff --git a/ROAR_gym/ppo_util.py b/ROAR_gym/ppo_util.py
-index 6702b99..8316cc9 100644
---- a/ROAR_gym/ppo_util.py
-+++ b/ROAR_gym/ppo_util.py
-@@ -4,6 +4,7 @@ from typing import Optional, Dict
- import gym
- import torch as th
- from torch import nn
-+import torch
- import torch.nn.functional as F
- import torchvision
- import numpy as np
-@@ -173,7 +174,6 @@ class CustomMaxPoolCNN_attention(BaseFeaturesExtractor):
-         return self.fullStack(observations[0])
- 
- 
--
- class CustomMaxPoolCNN(BaseFeaturesExtractor):
-     """
-     the CNN network that interleaves convolution & maxpooling layers, used in a
-@@ -424,6 +424,34 @@ class Atari_PPO_Adapted_CNN(BaseFeaturesExtractor):
-         observations=observations.view(observations.shape[0],-1,*observations.shape[3:])
-         return self.network(observations)
- 
-+class YunhaoModifiedAtariCNN(BaseFeaturesExtractor):
-+    def __init__(self, observation_space: gym.spaces.Tuple, features_dim: int = 256):
-+        super(YunhaoModifiedAtariCNN, self).__init__(observation_space,features_dim)
-+        cnn_space = observation_space.spaces[0]
-+        info_space = observation_space.spaces[1]
-+        channels = cnn_space.shape[0]*cnn_space.shape[1]
-+        self.network = nn.Sequential(
-+            # Scale(1/255),
-+            layer_init(nn.Conv2d(channels, 32, 8, stride=4)),
-+            nn.ReLU(),
-+            layer_init(nn.Conv2d(32, 64, 4, stride=2)),
-+            nn.ReLU(),
-+            layer_init(nn.Conv2d(64, 64, 3, stride=1)),
-+            nn.ReLU(),
-+            layer_init(nn.Conv2d(64,16,1,stride=1)), #added
-+            nn.ReLU(),
-+            nn.Flatten(),
-+            layer_init(nn.Linear(784, features_dim - info_space.shape[0])), #shrinked
-+            # nn.ReLU(),
-+        )
-+
-+    def forward(self, observations : tuple) -> th.Tensor:
-+        observations=observations.view(observations.shape[0],-1,*observations.shape[3:])
-+        cnnOutput = self.network(observations[0])
-+        infoOutput = observations[1]
-+        return torch.concat((cnnOutput,infoOutput))
-+
-+
- def find_latest_model(root_path: Path) -> Optional[Path]:
-     import os
-     from pathlib import Path
diff --git a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/requirements.txt b/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/requirements.txt
deleted file mode 100644
index 65dc1e5..0000000
--- a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/requirements.txt	
+++ /dev/null
@@ -1,130 +0,0 @@
-absl-py==1.1.0
-anyio==3.6.1
-argon2-cffi-bindings==21.2.0
-argon2-cffi==21.3.0
-attrs==21.4.0
-babel==2.10.3
-backcall==0.2.0
-beautifulsoup4==4.11.1
-bleach==5.0.0
-cachetools==5.2.0
-carla==0.9.10
-certifi==2022.6.15
-cffi==1.15.0
-charset-normalizer==2.0.12
-click==8.1.3
-cloudpickle==2.1.0
-colorama==0.4.5
-cycler==0.11.0
-debugpy==1.6.0
-decorator==5.1.1
-defusedxml==0.7.1
-deprecation==2.1.0
-docker-pycreds==0.4.0
-entrypoints==0.4
-fastjsonschema==2.15.3
-fonttools==4.33.3
-gitdb==4.0.9
-gitpython==3.1.27
-google-auth-oauthlib==0.4.6
-google-auth==2.8.0
-grpcio==1.46.3
-gym==0.21.0
-idna==3.3
-importlib-metadata==4.11.4
-importlib-resources==5.8.0
-ipykernel==6.15.0
-ipython-genutils==0.2.0
-ipython==7.34.0
-ipywidgets==7.7.0
-jedi==0.18.1
-jinja2==3.1.2
-json5==0.9.8
-jsonschema==4.6.0
-jupyter-client==7.3.4
-jupyter-core==4.10.0
-jupyter-packaging==0.12.2
-jupyter-server==1.17.1
-jupyterlab-pygments==0.2.2
-jupyterlab-server==2.14.0
-jupyterlab-widgets==1.1.0
-jupyterlab==3.4.3
-kiwisolver==1.4.3
-markdown==3.3.7
-markupsafe==2.1.1
-matplotlib-inline==0.1.3
-matplotlib==3.5.2
-mistune==0.8.4
-nbclassic==0.3.7
-nbclient==0.6.4
-nbconvert==6.5.0
-nbformat==5.4.0
-nest-asyncio==1.5.5
-notebook-shim==0.1.0
-notebook==6.4.12
-numpy==1.21.6
-oauthlib==3.2.0
-open3d==0.15.1
-packaging==21.3
-pandas==1.3.5
-pandocfilters==1.5.0
-parso==0.8.3
-pathtools==0.1.2
-pickleshare==0.7.5
-pillow==9.1.1
-pip==22.1.2
-prometheus-client==0.14.1
-promise==2.3
-prompt-toolkit==3.0.29
-protobuf==3.19.4
-psutil==5.9.1
-pyasn1-modules==0.2.8
-pyasn1==0.4.8
-pycparser==2.21
-pydantic==1.9.1
-pygame==2.1.2
-pygments==2.12.0
-pyparsing==3.0.9
-pyrsistent==0.18.1
-python-dateutil==2.8.2
-pytz==2022.1
-pywin32==304
-pywinpty==2.0.5
-pyyaml==6.0
-pyzmq==23.2.0
-requests-oauthlib==1.3.1
-requests==2.28.0
-rsa==4.8
-scipy==1.7.3
-send2trash==1.8.0
-sentry-sdk==1.5.12
-setproctitle==1.2.3
-setuptools==62.6.0
-shortuuid==1.0.9
-six==1.16.0
-smmap==5.0.0
-sniffio==1.2.0
-soupsieve==2.3.2.post1
-stable-baselines3==1.5.0
-tensorboard-data-server==0.6.1
-tensorboard-plugin-wit==1.8.1
-tensorboard==2.9.1
-termcolor==1.1.0
-terminado==0.15.0
-tinycss2==1.1.1
-tomlkit==0.11.0
-torch==1.11.0
-torchvision==0.12.0
-tornado==6.1
-traitlets==5.3.0
-typing-extensions==4.2.0
-urllib3==1.26.9
-wandb==0.12.11
-wcwidth==0.2.5
-webencodings==0.5.1
-websocket-client==1.3.3
-werkzeug==2.1.2
-wheel==0.37.1
-widgetsnbextension==3.6.0
-yaspin==2.1.0
-zipp==3.8.0
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/wandb-metadata.json b/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/wandb-metadata.json
deleted file mode 100644
index d829bcc..0000000
--- a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/wandb-metadata.json	
+++ /dev/null
@@ -1,24 +0,0 @@
-{
-    "os": "Windows-10-10.0.22000-SP0",
-    "python": "3.7.9",
-    "heartbeatAt": "2022-06-29T01:52:18.324197",
-    "startedAt": "2022-06-29T01:52:16.669620",
-    "docker": null,
-    "gpu": "NVIDIA GeForce RTX 3080",
-    "gpu_count": 1,
-    "cpu_count": 20,
-    "cuda": null,
-    "args": [],
-    "state": "running",
-    "program": "e2eModel.py",
-    "codePath": "ROAR_Gym\\e2eModel.py",
-    "git": {
-        "remote": "https://github.com/ToiletCommander/ROAR_RL",
-        "commit": "932723adf08dc8f0c0fe7f8317822ae1da9daced"
-    },
-    "email": "1745500559@qq.com",
-    "root": "D:/Programming/Subjects/ROAR/ROAR_RL",
-    "host": "Windys-Desktop",
-    "username": "cxcyh",
-    "executable": "D:\\Programming\\Subjects\\ROAR\\ROAR_RL\\roar-dev\\Scripts\\python.exe"
-}
diff --git a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 971d479..0000000
--- a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 1}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index 5e6b7a6..0000000
Binary files a/ROAR_gym/wandb/run-20220629_095216-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index 7a938a9..0000000
--- a/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,48 +0,0 @@
-wandb_version: 1
-
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468156
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-policy_type:
-  desc: null
-  value: CnnPolicy
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
diff --git a/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 8bf99d1..0000000
--- a/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 11}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index dcc0251..0000000
Binary files a/ROAR_gym/wandb/run-20220629_100236-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index 465d1b9..0000000
--- a/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,48 +0,0 @@
-wandb_version: 1
-
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468200
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-policy_type:
-  desc: null
-  value: CnnPolicy
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
diff --git a/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index e32ca1c..0000000
--- a/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 13}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index 62d790a..0000000
Binary files a/ROAR_gym/wandb/run-20220629_100320-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index de265bf..0000000
--- a/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,312 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468562
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 1
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0.0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 5118b50..0000000
--- a/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 15}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index c0a1fb9..0000000
Binary files a/ROAR_gym/wandb/run-20220629_100922-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index c556bbb..0000000
--- a/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,312 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468583
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 1
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 29d260f..0000000
--- a/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 16}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index 4954ae9..0000000
Binary files a/ROAR_gym/wandb/run-20220629_100943-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index d96e3f7..0000000
--- a/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,312 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468663
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 1
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 26a909c..0000000
--- a/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 17}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index a87b9dc..0000000
Binary files a/ROAR_gym/wandb/run-20220629_101103-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index 8c95acd..0000000
--- a/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,312 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468750
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 1
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 1f49627..0000000
--- a/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 18}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index 19e35b1..0000000
Binary files a/ROAR_gym/wandb/run-20220629_101230-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index b95edbe..0000000
--- a/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,311 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468937
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index f97bfbe..0000000
--- a/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 29}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index f7fcd1d..0000000
Binary files a/ROAR_gym/wandb/run-20220629_101537-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index 366c9a3..0000000
--- a/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,312 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656468957
-    t:
-      1:
-      - 1
-      - 41
-      2:
-      - 1
-      - 41
-      3:
-      - 1
-      - 5
-      - 13
-      - 14
-      - 16
-      - 22
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 3892ef5..0000000
--- a/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 31}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index f7eda0c..0000000
Binary files a/ROAR_gym/wandb/run-20220629_101557-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index e797dd1..0000000
--- a/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,306 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656469473
-    t:
-      1:
-      - 1
-      - 41
-      3:
-      - 13
-      - 14
-      - 16
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index f205c24..0000000
--- a/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 32}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index 6c52692..0000000
Binary files a/ROAR_gym/wandb/run-20220629_102433-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
diff --git a/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/files/config.yaml b/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/files/config.yaml
deleted file mode 100644
index f875351..0000000
--- a/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/files/config.yaml	
+++ /dev/null
@@ -1,306 +0,0 @@
-wandb_version: 1
-
-_current_progress_remaining:
-  desc: null
-  value: 1
-_custom_logger:
-  desc: null
-  value: 'False'
-_episode_num:
-  desc: null
-  value: 0
-_last_episode_starts:
-  desc: null
-  value: '[ True]'
-_last_obs:
-  desc: null
-  value: "OrderedDict([('occupancy_map', array([[[[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0.,\
-    \ 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n   \
-    \      [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n    \
-    \    [[[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]],\n\n         [[0., 0., 0., ..., 0., 0., 0.],\n   \
-    \       [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n\n       \
-    \  [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n\
-    \          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0.,\
-    \ 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0.,\
-    \ 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)), ('previous_control', array([[nan,\
-    \ nan, nan]], dtype=float32))])"
-_last_original_obs:
-  desc: null
-  value: None
-_logger:
-  desc: null
-  value: <stable_baselines3.common.logger.Logger object at 0x000001F8AE1AAFC8>
-_n_updates:
-  desc: null
-  value: 0
-_num_timesteps_at_start:
-  desc: null
-  value: 0
-_total_timesteps:
-  desc: null
-  value: 1000000
-_vec_normalize_env:
-  desc: null
-  value: None
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.12.11
-    code_path: code/ROAR_Gym/e2eModel.py
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    python_version: 3.7.9
-    start_time: 1656471341
-    t:
-      1:
-      - 1
-      - 41
-      3:
-      - 13
-      - 14
-      - 16
-      - 34
-      4: 3.7.9
-      5: 0.12.11
-      8:
-      - 3
-      - 5
-action_noise:
-  desc: null
-  value: None
-action_space:
-  desc: null
-  value: Box([-2.5 -5.   1. ], [-0.5  5.   3. ], (3,), float32)
-algo:
-  desc: null
-  value: PPO
-batch_size:
-  desc: null
-  value: 64
-clip_range:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD404B88>
-clip_range_vf:
-  desc: null
-  value: None
-device:
-  desc: null
-  value: cpu
-ent_coef:
-  desc: null
-  value: 0
-env:
-  desc: null
-  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F7FD0BA0C8>
-env_name:
-  desc: null
-  value: roar-e2e-ppo-v0
-ep_info_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-ep_success_buffer:
-  desc: null
-  value: deque([], maxlen=100)
-eval_env:
-  desc: null
-  value: None
-gae_lambda:
-  desc: null
-  value: 0.95
-gamma:
-  desc: null
-  value: 0.99
-learning_rate:
-  desc: null
-  value: 1.0e-05
-lr_schedule:
-  desc: null
-  value: <function constant_fn.<locals>.func at 0x000001F7FD3A6F78>
-max_grad_norm:
-  desc: null
-  value: 0.5
-n_envs:
-  desc: null
-  value: 1
-n_epochs:
-  desc: null
-  value: 10
-n_steps:
-  desc: null
-  value: 8192
-normalize_advantage:
-  desc: null
-  value: 'True'
-num_timesteps:
-  desc: null
-  value: 0
-observation_space:
-  desc: null
-  value: "Dict(occupancy_map:Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
-    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
-    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
-    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
-    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
-    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
-    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
-    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
-    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
-    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
-    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
-    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32), previous_control:Box([-1.  0.  0.],\
-    \ [1. 1. 1.], (3,), float32))"
-policy:
-  desc: null
-  value: "ActorCriticCnnPolicy(\n  (features_extractor): YunhaoModifiedAtariCNN(\n\
-    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
-    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
-    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
-    \ 1))\n      (5): ReLU()\n      (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1,\
-    \ 1))\n      (7): ReLU()\n      (8): Flatten(start_dim=1, end_dim=-1)\n      (9):\
-    \ Linear(in_features=784, out_features=253, bias=True)\n    )\n  )\n  (mlp_extractor):\
-    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
-    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
-    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
-    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
-    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
-    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
-    \ out_features=3, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
-    \ bias=True)\n)"
-policy_class:
-  desc: null
-  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
-policy_kwargs:
-  desc: null
-  value: '{''features_extractor_class'': <class ''ppo_util.YunhaoModifiedAtariCNN''>,
-    ''features_extractor_kwargs'': {''features_dim'': 256}}'
-policy_type:
-  desc: null
-  value: CnnPolicy
-rollout_buffer:
-  desc: null
-  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001F7FD3E5288>
-sde_sample_freq:
-  desc: null
-  value: -1
-seed:
-  desc: null
-  value: 1
-start_time:
-  desc: null
-  value: 1656468563.93503
-target_kl:
-  desc: null
-  value: None
-tensorboard_log:
-  desc: null
-  value: runs/CNN V2 Modified Run 1
-training_kwargs:
-  desc: null
-  value:
-    batch_size: 64
-    device: cpu
-    ent_coef: 0.0
-    gamma: 0.99
-    learning_rate: 1.0e-05
-    n_steps: 8192
-    seed: 1
-    verbose: 1
-use_sde:
-  desc: null
-  value: 'False'
-verbose:
-  desc: null
-  value: 1
-vf_coef:
-  desc: null
-  value: 0.5
diff --git a/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/files/wandb-summary.json b/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/files/wandb-summary.json
deleted file mode 100644
index 7daf75c..0000000
--- a/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/files/wandb-summary.json	
+++ /dev/null
@@ -1 +0,0 @@
-{"_wandb": {"runtime": 35}}
\ No newline at end of file
diff --git a/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb b/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb
deleted file mode 100644
index 1d02722..0000000
Binary files a/ROAR_gym/wandb/run-20220629_105541-CNN V2 Modified Run 1/run-CNN V2 Modified Run 1.wandb and /dev/null differ
